{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "188: 978\n",
      "21: 978\n",
      "195: 978\n",
      "414: 978\n",
      "42: 978\n",
      "41: 978\n",
      "978: 978\n",
      "23: 978\n",
      "86: 978\n",
      "246: 978\n",
      "16: 978\n",
      "10: 978\n",
      "34: 978\n",
      "2: 978\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "965/978 [============================>.] - ETA: 0s - loss: 6.6991 - leftLayer1_loss: 0.1246 - midLayer1_loss: 1.4401 - rightLayer1_loss: 1.7799 - leftLayer2_loss: 0.1258 - midLayer2_loss: 1.4775 - rightLayer2_loss: 1.7511\n",
      "Epoch 00001: val_loss improved from inf to 6.49146, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 6.6955 - leftLayer1_loss: 0.1246 - midLayer1_loss: 1.4402 - rightLayer1_loss: 1.7792 - leftLayer2_loss: 0.1258 - midLayer2_loss: 1.4770 - rightLayer2_loss: 1.7487 - val_loss: 6.4915 - val_leftLayer1_loss: 0.1244 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.7215 - val_leftLayer2_loss: 0.1232 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.6945\n",
      "Epoch 2/11\n",
      "966/978 [============================>.] - ETA: 0s - loss: 6.3084 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.4426 - rightLayer1_loss: 1.6790 - leftLayer2_loss: 0.1198 - midLayer2_loss: 1.4767 - rightLayer2_loss: 1.4676\n",
      "Epoch 00002: val_loss improved from 6.49146 to 6.23243, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.3061 - leftLayer1_loss: 0.1226 - midLayer1_loss: 1.4427 - rightLayer1_loss: 1.6783 - leftLayer2_loss: 0.1197 - midLayer2_loss: 1.4765 - rightLayer2_loss: 1.4662 - val_loss: 6.2324 - val_leftLayer1_loss: 0.1225 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.6243 - val_leftLayer2_loss: 0.1195 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.5383\n",
      "Epoch 3/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 6.0323 - leftLayer1_loss: 0.1208 - midLayer1_loss: 1.4416 - rightLayer1_loss: 1.5866 - leftLayer2_loss: 0.1147 - midLayer2_loss: 1.4783 - rightLayer2_loss: 1.2903\n",
      "Epoch 00003: val_loss improved from 6.23243 to 6.03036, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.0315 - leftLayer1_loss: 0.1208 - midLayer1_loss: 1.4420 - rightLayer1_loss: 1.5858 - leftLayer2_loss: 0.1147 - midLayer2_loss: 1.4793 - rightLayer2_loss: 1.2890 - val_loss: 6.0304 - val_leftLayer1_loss: 0.1206 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.5371 - val_leftLayer2_loss: 0.1160 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.4288\n",
      "Epoch 4/11\n",
      "967/978 [============================>.] - ETA: 0s - loss: 5.8383 - leftLayer1_loss: 0.1189 - midLayer1_loss: 1.4423 - rightLayer1_loss: 1.5043 - leftLayer2_loss: 0.1090 - midLayer2_loss: 1.4812 - rightLayer2_loss: 1.1826\n",
      "Epoch 00004: val_loss improved from 6.03036 to 5.87173, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.8374 - leftLayer1_loss: 0.1189 - midLayer1_loss: 1.4424 - rightLayer1_loss: 1.5036 - leftLayer2_loss: 0.1089 - midLayer2_loss: 1.4819 - rightLayer2_loss: 1.1818 - val_loss: 5.8717 - val_leftLayer1_loss: 0.1188 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.4603 - val_leftLayer2_loss: 0.1128 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.3520\n",
      "Epoch 5/11\n",
      "957/978 [============================>.] - ETA: 0s - loss: 5.6887 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.4414 - rightLayer1_loss: 1.4332 - leftLayer2_loss: 0.1036 - midLayer2_loss: 1.4748 - rightLayer2_loss: 1.1185\n",
      "Epoch 00005: val_loss improved from 5.87173 to 5.74561, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.6873 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.4417 - rightLayer1_loss: 1.4321 - leftLayer2_loss: 0.1036 - midLayer2_loss: 1.4756 - rightLayer2_loss: 1.1173 - val_loss: 5.7456 - val_leftLayer1_loss: 0.1170 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.3937 - val_leftLayer2_loss: 0.1097 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.2973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "970/978 [============================>.] - ETA: 0s - loss: 5.5960 - leftLayer1_loss: 0.1155 - midLayer1_loss: 1.4418 - rightLayer1_loss: 1.3711 - leftLayer2_loss: 0.0996 - midLayer2_loss: 1.4882 - rightLayer2_loss: 1.0798\n",
      "Epoch 00006: val_loss improved from 5.74561 to 5.64270, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 2s 3ms/step - loss: 5.5941 - leftLayer1_loss: 0.1155 - midLayer1_loss: 1.4416 - rightLayer1_loss: 1.3705 - leftLayer2_loss: 0.0996 - midLayer2_loss: 1.4878 - rightLayer2_loss: 1.0791 - val_loss: 5.6427 - val_leftLayer1_loss: 0.1153 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.3365 - val_leftLayer2_loss: 0.1069 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.2562\n",
      "Epoch 7/11\n",
      "959/978 [============================>.] - ETA: 0s - loss: 5.5009 - leftLayer1_loss: 0.1137 - midLayer1_loss: 1.4425 - rightLayer1_loss: 1.3184 - leftLayer2_loss: 0.0952 - midLayer2_loss: 1.4839 - rightLayer2_loss: 1.0472\n",
      "Epoch 00007: val_loss improved from 5.64270 to 5.55788, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5008 - leftLayer1_loss: 0.1136 - midLayer1_loss: 1.4429 - rightLayer1_loss: 1.3175 - leftLayer2_loss: 0.0952 - midLayer2_loss: 1.4845 - rightLayer2_loss: 1.0470 - val_loss: 5.5579 - val_leftLayer1_loss: 0.1135 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.2877 - val_leftLayer2_loss: 0.1042 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.2246\n",
      "Epoch 8/11\n",
      "969/978 [============================>.] - ETA: 0s - loss: 5.4325 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.4435 - rightLayer1_loss: 1.2730 - leftLayer2_loss: 0.0913 - midLayer2_loss: 1.4792 - rightLayer2_loss: 1.0335\n",
      "Epoch 00008: val_loss improved from 5.55788 to 5.48679, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4297 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.4434 - rightLayer1_loss: 1.2723 - leftLayer2_loss: 0.0912 - midLayer2_loss: 1.4779 - rightLayer2_loss: 1.0329 - val_loss: 5.4868 - val_leftLayer1_loss: 0.1119 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.2461 - val_leftLayer2_loss: 0.1017 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.1993\n",
      "Epoch 9/11\n",
      "975/978 [============================>.] - ETA: 0s - loss: 5.3712 - leftLayer1_loss: 0.1104 - midLayer1_loss: 1.4414 - rightLayer1_loss: 1.2337 - leftLayer2_loss: 0.0881 - midLayer2_loss: 1.4805 - rightLayer2_loss: 1.0172\n",
      "Epoch 00009: val_loss improved from 5.48679 to 5.42678, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3713 - leftLayer1_loss: 0.1104 - midLayer1_loss: 1.4415 - rightLayer1_loss: 1.2334 - leftLayer2_loss: 0.0881 - midLayer2_loss: 1.4808 - rightLayer2_loss: 1.0172 - val_loss: 5.4268 - val_leftLayer1_loss: 0.1102 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.2106 - val_leftLayer2_loss: 0.0993 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.1788\n",
      "Epoch 10/11\n",
      "971/978 [============================>.] - ETA: 0s - loss: 5.3258 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.4426 - rightLayer1_loss: 1.2024 - leftLayer2_loss: 0.0850 - midLayer2_loss: 1.4796 - rightLayer2_loss: 1.0073\n",
      "Epoch 00010: val_loss improved from 5.42678 to 5.37539, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3247 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.4426 - rightLayer1_loss: 1.2019 - leftLayer2_loss: 0.0850 - midLayer2_loss: 1.4794 - rightLayer2_loss: 1.0069 - val_loss: 5.3754 - val_leftLayer1_loss: 0.1086 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.1803 - val_leftLayer2_loss: 0.0971 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.1615\n",
      "Epoch 11/11\n",
      "958/978 [============================>.] - ETA: 0s - loss: 5.2775 - leftLayer1_loss: 0.1073 - midLayer1_loss: 1.4429 - rightLayer1_loss: 1.1749 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.4759 - rightLayer2_loss: 0.9947\n",
      "Epoch 00011: val_loss improved from 5.37539 to 5.33136, saving model to ./experiments/0.009_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2782 - leftLayer1_loss: 0.1072 - midLayer1_loss: 1.4430 - rightLayer1_loss: 1.1742 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.4772 - rightLayer2_loss: 0.9949 - val_loss: 5.3314 - val_leftLayer1_loss: 0.1071 - val_midLayer1_loss: 1.4336 - val_rightLayer1_loss: 1.1542 - val_leftLayer2_loss: 0.0951 - val_midLayer2_loss: 1.3942 - val_rightLayer2_loss: 1.1471\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Pneumonia: 0.5326342188460738\n",
      "\n",
      "auprc 0Pneumonia: 0.011502515980766544\n",
      "\n",
      "auroc 1Pneumonia: 0.4525291505639804\n",
      "\n",
      "auprc 1Pneumonia: 0.008913919955578931\n",
      "\n",
      "auroc 2Pneumonia: 0.43008296491280995\n",
      "\n",
      "auprc 2Pneumonia: 0.008550938283744038\n",
      "\n",
      "auroc 3Pneumonia: 0.48658500523814474\n",
      "\n",
      "auprc 3Pneumonia: 0.010854640046871436\n",
      "\n",
      "auroc 4Pneumonia: 0.48901982078208317\n",
      "\n",
      "auprc 4Pneumonia: 0.009760690988770337\n",
      "\n",
      "auroc 5Pneumonia: 0.47872816058628487\n",
      "\n",
      "auprc 5Pneumonia: 0.010531405139096164\n",
      "\n",
      "mean auroc: 0.47826322015489614\n",
      "\n",
      "mean auprc: 0.01001901839913791\n",
      "\n",
      "max auroc: 0.5326342188460738\n",
      "\n",
      "max auprc: 0.011502515980766544\n",
      "\n",
      "56.98218631744385\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "970/978 [============================>.] - ETA: 0s - loss: 6.7423 - leftLayer1_loss: 0.1290 - midLayer1_loss: 1.3798 - rightLayer1_loss: 1.8219 - leftLayer2_loss: 0.1170 - midLayer2_loss: 1.5599 - rightLayer2_loss: 1.7347\n",
      "Epoch 00001: val_loss improved from inf to 6.51582, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.7402 - leftLayer1_loss: 0.1289 - midLayer1_loss: 1.3797 - rightLayer1_loss: 1.8214 - leftLayer2_loss: 0.1169 - midLayer2_loss: 1.5601 - rightLayer2_loss: 1.7331 - val_loss: 6.5158 - val_leftLayer1_loss: 0.1284 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.7514 - val_leftLayer2_loss: 0.1179 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.6631\n",
      "Epoch 2/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 6.3165 - leftLayer1_loss: 0.1263 - midLayer1_loss: 1.3784 - rightLayer1_loss: 1.6940 - leftLayer2_loss: 0.1116 - midLayer2_loss: 1.5532 - rightLayer2_loss: 1.4529\n",
      "Epoch 00002: val_loss improved from 6.51582 to 6.21967, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.3137 - leftLayer1_loss: 0.1263 - midLayer1_loss: 1.3789 - rightLayer1_loss: 1.6928 - leftLayer2_loss: 0.1115 - midLayer2_loss: 1.5532 - rightLayer2_loss: 1.4508 - val_loss: 6.2197 - val_leftLayer1_loss: 0.1258 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.6283 - val_leftLayer2_loss: 0.1142 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.4964\n",
      "Epoch 3/11\n",
      "965/978 [============================>.] - ETA: 0s - loss: 6.0040 - leftLayer1_loss: 0.1239 - midLayer1_loss: 1.3794 - rightLayer1_loss: 1.5788 - leftLayer2_loss: 0.1059 - midLayer2_loss: 1.5451 - rightLayer2_loss: 1.2709\n",
      "Epoch 00003: val_loss improved from 6.21967 to 5.99280, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.0013 - leftLayer1_loss: 0.1238 - midLayer1_loss: 1.3797 - rightLayer1_loss: 1.5780 - leftLayer2_loss: 0.1059 - midLayer2_loss: 1.5447 - rightLayer2_loss: 1.2692 - val_loss: 5.9928 - val_leftLayer1_loss: 0.1234 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.5206 - val_leftLayer2_loss: 0.1107 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.3831\n",
      "Epoch 4/11\n",
      "956/978 [============================>.] - ETA: 0s - loss: 5.8050 - leftLayer1_loss: 0.1215 - midLayer1_loss: 1.3806 - rightLayer1_loss: 1.4800 - leftLayer2_loss: 0.1008 - midLayer2_loss: 1.5569 - rightLayer2_loss: 1.1652\n",
      "Epoch 00004: val_loss improved from 5.99280 to 5.81988, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.8019 - leftLayer1_loss: 0.1214 - midLayer1_loss: 1.3807 - rightLayer1_loss: 1.4787 - leftLayer2_loss: 0.1007 - midLayer2_loss: 1.5569 - rightLayer2_loss: 1.1636 - val_loss: 5.8199 - val_leftLayer1_loss: 0.1210 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.4293 - val_leftLayer2_loss: 0.1074 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.3072\n",
      "Epoch 5/11\n",
      "976/978 [============================>.] - ETA: 0s - loss: 5.6586 - leftLayer1_loss: 0.1191 - midLayer1_loss: 1.3819 - rightLayer1_loss: 1.3968 - leftLayer2_loss: 0.0965 - midLayer2_loss: 1.5596 - rightLayer2_loss: 1.1046\n",
      "Epoch 00005: val_loss improved from 5.81988 to 5.68512, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.6584 - leftLayer1_loss: 0.1191 - midLayer1_loss: 1.3819 - rightLayer1_loss: 1.3966 - leftLayer2_loss: 0.0965 - midLayer2_loss: 1.5597 - rightLayer2_loss: 1.1045 - val_loss: 5.6851 - val_leftLayer1_loss: 0.1186 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.3535 - val_leftLayer2_loss: 0.1044 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.2537\n",
      "Epoch 6/11\n",
      "962/978 [============================>.] - ETA: 0s - loss: 5.5470 - leftLayer1_loss: 0.1169 - midLayer1_loss: 1.3806 - rightLayer1_loss: 1.3284 - leftLayer2_loss: 0.0926 - midLayer2_loss: 1.5625 - rightLayer2_loss: 1.0660\n",
      "Epoch 00006: val_loss improved from 5.68512 to 5.57877, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5450 - leftLayer1_loss: 0.1168 - midLayer1_loss: 1.3806 - rightLayer1_loss: 1.3276 - leftLayer2_loss: 0.0925 - midLayer2_loss: 1.5617 - rightLayer2_loss: 1.0657 - val_loss: 5.5788 - val_leftLayer1_loss: 0.1164 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.2913 - val_leftLayer2_loss: 0.1015 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.2146\n",
      "Epoch 7/11\n",
      "967/978 [============================>.] - ETA: 0s - loss: 5.4525 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.3790 - rightLayer1_loss: 1.2738 - leftLayer2_loss: 0.0883 - midLayer2_loss: 1.5550 - rightLayer2_loss: 1.0418\n",
      "Epoch 00007: val_loss improved from 5.57877 to 5.49318, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4523 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.3791 - rightLayer1_loss: 1.2732 - leftLayer2_loss: 0.0883 - midLayer2_loss: 1.5561 - rightLayer2_loss: 1.0409 - val_loss: 5.4932 - val_leftLayer1_loss: 0.1142 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.2404 - val_leftLayer2_loss: 0.0989 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.1848\n",
      "Epoch 8/11\n",
      "967/978 [============================>.] - ETA: 0s - loss: 5.3775 - leftLayer1_loss: 0.1125 - midLayer1_loss: 1.3804 - rightLayer1_loss: 1.2273 - leftLayer2_loss: 0.0851 - midLayer2_loss: 1.5502 - rightLayer2_loss: 1.0220\n",
      "Epoch 00008: val_loss improved from 5.49318 to 5.42323, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3770 - leftLayer1_loss: 0.1125 - midLayer1_loss: 1.3806 - rightLayer1_loss: 1.2267 - leftLayer2_loss: 0.0851 - midLayer2_loss: 1.5510 - rightLayer2_loss: 1.0211 - val_loss: 5.4232 - val_leftLayer1_loss: 0.1120 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.1986 - val_leftLayer2_loss: 0.0964 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.1612\n",
      "Epoch 9/11\n",
      "967/978 [============================>.] - ETA: 0s - loss: 5.3228 - leftLayer1_loss: 0.1104 - midLayer1_loss: 1.3795 - rightLayer1_loss: 1.1890 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5533 - rightLayer2_loss: 1.0087\n",
      "Epoch 00009: val_loss improved from 5.42323 to 5.36558, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3216 - leftLayer1_loss: 0.1104 - midLayer1_loss: 1.3798 - rightLayer1_loss: 1.1883 - leftLayer2_loss: 0.0817 - midLayer2_loss: 1.5535 - rightLayer2_loss: 1.0079 - val_loss: 5.3656 - val_leftLayer1_loss: 0.1100 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.1643 - val_leftLayer2_loss: 0.0941 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.1422\n",
      "Epoch 10/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 5.2848 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.3791 - rightLayer1_loss: 1.1583 - leftLayer2_loss: 0.0790 - midLayer2_loss: 1.5624 - rightLayer2_loss: 0.9975\n",
      "Epoch 00010: val_loss improved from 5.36558 to 5.31727, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2848 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.3795 - rightLayer1_loss: 1.1579 - leftLayer2_loss: 0.0790 - midLayer2_loss: 1.5623 - rightLayer2_loss: 0.9978 - val_loss: 5.3173 - val_leftLayer1_loss: 0.1080 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.1359 - val_leftLayer2_loss: 0.0920 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.1264\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966/978 [============================>.] - ETA: 0s - loss: 5.2555 - leftLayer1_loss: 0.1065 - midLayer1_loss: 1.3805 - rightLayer1_loss: 1.1337 - leftLayer2_loss: 0.0761 - midLayer2_loss: 1.5618 - rightLayer2_loss: 0.9970\n",
      "Epoch 00011: val_loss improved from 5.31727 to 5.27622, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2558 - leftLayer1_loss: 0.1065 - midLayer1_loss: 1.3807 - rightLayer1_loss: 1.1330 - leftLayer2_loss: 0.0760 - midLayer2_loss: 1.5634 - rightLayer2_loss: 0.9962 - val_loss: 5.2762 - val_leftLayer1_loss: 0.1060 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 1.1122 - val_leftLayer2_loss: 0.0900 - val_midLayer2_loss: 1.4801 - val_rightLayer2_loss: 1.1131\n",
      "22433/22433 [==============================] - 33s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Pneumonia: 0.5547280913154056\n",
      "\n",
      "auprc 0Pneumonia: 0.01602681990259543\n",
      "\n",
      "auroc 1Pneumonia: 0.5454727942345773\n",
      "\n",
      "auprc 1Pneumonia: 0.014795445276586204\n",
      "\n",
      "auroc 2Pneumonia: 0.5206988649631245\n",
      "\n",
      "auprc 2Pneumonia: 0.011223698187168457\n",
      "\n",
      "auroc 3Pneumonia: 0.43368281609214665\n",
      "\n",
      "auprc 3Pneumonia: 0.00898398870752167\n",
      "\n",
      "auroc 4Pneumonia: 0.6096263804364139\n",
      "\n",
      "auprc 4Pneumonia: 0.01632706562177243\n",
      "\n",
      "auroc 5Pneumonia: 0.42720487160493553\n",
      "\n",
      "auprc 5Pneumonia: 0.008953250072646845\n",
      "\n",
      "mean auroc: 0.5152356364411006\n",
      "\n",
      "mean auprc: 0.01271837796138184\n",
      "\n",
      "max auroc: 0.6096263804364139\n",
      "\n",
      "max auprc: 0.01632706562177243\n",
      "\n",
      "65.14554929733276\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "966/978 [============================>.] - ETA: 0s - loss: 6.5873 - leftLayer1_loss: 0.1254 - midLayer1_loss: 1.3309 - rightLayer1_loss: 1.7923 - leftLayer2_loss: 0.1213 - midLayer2_loss: 1.5054 - rightLayer2_loss: 1.7121\n",
      "Epoch 00001: val_loss improved from inf to 6.35399, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 6.5844 - leftLayer1_loss: 0.1254 - midLayer1_loss: 1.3308 - rightLayer1_loss: 1.7916 - leftLayer2_loss: 0.1212 - midLayer2_loss: 1.5054 - rightLayer2_loss: 1.7101 - val_loss: 6.3540 - val_leftLayer1_loss: 0.1238 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.7395 - val_leftLayer2_loss: 0.1207 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.6325\n",
      "Epoch 2/11\n",
      "955/978 [============================>.] - ETA: 0s - loss: 6.1948 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.3297 - rightLayer1_loss: 1.6803 - leftLayer2_loss: 0.1147 - midLayer2_loss: 1.5077 - rightLayer2_loss: 1.4392\n",
      "Epoch 00002: val_loss improved from 6.35399 to 6.08541, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.1893 - leftLayer1_loss: 0.1231 - midLayer1_loss: 1.3297 - rightLayer1_loss: 1.6788 - leftLayer2_loss: 0.1146 - midLayer2_loss: 1.5066 - rightLayer2_loss: 1.4365 - val_loss: 6.0854 - val_leftLayer1_loss: 0.1217 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.6305 - val_leftLayer2_loss: 0.1170 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.4788\n",
      "Epoch 3/11\n",
      "971/978 [============================>.] - ETA: 0s - loss: 5.9154 - leftLayer1_loss: 0.1211 - midLayer1_loss: 1.3307 - rightLayer1_loss: 1.5776 - leftLayer2_loss: 0.1091 - midLayer2_loss: 1.5142 - rightLayer2_loss: 1.2626\n",
      "Epoch 00003: val_loss improved from 6.08541 to 5.87780, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.9144 - leftLayer1_loss: 0.1210 - midLayer1_loss: 1.3307 - rightLayer1_loss: 1.5771 - leftLayer2_loss: 0.1091 - midLayer2_loss: 1.5145 - rightLayer2_loss: 1.2620 - val_loss: 5.8778 - val_leftLayer1_loss: 0.1195 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.5338 - val_leftLayer2_loss: 0.1136 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.3734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 5.7191 - leftLayer1_loss: 0.1189 - midLayer1_loss: 1.3310 - rightLayer1_loss: 1.4904 - leftLayer2_loss: 0.1040 - midLayer2_loss: 1.5129 - rightLayer2_loss: 1.1619\n",
      "Epoch 00004: val_loss improved from 5.87780 to 5.71681, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.7154 - leftLayer1_loss: 0.1189 - midLayer1_loss: 1.3310 - rightLayer1_loss: 1.4895 - leftLayer2_loss: 0.1039 - midLayer2_loss: 1.5114 - rightLayer2_loss: 1.1607 - val_loss: 5.7168 - val_leftLayer1_loss: 0.1175 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.4501 - val_leftLayer2_loss: 0.1104 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.3014\n",
      "Epoch 5/11\n",
      "975/978 [============================>.] - ETA: 0s - loss: 5.5640 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.3300 - rightLayer1_loss: 1.4125 - leftLayer2_loss: 0.0995 - midLayer2_loss: 1.5016 - rightLayer2_loss: 1.1033\n",
      "Epoch 00005: val_loss improved from 5.71681 to 5.58943, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 5.5636 - leftLayer1_loss: 0.1170 - midLayer1_loss: 1.3300 - rightLayer1_loss: 1.4123 - leftLayer2_loss: 0.0995 - midLayer2_loss: 1.5015 - rightLayer2_loss: 1.1031 - val_loss: 5.5894 - val_leftLayer1_loss: 0.1155 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.3788 - val_leftLayer2_loss: 0.1074 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.2503\n",
      "Epoch 6/11\n",
      "963/978 [============================>.] - ETA: 0s - loss: 5.4720 - leftLayer1_loss: 0.1151 - midLayer1_loss: 1.3306 - rightLayer1_loss: 1.3496 - leftLayer2_loss: 0.0950 - midLayer2_loss: 1.5177 - rightLayer2_loss: 1.0640\n",
      "Epoch 00006: val_loss improved from 5.58943 to 5.48655, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 5.4687 - leftLayer1_loss: 0.1151 - midLayer1_loss: 1.3304 - rightLayer1_loss: 1.3486 - leftLayer2_loss: 0.0949 - midLayer2_loss: 1.5168 - rightLayer2_loss: 1.0629 - val_loss: 5.4866 - val_leftLayer1_loss: 0.1135 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.3185 - val_leftLayer2_loss: 0.1046 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.2125\n",
      "Epoch 7/11\n",
      "964/978 [============================>.] - ETA: 0s - loss: 5.3854 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.3320 - rightLayer1_loss: 1.2956 - leftLayer2_loss: 0.0914 - midLayer2_loss: 1.5133 - rightLayer2_loss: 1.0400\n",
      "Epoch 00007: val_loss improved from 5.48655 to 5.40224, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 5.3832 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.3318 - rightLayer1_loss: 1.2947 - leftLayer2_loss: 0.0913 - midLayer2_loss: 1.5131 - rightLayer2_loss: 1.0391 - val_loss: 5.4022 - val_leftLayer1_loss: 0.1116 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.2680 - val_leftLayer2_loss: 0.1019 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.1833\n",
      "Epoch 8/11\n",
      "967/978 [============================>.] - ETA: 0s - loss: 5.3083 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.3303 - rightLayer1_loss: 1.2506 - leftLayer2_loss: 0.0877 - midLayer2_loss: 1.5077 - rightLayer2_loss: 1.0207\n",
      "Epoch 00008: val_loss improved from 5.40224 to 5.33236, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 5.3066 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.3303 - rightLayer1_loss: 1.2499 - leftLayer2_loss: 0.0877 - midLayer2_loss: 1.5075 - rightLayer2_loss: 1.0200 - val_loss: 5.3324 - val_leftLayer1_loss: 0.1097 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.2256 - val_leftLayer2_loss: 0.0995 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.1601\n",
      "Epoch 9/11\n",
      "959/978 [============================>.] - ETA: 0s - loss: 5.2505 - leftLayer1_loss: 0.1095 - midLayer1_loss: 1.3305 - rightLayer1_loss: 1.2122 - leftLayer2_loss: 0.0845 - midLayer2_loss: 1.5066 - rightLayer2_loss: 1.0073\n",
      "Epoch 00009: val_loss improved from 5.33236 to 5.27405, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2480 - leftLayer1_loss: 0.1095 - midLayer1_loss: 1.3304 - rightLayer1_loss: 1.2114 - leftLayer2_loss: 0.0844 - midLayer2_loss: 1.5053 - rightLayer2_loss: 1.0070 - val_loss: 5.2740 - val_leftLayer1_loss: 0.1079 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.1900 - val_leftLayer2_loss: 0.0972 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.1415\n",
      "Epoch 10/11\n",
      "966/978 [============================>.] - ETA: 0s - loss: 5.2060 - leftLayer1_loss: 0.1077 - midLayer1_loss: 1.3303 - rightLayer1_loss: 1.1816 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5066 - rightLayer2_loss: 0.9979\n",
      "Epoch 00010: val_loss improved from 5.27405 to 5.22442, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2045 - leftLayer1_loss: 0.1077 - midLayer1_loss: 1.3302 - rightLayer1_loss: 1.1810 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5062 - rightLayer2_loss: 0.9976 - val_loss: 5.2244 - val_leftLayer1_loss: 0.1062 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.1599 - val_leftLayer2_loss: 0.0950 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.1259\n",
      "Epoch 11/11\n",
      "968/978 [============================>.] - ETA: 0s - loss: 5.1719 - leftLayer1_loss: 0.1060 - midLayer1_loss: 1.3310 - rightLayer1_loss: 1.1543 - leftLayer2_loss: 0.0788 - midLayer2_loss: 1.5123 - rightLayer2_loss: 0.9896\n",
      "Epoch 00011: val_loss improved from 5.22442 to 5.18213, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.1698 - leftLayer1_loss: 0.1060 - midLayer1_loss: 1.3308 - rightLayer1_loss: 1.1535 - leftLayer2_loss: 0.0787 - midLayer2_loss: 1.5122 - rightLayer2_loss: 0.9887 - val_loss: 5.1821 - val_leftLayer1_loss: 0.1045 - val_midLayer1_loss: 1.3230 - val_rightLayer1_loss: 1.1344 - val_leftLayer2_loss: 0.0930 - val_midLayer2_loss: 1.4145 - val_rightLayer2_loss: 1.1128\n",
      "22433/22433 [==============================] - 31s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Pneumonia: 0.43025046264381617\n",
      "\n",
      "auprc 0Pneumonia: 0.008487341117361092\n",
      "\n",
      "auroc 1Pneumonia: 0.43092436402070533\n",
      "\n",
      "auprc 1Pneumonia: 0.00904708430834998\n",
      "\n",
      "auroc 2Pneumonia: 0.47579997623934356\n",
      "\n",
      "auprc 2Pneumonia: 0.009307002954493318\n",
      "\n",
      "auroc 3Pneumonia: 0.5678773614945528\n",
      "\n",
      "auprc 3Pneumonia: 0.013970718619599698\n",
      "\n",
      "auroc 4Pneumonia: 0.6152023137963385\n",
      "\n",
      "auprc 4Pneumonia: 0.01602847414503651\n",
      "\n",
      "auroc 5Pneumonia: 0.46845707682103277\n",
      "\n",
      "auprc 5Pneumonia: 0.009221260575276441\n",
      "\n",
      "mean auroc: 0.4980852591692983\n",
      "\n",
      "mean auprc: 0.011010313620019507\n",
      "\n",
      "max auroc: 0.6152023137963385\n",
      "\n",
      "max auprc: 0.01602847414503651\n",
      "\n",
      "67.0886652469635\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "970/978 [============================>.] - ETA: 0s - loss: 6.5661 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.2984 - rightLayer1_loss: 1.7928 - leftLayer2_loss: 0.1320 - midLayer2_loss: 1.5410 - rightLayer2_loss: 1.6812\n",
      "Epoch 00001: val_loss improved from inf to 6.31963, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 6.5637 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.2986 - rightLayer1_loss: 1.7923 - leftLayer2_loss: 0.1320 - midLayer2_loss: 1.5402 - rightLayer2_loss: 1.6799 - val_loss: 6.3196 - val_leftLayer1_loss: 0.1196 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.7243 - val_leftLayer2_loss: 0.1256 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.6444\n",
      "Epoch 2/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 6.1535 - leftLayer1_loss: 0.1184 - midLayer1_loss: 1.2982 - rightLayer1_loss: 1.6599 - leftLayer2_loss: 0.1256 - midLayer2_loss: 1.5285 - rightLayer2_loss: 1.4228\n",
      "Epoch 00002: val_loss improved from 6.31963 to 6.03573, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.1505 - leftLayer1_loss: 0.1183 - midLayer1_loss: 1.2989 - rightLayer1_loss: 1.6589 - leftLayer2_loss: 0.1255 - midLayer2_loss: 1.5281 - rightLayer2_loss: 1.4208 - val_loss: 6.0357 - val_leftLayer1_loss: 0.1172 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.5969 - val_leftLayer2_loss: 0.1217 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.4943\n",
      "Epoch 3/11\n",
      "965/978 [============================>.] - ETA: 0s - loss: 5.8726 - leftLayer1_loss: 0.1159 - midLayer1_loss: 1.2991 - rightLayer1_loss: 1.5429 - leftLayer2_loss: 0.1191 - midLayer2_loss: 1.5384 - rightLayer2_loss: 1.2572\n",
      "Epoch 00003: val_loss improved from 6.03573 to 5.81671, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.8706 - leftLayer1_loss: 0.1159 - midLayer1_loss: 1.2995 - rightLayer1_loss: 1.5420 - leftLayer2_loss: 0.1190 - midLayer2_loss: 1.5383 - rightLayer2_loss: 1.2560 - val_loss: 5.8167 - val_leftLayer1_loss: 0.1148 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.4877 - val_leftLayer2_loss: 0.1179 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.3906\n",
      "Epoch 4/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 5.6625 - leftLayer1_loss: 0.1136 - midLayer1_loss: 1.2985 - rightLayer1_loss: 1.4439 - leftLayer2_loss: 0.1139 - midLayer2_loss: 1.5334 - rightLayer2_loss: 1.1592\n",
      "Epoch 00004: val_loss improved from 5.81671 to 5.64828, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.6611 - leftLayer1_loss: 0.1135 - midLayer1_loss: 1.2993 - rightLayer1_loss: 1.4430 - leftLayer2_loss: 0.1138 - midLayer2_loss: 1.5327 - rightLayer2_loss: 1.1586 - val_loss: 5.6483 - val_leftLayer1_loss: 0.1125 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.3969 - val_leftLayer2_loss: 0.1143 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.3188\n",
      "Epoch 5/11\n",
      "977/978 [============================>.] - ETA: 0s - loss: 5.5155 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.2998 - rightLayer1_loss: 1.3627 - leftLayer2_loss: 0.1083 - midLayer2_loss: 1.5303 - rightLayer2_loss: 1.1031\n",
      "Epoch 00005: val_loss improved from 5.64828 to 5.51761, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5148 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.2998 - rightLayer1_loss: 1.3626 - leftLayer2_loss: 0.1083 - midLayer2_loss: 1.5300 - rightLayer2_loss: 1.1028 - val_loss: 5.5176 - val_leftLayer1_loss: 0.1102 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.3230 - val_leftLayer2_loss: 0.1110 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.2677\n",
      "Epoch 6/11\n",
      "968/978 [============================>.] - ETA: 0s - loss: 5.4148 - leftLayer1_loss: 0.1092 - midLayer1_loss: 1.2981 - rightLayer1_loss: 1.2976 - leftLayer2_loss: 0.1032 - midLayer2_loss: 1.5375 - rightLayer2_loss: 1.0692\n",
      "Epoch 00006: val_loss improved from 5.51761 to 5.41391, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4119 - leftLayer1_loss: 0.1092 - midLayer1_loss: 1.2985 - rightLayer1_loss: 1.2968 - leftLayer2_loss: 0.1031 - midLayer2_loss: 1.5358 - rightLayer2_loss: 1.0685 - val_loss: 5.4139 - val_leftLayer1_loss: 0.1081 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.2631 - val_leftLayer2_loss: 0.1079 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.2291\n",
      "Epoch 7/11\n",
      "977/978 [============================>.] - ETA: 0s - loss: 5.3208 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.2985 - rightLayer1_loss: 1.2427 - leftLayer2_loss: 0.0983 - midLayer2_loss: 1.5316 - rightLayer2_loss: 1.0425\n",
      "Epoch 00007: val_loss improved from 5.41391 to 5.33090, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3203 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.2985 - rightLayer1_loss: 1.2426 - leftLayer2_loss: 0.0983 - midLayer2_loss: 1.5315 - rightLayer2_loss: 1.0422 - val_loss: 5.3309 - val_leftLayer1_loss: 0.1060 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.2146 - val_leftLayer2_loss: 0.1049 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.1997\n",
      "Epoch 8/11\n",
      "973/978 [============================>.] - ETA: 0s - loss: 5.2588 - leftLayer1_loss: 0.1050 - midLayer1_loss: 1.2970 - rightLayer1_loss: 1.2014 - leftLayer2_loss: 0.0946 - midLayer2_loss: 1.5372 - rightLayer2_loss: 1.0235\n",
      "Epoch 00008: val_loss improved from 5.33090 to 5.26342, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2577 - leftLayer1_loss: 0.1050 - midLayer1_loss: 1.2972 - rightLayer1_loss: 1.2010 - leftLayer2_loss: 0.0946 - midLayer2_loss: 1.5368 - rightLayer2_loss: 1.0231 - val_loss: 5.2634 - val_leftLayer1_loss: 0.1040 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.1753 - val_leftLayer2_loss: 0.1022 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.1763\n",
      "Epoch 9/11\n",
      "964/978 [============================>.] - ETA: 0s - loss: 5.1991 - leftLayer1_loss: 0.1032 - midLayer1_loss: 1.2976 - rightLayer1_loss: 1.1663 - leftLayer2_loss: 0.0908 - midLayer2_loss: 1.5302 - rightLayer2_loss: 1.0109\n",
      "Epoch 00009: val_loss improved from 5.26342 to 5.20769, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.1975 - leftLayer1_loss: 0.1031 - midLayer1_loss: 1.2980 - rightLayer1_loss: 1.1655 - leftLayer2_loss: 0.0907 - midLayer2_loss: 1.5300 - rightLayer2_loss: 1.0102 - val_loss: 5.2077 - val_leftLayer1_loss: 0.1020 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.1431 - val_leftLayer2_loss: 0.0996 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.1573\n",
      "Epoch 10/11\n",
      "969/978 [============================>.] - ETA: 0s - loss: 5.1595 - leftLayer1_loss: 0.1012 - midLayer1_loss: 1.2985 - rightLayer1_loss: 1.1366 - leftLayer2_loss: 0.0878 - midLayer2_loss: 1.5364 - rightLayer2_loss: 0.9990\n",
      "Epoch 00010: val_loss improved from 5.20769 to 5.16101, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.1580 - leftLayer1_loss: 0.1012 - midLayer1_loss: 1.2989 - rightLayer1_loss: 1.1360 - leftLayer2_loss: 0.0878 - midLayer2_loss: 1.5360 - rightLayer2_loss: 0.9981 - val_loss: 5.1610 - val_leftLayer1_loss: 0.1001 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.1166 - val_leftLayer2_loss: 0.0972 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.1415\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962/978 [============================>.] - ETA: 0s - loss: 5.1226 - leftLayer1_loss: 0.0994 - midLayer1_loss: 1.2981 - rightLayer1_loss: 1.1131 - leftLayer2_loss: 0.0837 - midLayer2_loss: 1.5367 - rightLayer2_loss: 0.9915\n",
      "Epoch 00011: val_loss improved from 5.16101 to 5.12141, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.1216 - leftLayer1_loss: 0.0994 - midLayer1_loss: 1.2987 - rightLayer1_loss: 1.1125 - leftLayer2_loss: 0.0837 - midLayer2_loss: 1.5359 - rightLayer2_loss: 0.9914 - val_loss: 5.1214 - val_leftLayer1_loss: 0.0983 - val_midLayer1_loss: 1.2882 - val_rightLayer1_loss: 1.0944 - val_leftLayer2_loss: 0.0949 - val_midLayer2_loss: 1.4175 - val_rightLayer2_loss: 1.1281\n",
      "22433/22433 [==============================] - 32s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Pneumonia: 0.4819689949503019\n",
      "\n",
      "auprc 0Pneumonia: 0.010831199054053307\n",
      "\n",
      "auroc 1Pneumonia: 0.48065927255893703\n",
      "\n",
      "auprc 1Pneumonia: 0.009722917523186244\n",
      "\n",
      "auroc 2Pneumonia: 0.43382750284811317\n",
      "\n",
      "auprc 2Pneumonia: 0.009109151051385796\n",
      "\n",
      "auroc 3Pneumonia: 0.5119435472127596\n",
      "\n",
      "auprc 3Pneumonia: 0.011025147612386894\n",
      "\n",
      "auroc 4Pneumonia: 0.5579096171443191\n",
      "\n",
      "auprc 4Pneumonia: 0.012776627128304413\n",
      "\n",
      "auroc 5Pneumonia: 0.5368356280243163\n",
      "\n",
      "auprc 5Pneumonia: 0.011221600061604095\n",
      "\n",
      "mean auroc: 0.5005240937897911\n",
      "\n",
      "mean auprc: 0.010781107071820126\n",
      "\n",
      "max auroc: 0.5579096171443191\n",
      "\n",
      "max auprc: 0.012776627128304413\n",
      "\n",
      "63.489160776138306\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "973/978 [============================>.] - ETA: 0s - loss: 6.7819 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.4581 - rightLayer1_loss: 1.7705 - leftLayer2_loss: 0.1269 - midLayer2_loss: 1.5665 - rightLayer2_loss: 1.7393\n",
      "Epoch 00001: val_loss improved from inf to 6.49455, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 6.7808 - leftLayer1_loss: 0.1206 - midLayer1_loss: 1.4578 - rightLayer1_loss: 1.7701 - leftLayer2_loss: 0.1269 - midLayer2_loss: 1.5669 - rightLayer2_loss: 1.7385 - val_loss: 6.4945 - val_leftLayer1_loss: 0.1191 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.6925 - val_leftLayer2_loss: 0.1251 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.6810\n",
      "Epoch 2/11\n",
      "971/978 [============================>.] - ETA: 0s - loss: 6.3613 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4560 - rightLayer1_loss: 1.6330 - leftLayer2_loss: 0.1203 - midLayer2_loss: 1.5723 - rightLayer2_loss: 1.4618\n",
      "Epoch 00002: val_loss improved from 6.49455 to 6.20224, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.3606 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4560 - rightLayer1_loss: 1.6324 - leftLayer2_loss: 0.1202 - midLayer2_loss: 1.5732 - rightLayer2_loss: 1.4608 - val_loss: 6.2022 - val_leftLayer1_loss: 0.1165 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.5611 - val_leftLayer2_loss: 0.1214 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.5264\n",
      "Epoch 3/11\n",
      "976/978 [============================>.] - ETA: 0s - loss: 6.0523 - leftLayer1_loss: 0.1155 - midLayer1_loss: 1.4579 - rightLayer1_loss: 1.5137 - leftLayer2_loss: 0.1153 - midLayer2_loss: 1.5689 - rightLayer2_loss: 1.2810\n",
      "Epoch 00003: val_loss improved from 6.20224 to 5.97764, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.0524 - leftLayer1_loss: 0.1155 - midLayer1_loss: 1.4579 - rightLayer1_loss: 1.5135 - leftLayer2_loss: 0.1153 - midLayer2_loss: 1.5693 - rightLayer2_loss: 1.2810 - val_loss: 5.9776 - val_leftLayer1_loss: 0.1140 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.4503 - val_leftLayer2_loss: 0.1179 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.4186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "965/978 [============================>.] - ETA: 0s - loss: 5.8504 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.4558 - rightLayer1_loss: 1.4160 - leftLayer2_loss: 0.1101 - midLayer2_loss: 1.5775 - rightLayer2_loss: 1.1779\n",
      "Epoch 00004: val_loss improved from 5.97764 to 5.80599, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 5.8499 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.4558 - rightLayer1_loss: 1.4152 - leftLayer2_loss: 0.1101 - midLayer2_loss: 1.5781 - rightLayer2_loss: 1.1777 - val_loss: 5.8060 - val_leftLayer1_loss: 0.1115 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.3598 - val_leftLayer2_loss: 0.1146 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.3431\n",
      "Epoch 5/11\n",
      "963/978 [============================>.] - ETA: 0s - loss: 5.7028 - leftLayer1_loss: 0.1108 - midLayer1_loss: 1.4571 - rightLayer1_loss: 1.3356 - leftLayer2_loss: 0.1047 - midLayer2_loss: 1.5756 - rightLayer2_loss: 1.1189\n",
      "Epoch 00005: val_loss improved from 5.80599 to 5.67373, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.7009 - leftLayer1_loss: 0.1107 - midLayer1_loss: 1.4568 - rightLayer1_loss: 1.3346 - leftLayer2_loss: 0.1047 - midLayer2_loss: 1.5762 - rightLayer2_loss: 1.1179 - val_loss: 5.6737 - val_leftLayer1_loss: 0.1092 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.2874 - val_leftLayer2_loss: 0.1115 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.2887\n",
      "Epoch 6/11\n",
      "972/978 [============================>.] - ETA: 0s - loss: 5.5829 - leftLayer1_loss: 0.1086 - midLayer1_loss: 1.4549 - rightLayer1_loss: 1.2699 - leftLayer2_loss: 0.1004 - midLayer2_loss: 1.5743 - rightLayer2_loss: 1.0748\n",
      "Epoch 00006: val_loss improved from 5.67373 to 5.57010, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5821 - leftLayer1_loss: 0.1086 - midLayer1_loss: 1.4547 - rightLayer1_loss: 1.2695 - leftLayer2_loss: 0.1004 - midLayer2_loss: 1.5742 - rightLayer2_loss: 1.0747 - val_loss: 5.5701 - val_leftLayer1_loss: 0.1069 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.2296 - val_leftLayer2_loss: 0.1086 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.2481\n",
      "Epoch 7/11\n",
      "969/978 [============================>.] - ETA: 0s - loss: 5.4936 - leftLayer1_loss: 0.1064 - midLayer1_loss: 1.4566 - rightLayer1_loss: 1.2198 - leftLayer2_loss: 0.0964 - midLayer2_loss: 1.5627 - rightLayer2_loss: 1.0518\n",
      "Epoch 00007: val_loss improved from 5.57010 to 5.48757, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4927 - leftLayer1_loss: 0.1063 - midLayer1_loss: 1.4563 - rightLayer1_loss: 1.2191 - leftLayer2_loss: 0.0964 - midLayer2_loss: 1.5636 - rightLayer2_loss: 1.0510 - val_loss: 5.4876 - val_leftLayer1_loss: 0.1047 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.1834 - val_leftLayer2_loss: 0.1059 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.2166\n",
      "Epoch 8/11\n",
      "961/978 [============================>.] - ETA: 0s - loss: 5.4408 - leftLayer1_loss: 0.1043 - midLayer1_loss: 1.4576 - rightLayer1_loss: 1.1793 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.5797 - rightLayer2_loss: 1.0279\n",
      "Epoch 00008: val_loss improved from 5.48757 to 5.42074, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4416 - leftLayer1_loss: 0.1042 - midLayer1_loss: 1.4576 - rightLayer1_loss: 1.1790 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.5809 - rightLayer2_loss: 1.0278 - val_loss: 5.4207 - val_leftLayer1_loss: 0.1026 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.1464 - val_leftLayer2_loss: 0.1033 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.1915\n",
      "Epoch 9/11\n",
      "963/978 [============================>.] - ETA: 0s - loss: 5.3806 - leftLayer1_loss: 0.1022 - midLayer1_loss: 1.4575 - rightLayer1_loss: 1.1462 - leftLayer2_loss: 0.0888 - midLayer2_loss: 1.5723 - rightLayer2_loss: 1.0136\n",
      "Epoch 00009: val_loss improved from 5.42074 to 5.36587, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3795 - leftLayer1_loss: 0.1021 - midLayer1_loss: 1.4574 - rightLayer1_loss: 1.1452 - leftLayer2_loss: 0.0888 - midLayer2_loss: 1.5727 - rightLayer2_loss: 1.0132 - val_loss: 5.3659 - val_leftLayer1_loss: 0.1006 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.1164 - val_leftLayer2_loss: 0.1009 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.1710\n",
      "Epoch 10/11\n",
      "974/978 [============================>.] - ETA: 0s - loss: 5.3383 - leftLayer1_loss: 0.1003 - midLayer1_loss: 1.4572 - rightLayer1_loss: 1.1184 - leftLayer2_loss: 0.0854 - midLayer2_loss: 1.5740 - rightLayer2_loss: 1.0030\n",
      "Epoch 00010: val_loss improved from 5.36587 to 5.32023, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3384 - leftLayer1_loss: 0.1003 - midLayer1_loss: 1.4572 - rightLayer1_loss: 1.1181 - leftLayer2_loss: 0.0854 - midLayer2_loss: 1.5742 - rightLayer2_loss: 1.0032 - val_loss: 5.3202 - val_leftLayer1_loss: 0.0987 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.0919 - val_leftLayer2_loss: 0.0987 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.1541\n",
      "Epoch 11/11\n",
      "974/978 [============================>.] - ETA: 0s - loss: 5.2990 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.4555 - rightLayer1_loss: 1.0971 - leftLayer2_loss: 0.0825 - midLayer2_loss: 1.5710 - rightLayer2_loss: 0.9946\n",
      "Epoch 00011: val_loss improved from 5.32023 to 5.28130, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2998 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.4555 - rightLayer1_loss: 1.0969 - leftLayer2_loss: 0.0825 - midLayer2_loss: 1.5719 - rightLayer2_loss: 0.9947 - val_loss: 5.2813 - val_leftLayer1_loss: 0.0968 - val_midLayer1_loss: 1.4346 - val_rightLayer1_loss: 1.0715 - val_leftLayer2_loss: 0.0965 - val_midLayer2_loss: 1.4423 - val_rightLayer2_loss: 1.1396\n",
      "22433/22433 [==============================] - 34s 2ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Pneumonia: 0.438587455043758\n",
      "\n",
      "auprc 0Pneumonia: 0.008722089844967628\n",
      "\n",
      "auroc 1Pneumonia: 0.3712862336044953\n",
      "\n",
      "auprc 1Pneumonia: 0.007897538725508897\n",
      "\n",
      "auroc 2Pneumonia: 0.5399390379019713\n",
      "\n",
      "auprc 2Pneumonia: 0.011536957169389846\n",
      "\n",
      "auroc 3Pneumonia: 0.2915636448549055\n",
      "\n",
      "auprc 3Pneumonia: 0.007218031315916739\n",
      "\n",
      "auroc 4Pneumonia: 0.2659432887504464\n",
      "\n",
      "auprc 4Pneumonia: 0.006806660485962863\n",
      "\n",
      "auroc 5Pneumonia: 0.377237104909257\n",
      "\n",
      "auprc 5Pneumonia: 0.007883540712659934\n",
      "\n",
      "mean auroc: 0.3807594608441389\n",
      "\n",
      "mean auprc: 0.008344136375734317\n",
      "\n",
      "max auroc: 0.5399390379019713\n",
      "\n",
      "max auprc: 0.011536957169389846\n",
      "\n",
      "65.95426106452942\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "975/978 [============================>.] - ETA: 0s - loss: 6.7955 - leftLayer1_loss: 0.1333 - midLayer1_loss: 1.4460 - rightLayer1_loss: 1.8062 - leftLayer2_loss: 0.1206 - midLayer2_loss: 1.5905 - rightLayer2_loss: 1.6988\n",
      "Epoch 00001: val_loss improved from inf to 6.56891, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 6.7951 - leftLayer1_loss: 0.1333 - midLayer1_loss: 1.4462 - rightLayer1_loss: 1.8059 - leftLayer2_loss: 0.1206 - midLayer2_loss: 1.5907 - rightLayer2_loss: 1.6983 - val_loss: 6.5689 - val_leftLayer1_loss: 0.1324 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.7360 - val_leftLayer2_loss: 0.1201 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.6623\n",
      "Epoch 2/11\n",
      "973/978 [============================>.] - ETA: 0s - loss: 6.4205 - leftLayer1_loss: 0.1308 - midLayer1_loss: 1.4462 - rightLayer1_loss: 1.6834 - leftLayer2_loss: 0.1148 - midLayer2_loss: 1.6011 - rightLayer2_loss: 1.4442\n",
      "Epoch 00002: val_loss improved from 6.56891 to 6.30290, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.4191 - leftLayer1_loss: 0.1308 - midLayer1_loss: 1.4464 - rightLayer1_loss: 1.6829 - leftLayer2_loss: 0.1148 - midLayer2_loss: 1.6008 - rightLayer2_loss: 1.4435 - val_loss: 6.3029 - val_leftLayer1_loss: 0.1299 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.6190 - val_leftLayer2_loss: 0.1168 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.5192\n",
      "Epoch 3/11\n",
      "959/978 [============================>.] - ETA: 0s - loss: 6.1364 - leftLayer1_loss: 0.1282 - midLayer1_loss: 1.4468 - rightLayer1_loss: 1.5742 - leftLayer2_loss: 0.1102 - midLayer2_loss: 1.5966 - rightLayer2_loss: 1.2805\n",
      "Epoch 00003: val_loss improved from 6.30290 to 6.09355, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.1340 - leftLayer1_loss: 0.1282 - midLayer1_loss: 1.4471 - rightLayer1_loss: 1.5728 - leftLayer2_loss: 0.1102 - midLayer2_loss: 1.5965 - rightLayer2_loss: 1.2792 - val_loss: 6.0936 - val_leftLayer1_loss: 0.1274 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.5164 - val_leftLayer2_loss: 0.1137 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.4180\n",
      "Epoch 4/11\n",
      "976/978 [============================>.] - ETA: 0s - loss: 5.9228 - leftLayer1_loss: 0.1258 - midLayer1_loss: 1.4465 - rightLayer1_loss: 1.4776 - leftLayer2_loss: 0.1051 - midLayer2_loss: 1.5908 - rightLayer2_loss: 1.1769\n",
      "Epoch 00004: val_loss improved from 6.09355 to 5.92868, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.9224 - leftLayer1_loss: 0.1258 - midLayer1_loss: 1.4467 - rightLayer1_loss: 1.4774 - leftLayer2_loss: 0.1051 - midLayer2_loss: 1.5907 - rightLayer2_loss: 1.1768 - val_loss: 5.9287 - val_leftLayer1_loss: 0.1250 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.4290 - val_leftLayer2_loss: 0.1107 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.3459\n",
      "Epoch 5/11\n",
      "973/978 [============================>.] - ETA: 0s - loss: 5.7847 - leftLayer1_loss: 0.1235 - midLayer1_loss: 1.4468 - rightLayer1_loss: 1.3987 - leftLayer2_loss: 0.1002 - midLayer2_loss: 1.5966 - rightLayer2_loss: 1.1188\n",
      "Epoch 00005: val_loss improved from 5.92868 to 5.79839, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.7836 - leftLayer1_loss: 0.1235 - midLayer1_loss: 1.4470 - rightLayer1_loss: 1.3981 - leftLayer2_loss: 0.1002 - midLayer2_loss: 1.5964 - rightLayer2_loss: 1.1184 - val_loss: 5.7984 - val_leftLayer1_loss: 0.1227 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.3558 - val_leftLayer2_loss: 0.1080 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.2939\n",
      "Epoch 6/11\n",
      "965/978 [============================>.] - ETA: 0s - loss: 5.6698 - leftLayer1_loss: 0.1212 - midLayer1_loss: 1.4469 - rightLayer1_loss: 1.3314 - leftLayer2_loss: 0.0970 - midLayer2_loss: 1.5981 - rightLayer2_loss: 1.0753\n",
      "Epoch 00006: val_loss improved from 5.79839 to 5.69386, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.6681 - leftLayer1_loss: 0.1212 - midLayer1_loss: 1.4470 - rightLayer1_loss: 1.3303 - leftLayer2_loss: 0.0970 - midLayer2_loss: 1.5979 - rightLayer2_loss: 1.0746 - val_loss: 5.6939 - val_leftLayer1_loss: 0.1204 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.2952 - val_leftLayer2_loss: 0.1054 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.2548\n",
      "Epoch 7/11\n",
      "975/978 [============================>.] - ETA: 0s - loss: 5.5830 - leftLayer1_loss: 0.1190 - midLayer1_loss: 1.4457 - rightLayer1_loss: 1.2761 - leftLayer2_loss: 0.0927 - midLayer2_loss: 1.5994 - rightLayer2_loss: 1.0502\n",
      "Epoch 00007: val_loss improved from 5.69386 to 5.60901, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5828 - leftLayer1_loss: 0.1190 - midLayer1_loss: 1.4460 - rightLayer1_loss: 1.2758 - leftLayer2_loss: 0.0927 - midLayer2_loss: 1.5992 - rightLayer2_loss: 1.0502 - val_loss: 5.6090 - val_leftLayer1_loss: 0.1182 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.2454 - val_leftLayer2_loss: 0.1029 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.2245\n",
      "Epoch 8/11\n",
      "964/978 [============================>.] - ETA: 0s - loss: 5.5138 - leftLayer1_loss: 0.1167 - midLayer1_loss: 1.4480 - rightLayer1_loss: 1.2315 - leftLayer2_loss: 0.0890 - midLayer2_loss: 1.5983 - rightLayer2_loss: 1.0303\n",
      "Epoch 00008: val_loss improved from 5.60901 to 5.53919, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 5.5121 - leftLayer1_loss: 0.1167 - midLayer1_loss: 1.4481 - rightLayer1_loss: 1.2303 - leftLayer2_loss: 0.0890 - midLayer2_loss: 1.5983 - rightLayer2_loss: 1.0297 - val_loss: 5.5392 - val_leftLayer1_loss: 0.1160 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.2042 - val_leftLayer2_loss: 0.1006 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.2003\n",
      "Epoch 9/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 5.4495 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.4464 - rightLayer1_loss: 1.1941 - leftLayer2_loss: 0.0861 - midLayer2_loss: 1.5935 - rightLayer2_loss: 1.0147\n",
      "Epoch 00009: val_loss improved from 5.53919 to 5.48082, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4499 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.4472 - rightLayer1_loss: 1.1931 - leftLayer2_loss: 0.0861 - midLayer2_loss: 1.5939 - rightLayer2_loss: 1.0150 - val_loss: 5.4808 - val_leftLayer1_loss: 0.1139 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.1700 - val_leftLayer2_loss: 0.0985 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.1804\n",
      "Epoch 10/11\n",
      "961/978 [============================>.] - ETA: 0s - loss: 5.3973 - leftLayer1_loss: 0.1126 - midLayer1_loss: 1.4460 - rightLayer1_loss: 1.1631 - leftLayer2_loss: 0.0834 - midLayer2_loss: 1.5901 - rightLayer2_loss: 1.0021\n",
      "Epoch 00010: val_loss improved from 5.48082 to 5.43173, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3979 - leftLayer1_loss: 0.1126 - midLayer1_loss: 1.4465 - rightLayer1_loss: 1.1624 - leftLayer2_loss: 0.0833 - midLayer2_loss: 1.5909 - rightLayer2_loss: 1.0023 - val_loss: 5.4317 - val_leftLayer1_loss: 0.1119 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.1414 - val_leftLayer2_loss: 0.0964 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.1639\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973/978 [============================>.] - ETA: 0s - loss: 5.3676 - leftLayer1_loss: 0.1106 - midLayer1_loss: 1.4470 - rightLayer1_loss: 1.1359 - leftLayer2_loss: 0.0806 - midLayer2_loss: 1.5987 - rightLayer2_loss: 0.9946\n",
      "Epoch 00011: val_loss improved from 5.43173 to 5.38986, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3665 - leftLayer1_loss: 0.1106 - midLayer1_loss: 1.4472 - rightLayer1_loss: 1.1354 - leftLayer2_loss: 0.0806 - midLayer2_loss: 1.5985 - rightLayer2_loss: 0.9942 - val_loss: 5.3899 - val_leftLayer1_loss: 0.1099 - val_midLayer1_loss: 1.4518 - val_rightLayer1_loss: 1.1174 - val_leftLayer2_loss: 0.0945 - val_midLayer2_loss: 1.4662 - val_rightLayer2_loss: 1.1499\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Pneumonia: 0.4013469089359807\n",
      "\n",
      "auprc 0Pneumonia: 0.008203007100559262\n",
      "\n",
      "auroc 1Pneumonia: 0.4397747430180726\n",
      "\n",
      "auprc 1Pneumonia: 0.008794083145345237\n",
      "\n",
      "auroc 2Pneumonia: 0.5185016559836819\n",
      "\n",
      "auprc 2Pneumonia: 0.011050883014993226\n",
      "\n",
      "auroc 3Pneumonia: 0.47723474001633454\n",
      "\n",
      "auprc 3Pneumonia: 0.009608791213055976\n",
      "\n",
      "auroc 4Pneumonia: 0.5534654805704494\n",
      "\n",
      "auprc 4Pneumonia: 0.012052258824981375\n",
      "\n",
      "auroc 5Pneumonia: 0.435903487788773\n",
      "\n",
      "auprc 5Pneumonia: 0.009522799075948385\n",
      "\n",
      "mean auroc: 0.4710378360522154\n",
      "\n",
      "mean auprc: 0.00987197039581391\n",
      "\n",
      "max auroc: 0.5534654805704494\n",
      "\n",
      "max auprc: 0.012052258824981375\n",
      "\n",
      "62.64890146255493\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 978 steps, validate for 133 steps\n",
      "Epoch 1/11\n",
      "965/978 [============================>.] - ETA: 0s - loss: 6.8467 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.4307 - rightLayer1_loss: 1.8045 - leftLayer2_loss: 0.1309 - midLayer2_loss: 1.5787 - rightLayer2_loss: 1.7787\n",
      "Epoch 00001: val_loss improved from inf to 6.54988, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 4ms/step - loss: 6.8450 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.4311 - rightLayer1_loss: 1.8037 - leftLayer2_loss: 0.1309 - midLayer2_loss: 1.5796 - rightLayer2_loss: 1.7765 - val_loss: 6.5499 - val_leftLayer1_loss: 0.1222 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.7278 - val_leftLayer2_loss: 0.1251 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.6676\n",
      "Epoch 2/11\n",
      "969/978 [============================>.] - ETA: 0s - loss: 6.3966 - leftLayer1_loss: 0.1209 - midLayer1_loss: 1.4294 - rightLayer1_loss: 1.6764 - leftLayer2_loss: 0.1238 - midLayer2_loss: 1.5703 - rightLayer2_loss: 1.4758\n",
      "Epoch 00002: val_loss improved from 6.54988 to 6.24610, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.3955 - leftLayer1_loss: 0.1209 - midLayer1_loss: 1.4298 - rightLayer1_loss: 1.6757 - leftLayer2_loss: 0.1238 - midLayer2_loss: 1.5706 - rightLayer2_loss: 1.4746 - val_loss: 6.2461 - val_leftLayer1_loss: 0.1198 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.6044 - val_leftLayer2_loss: 0.1208 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.4939\n",
      "Epoch 3/11\n",
      "959/978 [============================>.] - ETA: 0s - loss: 6.0798 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.4309 - rightLayer1_loss: 1.5626 - leftLayer2_loss: 0.1179 - midLayer2_loss: 1.5681 - rightLayer2_loss: 1.2818\n",
      "Epoch 00003: val_loss improved from 6.24610 to 6.01561, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 6.0803 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.4320 - rightLayer1_loss: 1.5614 - leftLayer2_loss: 0.1178 - midLayer2_loss: 1.5703 - rightLayer2_loss: 1.2802 - val_loss: 6.0156 - val_leftLayer1_loss: 0.1175 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.4972 - val_leftLayer2_loss: 0.1168 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "960/978 [============================>.] - ETA: 0s - loss: 5.8595 - leftLayer1_loss: 0.1163 - midLayer1_loss: 1.4288 - rightLayer1_loss: 1.4648 - leftLayer2_loss: 0.1121 - midLayer2_loss: 1.5647 - rightLayer2_loss: 1.1728\n",
      "Epoch 00004: val_loss improved from 6.01561 to 5.84054, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.8607 - leftLayer1_loss: 0.1163 - midLayer1_loss: 1.4301 - rightLayer1_loss: 1.4638 - leftLayer2_loss: 0.1121 - midLayer2_loss: 1.5662 - rightLayer2_loss: 1.1722 - val_loss: 5.8405 - val_leftLayer1_loss: 0.1152 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.4066 - val_leftLayer2_loss: 0.1130 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.2985\n",
      "Epoch 5/11\n",
      "967/978 [============================>.] - ETA: 0s - loss: 5.7163 - leftLayer1_loss: 0.1140 - midLayer1_loss: 1.4309 - rightLayer1_loss: 1.3816 - leftLayer2_loss: 0.1067 - midLayer2_loss: 1.5735 - rightLayer2_loss: 1.1096\n",
      "Epoch 00005: val_loss improved from 5.84054 to 5.70550, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.7155 - leftLayer1_loss: 0.1140 - midLayer1_loss: 1.4315 - rightLayer1_loss: 1.3809 - leftLayer2_loss: 0.1066 - midLayer2_loss: 1.5739 - rightLayer2_loss: 1.1086 - val_loss: 5.7055 - val_leftLayer1_loss: 0.1130 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.3320 - val_leftLayer2_loss: 0.1094 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.2439\n",
      "Epoch 6/11\n",
      "970/978 [============================>.] - ETA: 0s - loss: 5.5989 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.4317 - rightLayer1_loss: 1.3153 - leftLayer2_loss: 0.1012 - midLayer2_loss: 1.5696 - rightLayer2_loss: 1.0690\n",
      "Epoch 00006: val_loss improved from 5.70550 to 5.59908, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5978 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.4318 - rightLayer1_loss: 1.3147 - leftLayer2_loss: 0.1011 - midLayer2_loss: 1.5701 - rightLayer2_loss: 1.0682 - val_loss: 5.5991 - val_leftLayer1_loss: 0.1109 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.2709 - val_leftLayer2_loss: 0.1061 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.2040\n",
      "Epoch 7/11\n",
      "958/978 [============================>.] - ETA: 0s - loss: 5.5110 - leftLayer1_loss: 0.1099 - midLayer1_loss: 1.4297 - rightLayer1_loss: 1.2604 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.5735 - rightLayer2_loss: 1.0413\n",
      "Epoch 00007: val_loss improved from 5.59908 to 5.51446, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.5123 - leftLayer1_loss: 0.1098 - midLayer1_loss: 1.4311 - rightLayer1_loss: 1.2597 - leftLayer2_loss: 0.0962 - midLayer2_loss: 1.5749 - rightLayer2_loss: 1.0406 - val_loss: 5.5145 - val_leftLayer1_loss: 0.1089 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.2211 - val_leftLayer2_loss: 0.1031 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.1743\n",
      "Epoch 8/11\n",
      "962/978 [============================>.] - ETA: 0s - loss: 5.4357 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.4299 - rightLayer1_loss: 1.2158 - leftLayer2_loss: 0.0930 - midLayer2_loss: 1.5649 - rightLayer2_loss: 1.0243\n",
      "Epoch 00008: val_loss improved from 5.51446 to 5.44546, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.4366 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.4310 - rightLayer1_loss: 1.2152 - leftLayer2_loss: 0.0930 - midLayer2_loss: 1.5655 - rightLayer2_loss: 1.0239 - val_loss: 5.4455 - val_leftLayer1_loss: 0.1069 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.1804 - val_leftLayer2_loss: 0.1002 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.1508\n",
      "Epoch 9/11\n",
      "963/978 [============================>.] - ETA: 0s - loss: 5.3820 - leftLayer1_loss: 0.1059 - midLayer1_loss: 1.4307 - rightLayer1_loss: 1.1790 - leftLayer2_loss: 0.0885 - midLayer2_loss: 1.5689 - rightLayer2_loss: 1.0089\n",
      "Epoch 00009: val_loss improved from 5.44546 to 5.38868, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3821 - leftLayer1_loss: 0.1059 - midLayer1_loss: 1.4314 - rightLayer1_loss: 1.1782 - leftLayer2_loss: 0.0885 - midLayer2_loss: 1.5698 - rightLayer2_loss: 1.0083 - val_loss: 5.3887 - val_leftLayer1_loss: 0.1049 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.1470 - val_leftLayer2_loss: 0.0976 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.1320\n",
      "Epoch 10/11\n",
      "971/978 [============================>.] - ETA: 0s - loss: 5.3370 - leftLayer1_loss: 0.1040 - midLayer1_loss: 1.4303 - rightLayer1_loss: 1.1485 - leftLayer2_loss: 0.0852 - midLayer2_loss: 1.5720 - rightLayer2_loss: 0.9969\n",
      "Epoch 00010: val_loss improved from 5.38868 to 5.34129, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.3365 - leftLayer1_loss: 0.1040 - midLayer1_loss: 1.4306 - rightLayer1_loss: 1.1480 - leftLayer2_loss: 0.0852 - midLayer2_loss: 1.5722 - rightLayer2_loss: 0.9965 - val_loss: 5.3413 - val_leftLayer1_loss: 0.1030 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.1194 - val_leftLayer2_loss: 0.0951 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.1166\n",
      "Epoch 11/11\n",
      "969/978 [============================>.] - ETA: 0s - loss: 5.2968 - leftLayer1_loss: 0.1023 - midLayer1_loss: 1.4312 - rightLayer1_loss: 1.1240 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5650 - rightLayer2_loss: 0.9925\n",
      "Epoch 00011: val_loss improved from 5.34129 to 5.30116, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "978/978 [==============================] - 3s 3ms/step - loss: 5.2956 - leftLayer1_loss: 0.1023 - midLayer1_loss: 1.4315 - rightLayer1_loss: 1.1233 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5649 - rightLayer2_loss: 0.9917 - val_loss: 5.3012 - val_leftLayer1_loss: 0.1012 - val_midLayer1_loss: 1.4224 - val_rightLayer1_loss: 1.0963 - val_leftLayer2_loss: 0.0928 - val_midLayer2_loss: 1.4848 - val_rightLayer2_loss: 1.1037\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Pneumonia: 0.43459944486466295\n",
      "\n",
      "auprc 0Pneumonia: 0.008714047272532615\n",
      "\n",
      "auroc 1Pneumonia: 0.491367395984747\n",
      "\n",
      "auprc 1Pneumonia: 0.009869957985655783\n",
      "\n",
      "auroc 2Pneumonia: 0.4534259477541152\n",
      "\n",
      "auprc 2Pneumonia: 0.009026812650424449\n",
      "\n",
      "auroc 3Pneumonia: 0.6195349093575647\n",
      "\n",
      "auprc 3Pneumonia: 0.01678852601121239\n",
      "\n",
      "auroc 4Pneumonia: 0.3698029615907871\n",
      "\n",
      "auprc 4Pneumonia: 0.007912029251687007\n",
      "\n",
      "auroc 5Pneumonia: 0.5724642295979571\n",
      "\n",
      "auprc 5Pneumonia: 0.012515714125374555\n",
      "\n",
      "mean auroc: 0.490199148191639\n",
      "\n",
      "mean auprc: 0.010804514549481134\n",
      "\n",
      "max auroc: 0.6195349093575647\n",
      "\n",
      "max auprc: 0.01678852601121239\n",
      "\n",
      "59.0556914806366\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195349093575647\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
