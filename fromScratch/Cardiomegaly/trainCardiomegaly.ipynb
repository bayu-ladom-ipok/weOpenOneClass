{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Cardiomegaly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path= None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path= None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "264: 1950\n",
      "1950: 1950\n",
      "741: 1950\n",
      "431: 1950\n",
      "75: 1950\n",
      "80: 1950\n",
      "21: 1950\n",
      "32: 1950\n",
      "126: 1950\n",
      "85: 1950\n",
      "38: 1950\n",
      "43: 1950\n",
      "85: 1950\n",
      "2: 1950\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1937/1950 [============================>.] - ETA: 0s - loss: 6.3133 - leftLayer1_loss: 0.1141 - midLayer1_loss: 1.4628 - rightLayer1_loss: 1.6889 - leftLayer2_loss: 0.1232 - midLayer2_loss: 1.4125 - rightLayer2_loss: 1.5119\n",
      "Epoch 00001: val_loss improved from inf to 5.94079, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.3116 - leftLayer1_loss: 0.1141 - midLayer1_loss: 1.4633 - rightLayer1_loss: 1.6878 - leftLayer2_loss: 0.1232 - midLayer2_loss: 1.4126 - rightLayer2_loss: 1.5107 - val_loss: 5.9408 - val_leftLayer1_loss: 0.1113 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 1.5253 - val_leftLayer2_loss: 0.1211 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 1.4099\n",
      "Epoch 2/11\n",
      "1946/1950 [============================>.] - ETA: 0s - loss: 5.5940 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.4624 - rightLayer1_loss: 1.3936 - leftLayer2_loss: 0.1093 - midLayer2_loss: 1.4150 - rightLayer2_loss: 1.1053\n",
      "Epoch 00002: val_loss improved from 5.94079 to 5.45854, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.5936 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.4624 - rightLayer1_loss: 1.3933 - leftLayer2_loss: 0.1093 - midLayer2_loss: 1.4151 - rightLayer2_loss: 1.1050 - val_loss: 5.4585 - val_leftLayer1_loss: 0.1058 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 1.2774 - val_leftLayer2_loss: 0.1124 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 1.1897\n",
      "Epoch 3/11\n",
      "1941/1950 [============================>.] - ETA: 0s - loss: 5.2301 - leftLayer1_loss: 0.1031 - midLayer1_loss: 1.4640 - rightLayer1_loss: 1.1979 - leftLayer2_loss: 0.0980 - midLayer2_loss: 1.4127 - rightLayer2_loss: 0.9544\n",
      "Epoch 00003: val_loss improved from 5.45854 to 5.17658, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.2315 - leftLayer1_loss: 0.1031 - midLayer1_loss: 1.4644 - rightLayer1_loss: 1.1979 - leftLayer2_loss: 0.0980 - midLayer2_loss: 1.4134 - rightLayer2_loss: 0.9548 - val_loss: 5.1766 - val_leftLayer1_loss: 0.1007 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 1.1193 - val_leftLayer2_loss: 0.1049 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 1.0785\n",
      "Epoch 4/11\n",
      "1929/1950 [============================>.] - ETA: 0s - loss: 5.0159 - leftLayer1_loss: 0.0982 - midLayer1_loss: 1.4616 - rightLayer1_loss: 1.0758 - leftLayer2_loss: 0.0887 - midLayer2_loss: 1.4054 - rightLayer2_loss: 0.8862\n",
      "Epoch 00004: val_loss improved from 5.17658 to 5.00028, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.0203 - leftLayer1_loss: 0.0982 - midLayer1_loss: 1.4625 - rightLayer1_loss: 1.0763 - leftLayer2_loss: 0.0887 - midLayer2_loss: 1.4069 - rightLayer2_loss: 0.8877 - val_loss: 5.0003 - val_leftLayer1_loss: 0.0959 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 1.0197 - val_leftLayer2_loss: 0.0984 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 1.0130\n",
      "Epoch 5/11\n",
      "1933/1950 [============================>.] - ETA: 0s - loss: 4.8996 - leftLayer1_loss: 0.0937 - midLayer1_loss: 1.4623 - rightLayer1_loss: 0.9989 - leftLayer2_loss: 0.0810 - midLayer2_loss: 1.4113 - rightLayer2_loss: 0.8523\n",
      "Epoch 00005: val_loss improved from 5.00028 to 4.88240, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.9021 - leftLayer1_loss: 0.0937 - midLayer1_loss: 1.4628 - rightLayer1_loss: 0.9993 - leftLayer2_loss: 0.0810 - midLayer2_loss: 1.4119 - rightLayer2_loss: 0.8533 - val_loss: 4.8824 - val_leftLayer1_loss: 0.0916 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.9547 - val_leftLayer2_loss: 0.0928 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.9702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "1947/1950 [============================>.] - ETA: 0s - loss: 4.8174 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.4631 - rightLayer1_loss: 0.9490 - leftLayer2_loss: 0.0747 - midLayer2_loss: 1.4067 - rightLayer2_loss: 0.8344\n",
      "Epoch 00006: val_loss improved from 4.88240 to 4.79782, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 4.8177 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.4631 - rightLayer1_loss: 0.9490 - leftLayer2_loss: 0.0747 - midLayer2_loss: 1.4069 - rightLayer2_loss: 0.8345 - val_loss: 4.7978 - val_leftLayer1_loss: 0.0875 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.9102 - val_leftLayer2_loss: 0.0879 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.9390\n",
      "Epoch 7/11\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 4.7673 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.4636 - rightLayer1_loss: 0.9135 - leftLayer2_loss: 0.0691 - midLayer2_loss: 1.4144 - rightLayer2_loss: 0.8209\n",
      "Epoch 00007: val_loss improved from 4.79782 to 4.73451, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7691 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.4640 - rightLayer1_loss: 0.9140 - leftLayer2_loss: 0.0691 - midLayer2_loss: 1.4146 - rightLayer2_loss: 0.8216 - val_loss: 4.7345 - val_leftLayer1_loss: 0.0838 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.8783 - val_leftLayer2_loss: 0.0837 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.9155\n",
      "Epoch 8/11\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 4.7187 - leftLayer1_loss: 0.0823 - midLayer1_loss: 1.4635 - rightLayer1_loss: 0.8879 - leftLayer2_loss: 0.0644 - midLayer2_loss: 1.4113 - rightLayer2_loss: 0.8092\n",
      "Epoch 00008: val_loss improved from 4.73451 to 4.68538, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 4.7188 - leftLayer1_loss: 0.0823 - midLayer1_loss: 1.4634 - rightLayer1_loss: 0.8880 - leftLayer2_loss: 0.0644 - midLayer2_loss: 1.4112 - rightLayer2_loss: 0.8093 - val_loss: 4.6854 - val_leftLayer1_loss: 0.0804 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.8545 - val_leftLayer2_loss: 0.0800 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.8974\n",
      "Epoch 9/11\n",
      "1933/1950 [============================>.] - ETA: 0s - loss: 4.6969 - leftLayer1_loss: 0.0791 - midLayer1_loss: 1.4643 - rightLayer1_loss: 0.8680 - leftLayer2_loss: 0.0607 - midLayer2_loss: 1.4220 - rightLayer2_loss: 0.8030\n",
      "Epoch 00009: val_loss improved from 4.68538 to 4.64555, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 4.6999 - leftLayer1_loss: 0.0791 - midLayer1_loss: 1.4646 - rightLayer1_loss: 0.8688 - leftLayer2_loss: 0.0608 - midLayer2_loss: 1.4224 - rightLayer2_loss: 0.8043 - val_loss: 4.6456 - val_leftLayer1_loss: 0.0773 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.8361 - val_leftLayer2_loss: 0.0767 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.8823\n",
      "Epoch 10/11\n",
      "1937/1950 [============================>.] - ETA: 0s - loss: 4.6654 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.4645 - rightLayer1_loss: 0.8528 - leftLayer2_loss: 0.0577 - midLayer2_loss: 1.4171 - rightLayer2_loss: 0.7972\n",
      "Epoch 00010: val_loss improved from 4.64555 to 4.61283, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 4.6684 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.4649 - rightLayer1_loss: 0.8538 - leftLayer2_loss: 0.0577 - midLayer2_loss: 1.4173 - rightLayer2_loss: 0.7986 - val_loss: 4.6128 - val_leftLayer1_loss: 0.0744 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.8216 - val_leftLayer2_loss: 0.0738 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.8699\n",
      "Epoch 11/11\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 4.6411 - leftLayer1_loss: 0.0733 - midLayer1_loss: 1.4637 - rightLayer1_loss: 0.8424 - leftLayer2_loss: 0.0550 - midLayer2_loss: 1.4139 - rightLayer2_loss: 0.7927\n",
      "Epoch 00011: val_loss improved from 4.61283 to 4.58536, saving model to ./experiments/0.009_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6413 - leftLayer1_loss: 0.0733 - midLayer1_loss: 1.4637 - rightLayer1_loss: 0.8425 - leftLayer2_loss: 0.0550 - midLayer2_loss: 1.4139 - rightLayer2_loss: 0.7928 - val_loss: 4.5854 - val_leftLayer1_loss: 0.0717 - val_midLayer1_loss: 1.4400 - val_rightLayer1_loss: 0.8098 - val_leftLayer2_loss: 0.0712 - val_midLayer2_loss: 1.3332 - val_rightLayer2_loss: 0.8595\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Cardiomegaly: 0.8547427823020672\n",
      "\n",
      "auprc 0Cardiomegaly: 0.18155868447721846\n",
      "\n",
      "auroc 1Cardiomegaly: 0.30624602017946917\n",
      "\n",
      "auprc 1Cardiomegaly: 0.016774809836038046\n",
      "\n",
      "auroc 2Cardiomegaly: 0.814474979795211\n",
      "\n",
      "auprc 2Cardiomegaly: 0.11281433561891784\n",
      "\n",
      "auroc 3Cardiomegaly: 0.7037727479818408\n",
      "\n",
      "auprc 3Cardiomegaly: 0.06518808549560628\n",
      "\n",
      "auroc 4Cardiomegaly: 0.5155517900758984\n",
      "\n",
      "auprc 4Cardiomegaly: 0.026366694523749547\n",
      "\n",
      "auroc 5Cardiomegaly: 0.6884156929129983\n",
      "\n",
      "auprc 5Cardiomegaly: 0.05361184004261704\n",
      "\n",
      "mean auroc: 0.6472006688745808\n",
      "\n",
      "mean auprc: 0.07605240833235787\n",
      "\n",
      "max auroc: 0.8547427823020672\n",
      "\n",
      "max auprc: 0.18155868447721846\n",
      "\n",
      "83.02065682411194\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1946/1950 [============================>.] - ETA: 0s - loss: 6.4752 - leftLayer1_loss: 0.1195 - midLayer1_loss: 1.4282 - rightLayer1_loss: 1.7504 - leftLayer2_loss: 0.1234 - midLayer2_loss: 1.4943 - rightLayer2_loss: 1.5593\n",
      "Epoch 00001: val_loss improved from inf to 6.00743, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.4740 - leftLayer1_loss: 0.1195 - midLayer1_loss: 1.4282 - rightLayer1_loss: 1.7500 - leftLayer2_loss: 0.1234 - midLayer2_loss: 1.4941 - rightLayer2_loss: 1.5588 - val_loss: 6.0074 - val_leftLayer1_loss: 0.1166 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 1.5790 - val_leftLayer2_loss: 0.1151 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 1.4434\n",
      "Epoch 2/11\n",
      "1930/1950 [============================>.] - ETA: 0s - loss: 5.7213 - leftLayer1_loss: 0.1136 - midLayer1_loss: 1.4271 - rightLayer1_loss: 1.4407 - leftLayer2_loss: 0.1100 - midLayer2_loss: 1.5003 - rightLayer2_loss: 1.1295\n",
      "Epoch 00002: val_loss improved from 6.00743 to 5.50105, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.7213 - leftLayer1_loss: 0.1136 - midLayer1_loss: 1.4277 - rightLayer1_loss: 1.4397 - leftLayer2_loss: 0.1099 - midLayer2_loss: 1.5010 - rightLayer2_loss: 1.1293 - val_loss: 5.5011 - val_leftLayer1_loss: 0.1108 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 1.3135 - val_leftLayer2_loss: 0.1071 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 1.2163\n",
      "Epoch 3/11\n",
      "1931/1950 [============================>.] - ETA: 0s - loss: 5.3236 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.4265 - rightLayer1_loss: 1.2270 - leftLayer2_loss: 0.0993 - midLayer2_loss: 1.5001 - rightLayer2_loss: 0.9628\n",
      "Epoch 00003: val_loss improved from 5.50105 to 5.20033, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 5.3249 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.4271 - rightLayer1_loss: 1.2267 - leftLayer2_loss: 0.0993 - midLayer2_loss: 1.5005 - rightLayer2_loss: 0.9633 - val_loss: 5.2003 - val_leftLayer1_loss: 0.1053 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 1.1411 - val_leftLayer2_loss: 0.1001 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 1.1005\n",
      "Epoch 4/11\n",
      "1941/1950 [============================>.] - ETA: 0s - loss: 5.1060 - leftLayer1_loss: 0.1027 - midLayer1_loss: 1.4262 - rightLayer1_loss: 1.0937 - leftLayer2_loss: 0.0892 - midLayer2_loss: 1.5008 - rightLayer2_loss: 0.8933\n",
      "Epoch 00004: val_loss improved from 5.20033 to 5.01216, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.1072 - leftLayer1_loss: 0.1027 - midLayer1_loss: 1.4266 - rightLayer1_loss: 1.0940 - leftLayer2_loss: 0.0892 - midLayer2_loss: 1.5009 - rightLayer2_loss: 0.8939 - val_loss: 5.0122 - val_leftLayer1_loss: 0.1003 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 1.0321 - val_leftLayer2_loss: 0.0940 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 1.0324\n",
      "Epoch 5/11\n",
      "1935/1950 [============================>.] - ETA: 0s - loss: 4.9677 - leftLayer1_loss: 0.0978 - midLayer1_loss: 1.4258 - rightLayer1_loss: 1.0087 - leftLayer2_loss: 0.0816 - midLayer2_loss: 1.4925 - rightLayer2_loss: 0.8613\n",
      "Epoch 00005: val_loss improved from 5.01216 to 4.88665, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.9707 - leftLayer1_loss: 0.0978 - midLayer1_loss: 1.4263 - rightLayer1_loss: 1.0092 - leftLayer2_loss: 0.0816 - midLayer2_loss: 1.4937 - rightLayer2_loss: 0.8622 - val_loss: 4.8866 - val_leftLayer1_loss: 0.0956 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.9612 - val_leftLayer2_loss: 0.0888 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.9877\n",
      "Epoch 6/11\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 4.8822 - leftLayer1_loss: 0.0935 - midLayer1_loss: 1.4285 - rightLayer1_loss: 0.9541 - leftLayer2_loss: 0.0753 - midLayer2_loss: 1.4911 - rightLayer2_loss: 0.8397\n",
      "Epoch 00006: val_loss improved from 4.88665 to 4.79745, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8841 - leftLayer1_loss: 0.0935 - midLayer1_loss: 1.4289 - rightLayer1_loss: 0.9546 - leftLayer2_loss: 0.0753 - midLayer2_loss: 1.4913 - rightLayer2_loss: 0.8405 - val_loss: 4.7974 - val_leftLayer1_loss: 0.0913 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.9129 - val_leftLayer2_loss: 0.0843 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.9556\n",
      "Epoch 7/11\n",
      "1941/1950 [============================>.] - ETA: 0s - loss: 4.8266 - leftLayer1_loss: 0.0894 - midLayer1_loss: 1.4265 - rightLayer1_loss: 0.9160 - leftLayer2_loss: 0.0699 - midLayer2_loss: 1.4990 - rightLayer2_loss: 0.8259\n",
      "Epoch 00007: val_loss improved from 4.79745 to 4.73096, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8296 - leftLayer1_loss: 0.0893 - midLayer1_loss: 1.4268 - rightLayer1_loss: 0.9165 - leftLayer2_loss: 0.0699 - midLayer2_loss: 1.5002 - rightLayer2_loss: 0.8268 - val_loss: 4.7310 - val_leftLayer1_loss: 0.0874 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.8787 - val_leftLayer2_loss: 0.0803 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.9313\n",
      "Epoch 8/11\n",
      "1932/1950 [============================>.] - ETA: 0s - loss: 4.7763 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.4259 - rightLayer1_loss: 0.8887 - leftLayer2_loss: 0.0653 - midLayer2_loss: 1.4945 - rightLayer2_loss: 0.8164\n",
      "Epoch 00008: val_loss improved from 4.73096 to 4.67932, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7793 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.4263 - rightLayer1_loss: 0.8893 - leftLayer2_loss: 0.0653 - midLayer2_loss: 1.4956 - rightLayer2_loss: 0.8172 - val_loss: 4.6793 - val_leftLayer1_loss: 0.0837 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.8533 - val_leftLayer2_loss: 0.0768 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.9121\n",
      "Epoch 9/11\n",
      "1928/1950 [============================>.] - ETA: 0s - loss: 4.7456 - leftLayer1_loss: 0.0822 - midLayer1_loss: 1.4272 - rightLayer1_loss: 0.8669 - leftLayer2_loss: 0.0616 - midLayer2_loss: 1.4995 - rightLayer2_loss: 0.8083\n",
      "Epoch 00009: val_loss improved from 4.67932 to 4.63797, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7506 - leftLayer1_loss: 0.0822 - midLayer1_loss: 1.4280 - rightLayer1_loss: 0.8683 - leftLayer2_loss: 0.0616 - midLayer2_loss: 1.5007 - rightLayer2_loss: 0.8098 - val_loss: 4.6380 - val_leftLayer1_loss: 0.0804 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.8339 - val_leftLayer2_loss: 0.0738 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.8966\n",
      "Epoch 10/11\n",
      "1943/1950 [============================>.] - ETA: 0s - loss: 4.7196 - leftLayer1_loss: 0.0790 - midLayer1_loss: 1.4270 - rightLayer1_loss: 0.8519 - leftLayer2_loss: 0.0579 - midLayer2_loss: 1.5019 - rightLayer2_loss: 0.8020\n",
      "Epoch 00010: val_loss improved from 4.63797 to 4.60419, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7209 - leftLayer1_loss: 0.0790 - midLayer1_loss: 1.4272 - rightLayer1_loss: 0.8522 - leftLayer2_loss: 0.0579 - midLayer2_loss: 1.5023 - rightLayer2_loss: 0.8023 - val_loss: 4.6042 - val_leftLayer1_loss: 0.0773 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.8186 - val_leftLayer2_loss: 0.0711 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.8839\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1945/1950 [============================>.] - ETA: 0s - loss: 4.6870 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.4277 - rightLayer1_loss: 0.8399 - leftLayer2_loss: 0.0551 - midLayer2_loss: 1.4910 - rightLayer2_loss: 0.7971\n",
      "Epoch 00011: val_loss improved from 4.60419 to 4.57581, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 4.6872 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.4277 - rightLayer1_loss: 0.8398 - leftLayer2_loss: 0.0551 - midLayer2_loss: 1.4914 - rightLayer2_loss: 0.7969 - val_loss: 4.5758 - val_leftLayer1_loss: 0.0744 - val_midLayer1_loss: 1.4038 - val_rightLayer1_loss: 0.8062 - val_leftLayer2_loss: 0.0686 - val_midLayer2_loss: 1.3495 - val_rightLayer2_loss: 0.8732\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Cardiomegaly: 0.8574073846911628\n",
      "\n",
      "auprc 0Cardiomegaly: 0.20694632452184125\n",
      "\n",
      "auroc 1Cardiomegaly: 0.2628978817958114\n",
      "\n",
      "auprc 1Cardiomegaly: 0.015852763179054947\n",
      "\n",
      "auroc 2Cardiomegaly: 0.8162519711365999\n",
      "\n",
      "auprc 2Cardiomegaly: 0.16494129919699602\n",
      "\n",
      "auroc 3Cardiomegaly: 0.4941661276363928\n",
      "\n",
      "auprc 3Cardiomegaly: 0.02353689193746181\n",
      "\n",
      "auroc 4Cardiomegaly: 0.3793765444534454\n",
      "\n",
      "auprc 4Cardiomegaly: 0.01882437149445452\n",
      "\n",
      "auroc 5Cardiomegaly: 0.6593115179800212\n",
      "\n",
      "auprc 5Cardiomegaly: 0.03967758656374086\n",
      "\n",
      "mean auroc: 0.5782352379489056\n",
      "\n",
      "mean auprc: 0.07829653948225825\n",
      "\n",
      "max auroc: 0.8574073846911628\n",
      "\n",
      "max auprc: 0.20694632452184125\n",
      "\n",
      "82.72958040237427\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 6.4528 - leftLayer1_loss: 0.1262 - midLayer1_loss: 1.4588 - rightLayer1_loss: 1.7083 - leftLayer2_loss: 0.1220 - midLayer2_loss: 1.4888 - rightLayer2_loss: 1.5488\n",
      "Epoch 00001: val_loss improved from inf to 6.04555, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.4517 - leftLayer1_loss: 0.1262 - midLayer1_loss: 1.4588 - rightLayer1_loss: 1.7079 - leftLayer2_loss: 0.1219 - midLayer2_loss: 1.4888 - rightLayer2_loss: 1.5481 - val_loss: 6.0455 - val_leftLayer1_loss: 0.1234 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 1.5475 - val_leftLayer2_loss: 0.1150 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 1.4458\n",
      "Epoch 2/11\n",
      "1931/1950 [============================>.] - ETA: 0s - loss: 5.7271 - leftLayer1_loss: 0.1203 - midLayer1_loss: 1.4578 - rightLayer1_loss: 1.4339 - leftLayer2_loss: 0.1090 - midLayer2_loss: 1.4861 - rightLayer2_loss: 1.1201\n",
      "Epoch 00002: val_loss improved from 6.04555 to 5.56486, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.7259 - leftLayer1_loss: 0.1202 - midLayer1_loss: 1.4582 - rightLayer1_loss: 1.4330 - leftLayer2_loss: 0.1089 - midLayer2_loss: 1.4859 - rightLayer2_loss: 1.1196 - val_loss: 5.5649 - val_leftLayer1_loss: 0.1176 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 1.3086 - val_leftLayer2_loss: 0.1069 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 1.2179\n",
      "Epoch 3/11\n",
      "1941/1950 [============================>.] - ETA: 0s - loss: 5.3574 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.4592 - rightLayer1_loss: 1.2391 - leftLayer2_loss: 0.0983 - midLayer2_loss: 1.4843 - rightLayer2_loss: 0.9619\n",
      "Epoch 00003: val_loss improved from 5.56486 to 5.27569, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.3580 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.4596 - rightLayer1_loss: 1.2391 - leftLayer2_loss: 0.0982 - midLayer2_loss: 1.4843 - rightLayer2_loss: 0.9621 - val_loss: 5.2757 - val_leftLayer1_loss: 0.1121 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 1.1478 - val_leftLayer2_loss: 0.0999 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 1.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1943/1950 [============================>.] - ETA: 0s - loss: 5.1499 - leftLayer1_loss: 0.1095 - midLayer1_loss: 1.4590 - rightLayer1_loss: 1.1128 - leftLayer2_loss: 0.0887 - midLayer2_loss: 1.4852 - rightLayer2_loss: 0.8946\n",
      "Epoch 00004: val_loss improved from 5.27569 to 5.09116, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 5.1505 - leftLayer1_loss: 0.1095 - midLayer1_loss: 1.4591 - rightLayer1_loss: 1.1128 - leftLayer2_loss: 0.0887 - midLayer2_loss: 1.4855 - rightLayer2_loss: 0.8948 - val_loss: 5.0912 - val_leftLayer1_loss: 0.1070 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 1.0424 - val_leftLayer2_loss: 0.0938 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 1.0341\n",
      "Epoch 5/11\n",
      "1935/1950 [============================>.] - ETA: 0s - loss: 5.0213 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4584 - rightLayer1_loss: 1.0294 - leftLayer2_loss: 0.0804 - midLayer2_loss: 1.4884 - rightLayer2_loss: 0.8599\n",
      "Epoch 00005: val_loss improved from 5.09116 to 4.96588, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.0233 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4589 - rightLayer1_loss: 1.0299 - leftLayer2_loss: 0.0804 - midLayer2_loss: 1.4886 - rightLayer2_loss: 0.8608 - val_loss: 4.9659 - val_leftLayer1_loss: 0.1023 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.9720 - val_leftLayer2_loss: 0.0885 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.9893\n",
      "Epoch 6/11\n",
      "1938/1950 [============================>.] - ETA: 0s - loss: 4.9320 - leftLayer1_loss: 0.1001 - midLayer1_loss: 1.4579 - rightLayer1_loss: 0.9728 - leftLayer2_loss: 0.0741 - midLayer2_loss: 1.4880 - rightLayer2_loss: 0.8391\n",
      "Epoch 00006: val_loss improved from 4.96588 to 4.87616, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.9351 - leftLayer1_loss: 0.1001 - midLayer1_loss: 1.4584 - rightLayer1_loss: 0.9736 - leftLayer2_loss: 0.0741 - midLayer2_loss: 1.4882 - rightLayer2_loss: 0.8406 - val_loss: 4.8762 - val_leftLayer1_loss: 0.0978 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.9233 - val_leftLayer2_loss: 0.0840 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.9573\n",
      "Epoch 7/11\n",
      "1948/1950 [============================>.] - ETA: 0s - loss: 4.8644 - leftLayer1_loss: 0.0959 - midLayer1_loss: 1.4587 - rightLayer1_loss: 0.9334 - leftLayer2_loss: 0.0687 - midLayer2_loss: 1.4822 - rightLayer2_loss: 0.8255\n",
      "Epoch 00007: val_loss improved from 4.87616 to 4.80877, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8649 - leftLayer1_loss: 0.0959 - midLayer1_loss: 1.4587 - rightLayer1_loss: 0.9337 - leftLayer2_loss: 0.0687 - midLayer2_loss: 1.4820 - rightLayer2_loss: 0.8259 - val_loss: 4.8088 - val_leftLayer1_loss: 0.0937 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.8882 - val_leftLayer2_loss: 0.0800 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.9330\n",
      "Epoch 8/11\n",
      "1927/1950 [============================>.] - ETA: 0s - loss: 4.8130 - leftLayer1_loss: 0.0920 - midLayer1_loss: 1.4585 - rightLayer1_loss: 0.9037 - leftLayer2_loss: 0.0643 - midLayer2_loss: 1.4797 - rightLayer2_loss: 0.8148\n",
      "Epoch 00008: val_loss improved from 4.80877 to 4.75624, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8181 - leftLayer1_loss: 0.0920 - midLayer1_loss: 1.4594 - rightLayer1_loss: 0.9052 - leftLayer2_loss: 0.0643 - midLayer2_loss: 1.4803 - rightLayer2_loss: 0.8169 - val_loss: 4.7562 - val_leftLayer1_loss: 0.0899 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.8622 - val_leftLayer2_loss: 0.0765 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.9139\n",
      "Epoch 9/11\n",
      "1929/1950 [============================>.] - ETA: 0s - loss: 4.7757 - leftLayer1_loss: 0.0884 - midLayer1_loss: 1.4581 - rightLayer1_loss: 0.8818 - leftLayer2_loss: 0.0604 - midLayer2_loss: 1.4810 - rightLayer2_loss: 0.8061\n",
      "Epoch 00009: val_loss improved from 4.75624 to 4.71412, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7804 - leftLayer1_loss: 0.0884 - midLayer1_loss: 1.4590 - rightLayer1_loss: 0.8833 - leftLayer2_loss: 0.0605 - midLayer2_loss: 1.4814 - rightLayer2_loss: 0.8079 - val_loss: 4.7141 - val_leftLayer1_loss: 0.0863 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.8421 - val_leftLayer2_loss: 0.0735 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.8984\n",
      "Epoch 10/11\n",
      "1940/1950 [============================>.] - ETA: 0s - loss: 4.7545 - leftLayer1_loss: 0.0850 - midLayer1_loss: 1.4592 - rightLayer1_loss: 0.8659 - leftLayer2_loss: 0.0574 - midLayer2_loss: 1.4864 - rightLayer2_loss: 0.8005\n",
      "Epoch 00010: val_loss improved from 4.71412 to 4.67925, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7570 - leftLayer1_loss: 0.0850 - midLayer1_loss: 1.4596 - rightLayer1_loss: 0.8668 - leftLayer2_loss: 0.0574 - midLayer2_loss: 1.4864 - rightLayer2_loss: 0.8017 - val_loss: 4.6792 - val_leftLayer1_loss: 0.0830 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.8263 - val_leftLayer2_loss: 0.0707 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.8854\n",
      "Epoch 11/11\n",
      "1946/1950 [============================>.] - ETA: 0s - loss: 4.7285 - leftLayer1_loss: 0.0819 - midLayer1_loss: 1.4593 - rightLayer1_loss: 0.8533 - leftLayer2_loss: 0.0544 - midLayer2_loss: 1.4833 - rightLayer2_loss: 0.7962\n",
      "Epoch 00011: val_loss improved from 4.67925 to 4.65021, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7288 - leftLayer1_loss: 0.0819 - midLayer1_loss: 1.4593 - rightLayer1_loss: 0.8534 - leftLayer2_loss: 0.0544 - midLayer2_loss: 1.4834 - rightLayer2_loss: 0.7963 - val_loss: 4.6502 - val_leftLayer1_loss: 0.0800 - val_midLayer1_loss: 1.4593 - val_rightLayer1_loss: 0.8135 - val_leftLayer2_loss: 0.0683 - val_midLayer2_loss: 1.3545 - val_rightLayer2_loss: 0.8746\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Cardiomegaly: 0.5969527529546015\n",
      "\n",
      "auprc 0Cardiomegaly: 0.035663974319573244\n",
      "\n",
      "auroc 1Cardiomegaly: 0.5731238011392685\n",
      "\n",
      "auprc 1Cardiomegaly: 0.027721172276430884\n",
      "\n",
      "auroc 2Cardiomegaly: 0.7464137777238878\n",
      "\n",
      "auprc 2Cardiomegaly: 0.07754624921510601\n",
      "\n",
      "auroc 3Cardiomegaly: 0.3990430895532552\n",
      "\n",
      "auprc 3Cardiomegaly: 0.019377794635159543\n",
      "\n",
      "auroc 4Cardiomegaly: 0.4529185560247858\n",
      "\n",
      "auprc 4Cardiomegaly: 0.0213949136339799\n",
      "\n",
      "auroc 5Cardiomegaly: 0.6008079006190159\n",
      "\n",
      "auprc 5Cardiomegaly: 0.03248624165050662\n",
      "\n",
      "mean auroc: 0.5615433130024691\n",
      "\n",
      "mean auprc: 0.03569839095512604\n",
      "\n",
      "max auroc: 0.7464137777238878\n",
      "\n",
      "max auprc: 0.07754624921510601\n",
      "\n",
      "82.85752272605896\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1948/1950 [============================>.] - ETA: 0s - loss: 6.2556 - leftLayer1_loss: 0.1244 - midLayer1_loss: 1.3762 - rightLayer1_loss: 1.7247 - leftLayer2_loss: 0.1204 - midLayer2_loss: 1.3357 - rightLayer2_loss: 1.5743\n",
      "Epoch 00001: val_loss improved from inf to 5.88820, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.2556 - leftLayer1_loss: 0.1243 - midLayer1_loss: 1.3762 - rightLayer1_loss: 1.7246 - leftLayer2_loss: 0.1204 - midLayer2_loss: 1.3360 - rightLayer2_loss: 1.5741 - val_loss: 5.8882 - val_leftLayer1_loss: 0.1208 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 1.5676 - val_leftLayer2_loss: 0.1180 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 1.4304\n",
      "Epoch 2/11\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 5.5080 - leftLayer1_loss: 0.1185 - midLayer1_loss: 1.3774 - rightLayer1_loss: 1.4474 - leftLayer2_loss: 0.1070 - midLayer2_loss: 1.3411 - rightLayer2_loss: 1.1166\n",
      "Epoch 00002: val_loss improved from 5.88820 to 5.39626, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.5082 - leftLayer1_loss: 0.1185 - midLayer1_loss: 1.3774 - rightLayer1_loss: 1.4474 - leftLayer2_loss: 0.1070 - midLayer2_loss: 1.3412 - rightLayer2_loss: 1.1167 - val_loss: 5.3963 - val_leftLayer1_loss: 0.1152 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 1.3271 - val_leftLayer2_loss: 0.1093 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 1.1931\n",
      "Epoch 3/11\n",
      "1940/1950 [============================>.] - ETA: 0s - loss: 5.1313 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.3773 - rightLayer1_loss: 1.2501 - leftLayer2_loss: 0.0959 - midLayer2_loss: 1.3411 - rightLayer2_loss: 0.9537\n",
      "Epoch 00003: val_loss improved from 5.39626 to 5.10462, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.1326 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.3775 - rightLayer1_loss: 1.2501 - leftLayer2_loss: 0.0959 - midLayer2_loss: 1.3417 - rightLayer2_loss: 0.9543 - val_loss: 5.1046 - val_leftLayer1_loss: 0.1099 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 1.1641 - val_leftLayer2_loss: 0.1019 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 1.0772\n",
      "Epoch 4/11\n",
      "1933/1950 [============================>.] - ETA: 0s - loss: 4.9218 - leftLayer1_loss: 0.1080 - midLayer1_loss: 1.3770 - rightLayer1_loss: 1.1210 - leftLayer2_loss: 0.0868 - midLayer2_loss: 1.3413 - rightLayer2_loss: 0.8876\n",
      "Epoch 00004: val_loss improved from 5.10462 to 4.91893, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.9230 - leftLayer1_loss: 0.1080 - midLayer1_loss: 1.3772 - rightLayer1_loss: 1.1210 - leftLayer2_loss: 0.0868 - midLayer2_loss: 1.3413 - rightLayer2_loss: 0.8886 - val_loss: 4.9189 - val_leftLayer1_loss: 0.1050 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 1.0567 - val_leftLayer2_loss: 0.0954 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 1.0103\n",
      "Epoch 5/11\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 4.7798 - leftLayer1_loss: 0.1033 - midLayer1_loss: 1.3759 - rightLayer1_loss: 1.0366 - leftLayer2_loss: 0.0786 - midLayer2_loss: 1.3313 - rightLayer2_loss: 0.8542\n",
      "Epoch 00005: val_loss improved from 4.91893 to 4.79347, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7801 - leftLayer1_loss: 0.1033 - midLayer1_loss: 1.3759 - rightLayer1_loss: 1.0367 - leftLayer2_loss: 0.0786 - midLayer2_loss: 1.3311 - rightLayer2_loss: 0.8546 - val_loss: 4.7935 - val_leftLayer1_loss: 0.1004 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.9847 - val_leftLayer2_loss: 0.0898 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.9670\n",
      "Epoch 6/11\n",
      "1941/1950 [============================>.] - ETA: 0s - loss: 4.7018 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.3765 - rightLayer1_loss: 0.9794 - leftLayer2_loss: 0.0723 - midLayer2_loss: 1.3441 - rightLayer2_loss: 0.8306\n",
      "Epoch 00006: val_loss improved from 4.79347 to 4.70372, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7032 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.3766 - rightLayer1_loss: 0.9798 - leftLayer2_loss: 0.0723 - midLayer2_loss: 1.3442 - rightLayer2_loss: 0.8314 - val_loss: 4.7037 - val_leftLayer1_loss: 0.0961 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.9348 - val_leftLayer2_loss: 0.0851 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.9363\n",
      "Epoch 7/11\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 4.6410 - leftLayer1_loss: 0.0947 - midLayer1_loss: 1.3773 - rightLayer1_loss: 0.9385 - leftLayer2_loss: 0.0671 - midLayer2_loss: 1.3435 - rightLayer2_loss: 0.8199\n",
      "Epoch 00007: val_loss improved from 4.70372 to 4.63642, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6411 - leftLayer1_loss: 0.0947 - midLayer1_loss: 1.3772 - rightLayer1_loss: 0.9386 - leftLayer2_loss: 0.0671 - midLayer2_loss: 1.3435 - rightLayer2_loss: 0.8200 - val_loss: 4.6364 - val_leftLayer1_loss: 0.0921 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.8988 - val_leftLayer2_loss: 0.0809 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.9131\n",
      "Epoch 8/11\n",
      "1948/1950 [============================>.] - ETA: 0s - loss: 4.5977 - leftLayer1_loss: 0.0910 - midLayer1_loss: 1.3768 - rightLayer1_loss: 0.9097 - leftLayer2_loss: 0.0631 - midLayer2_loss: 1.3458 - rightLayer2_loss: 0.8113\n",
      "Epoch 00008: val_loss improved from 4.63642 to 4.58388, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.5987 - leftLayer1_loss: 0.0910 - midLayer1_loss: 1.3768 - rightLayer1_loss: 0.9100 - leftLayer2_loss: 0.0631 - midLayer2_loss: 1.3460 - rightLayer2_loss: 0.8117 - val_loss: 4.5839 - val_leftLayer1_loss: 0.0885 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.8718 - val_leftLayer2_loss: 0.0773 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.8948\n",
      "Epoch 9/11\n",
      "1948/1950 [============================>.] - ETA: 0s - loss: 4.5571 - leftLayer1_loss: 0.0875 - midLayer1_loss: 1.3765 - rightLayer1_loss: 0.8878 - leftLayer2_loss: 0.0590 - midLayer2_loss: 1.3421 - rightLayer2_loss: 0.8043\n",
      "Epoch 00009: val_loss improved from 4.58388 to 4.54166, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.5579 - leftLayer1_loss: 0.0875 - midLayer1_loss: 1.3766 - rightLayer1_loss: 0.8881 - leftLayer2_loss: 0.0590 - midLayer2_loss: 1.3421 - rightLayer2_loss: 0.8047 - val_loss: 4.5417 - val_leftLayer1_loss: 0.0851 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.8511 - val_leftLayer2_loss: 0.0741 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.8799\n",
      "Epoch 10/11\n",
      "1938/1950 [============================>.] - ETA: 0s - loss: 4.5179 - leftLayer1_loss: 0.0842 - midLayer1_loss: 1.3755 - rightLayer1_loss: 0.8698 - leftLayer2_loss: 0.0557 - midLayer2_loss: 1.3382 - rightLayer2_loss: 0.7946\n",
      "Epoch 00010: val_loss improved from 4.54166 to 4.50714, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.5217 - leftLayer1_loss: 0.0842 - midLayer1_loss: 1.3758 - rightLayer1_loss: 0.8710 - leftLayer2_loss: 0.0557 - midLayer2_loss: 1.3386 - rightLayer2_loss: 0.7962 - val_loss: 4.5071 - val_leftLayer1_loss: 0.0819 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.8347 - val_leftLayer2_loss: 0.0713 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.8677\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1935/1950 [============================>.] - ETA: 0s - loss: 4.5000 - leftLayer1_loss: 0.0812 - midLayer1_loss: 1.3773 - rightLayer1_loss: 0.8560 - leftLayer2_loss: 0.0533 - midLayer2_loss: 1.3401 - rightLayer2_loss: 0.7922\n",
      "Epoch 00011: val_loss improved from 4.50714 to 4.47791, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 4.5030 - leftLayer1_loss: 0.0812 - midLayer1_loss: 1.3774 - rightLayer1_loss: 0.8569 - leftLayer2_loss: 0.0533 - midLayer2_loss: 1.3405 - rightLayer2_loss: 0.7936 - val_loss: 4.4779 - val_leftLayer1_loss: 0.0789 - val_midLayer1_loss: 1.3481 - val_rightLayer1_loss: 0.8214 - val_leftLayer2_loss: 0.0689 - val_midLayer2_loss: 1.3034 - val_rightLayer2_loss: 0.8571\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Cardiomegaly: 0.7272147460440053\n",
      "\n",
      "auprc 0Cardiomegaly: 0.07239700133387263\n",
      "\n",
      "auroc 1Cardiomegaly: 0.5205780213098994\n",
      "\n",
      "auprc 1Cardiomegaly: 0.0331741884504674\n",
      "\n",
      "auroc 2Cardiomegaly: 0.7647029451733476\n",
      "\n",
      "auprc 2Cardiomegaly: 0.14074092494743606\n",
      "\n",
      "auroc 3Cardiomegaly: 0.6164934456906751\n",
      "\n",
      "auprc 3Cardiomegaly: 0.03298490166825589\n",
      "\n",
      "auroc 4Cardiomegaly: 0.3542490840417001\n",
      "\n",
      "auprc 4Cardiomegaly: 0.0180365403277096\n",
      "\n",
      "auroc 5Cardiomegaly: 0.757804143998694\n",
      "\n",
      "auprc 5Cardiomegaly: 0.11584695463571833\n",
      "\n",
      "mean auroc: 0.6235070643763869\n",
      "\n",
      "mean auprc: 0.06886341856057664\n",
      "\n",
      "max auroc: 0.7647029451733476\n",
      "\n",
      "max auprc: 0.14074092494743606\n",
      "\n",
      "82.61932492256165\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1938/1950 [============================>.] - ETA: 0s - loss: 6.2713 - leftLayer1_loss: 0.1170 - midLayer1_loss: 1.2751 - rightLayer1_loss: 1.7128 - leftLayer2_loss: 0.1214 - midLayer2_loss: 1.5285 - rightLayer2_loss: 1.5164\n",
      "Epoch 00001: val_loss improved from inf to 5.85197, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.2711 - leftLayer1_loss: 0.1170 - midLayer1_loss: 1.2758 - rightLayer1_loss: 1.7120 - leftLayer2_loss: 0.1214 - midLayer2_loss: 1.5298 - rightLayer2_loss: 1.5150 - val_loss: 5.8520 - val_leftLayer1_loss: 0.1133 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 1.5571 - val_leftLayer2_loss: 0.1156 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 1.4195\n",
      "Epoch 2/11\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 5.5684 - leftLayer1_loss: 0.1116 - midLayer1_loss: 1.2760 - rightLayer1_loss: 1.4383 - leftLayer2_loss: 0.1081 - midLayer2_loss: 1.5287 - rightLayer2_loss: 1.1058\n",
      "Epoch 00002: val_loss improved from 5.85197 to 5.37937, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.5683 - leftLayer1_loss: 0.1116 - midLayer1_loss: 1.2761 - rightLayer1_loss: 1.4380 - leftLayer2_loss: 0.1080 - midLayer2_loss: 1.5287 - rightLayer2_loss: 1.1059 - val_loss: 5.3794 - val_leftLayer1_loss: 0.1080 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 1.3191 - val_leftLayer2_loss: 0.1072 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 1.1985\n",
      "Epoch 3/11\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 5.2113 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.2758 - rightLayer1_loss: 1.2444 - leftLayer2_loss: 0.0964 - midLayer2_loss: 1.5334 - rightLayer2_loss: 0.9547\n",
      "Epoch 00003: val_loss improved from 5.37937 to 5.09537, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.2116 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.2759 - rightLayer1_loss: 1.2443 - leftLayer2_loss: 0.0964 - midLayer2_loss: 1.5335 - rightLayer2_loss: 0.9549 - val_loss: 5.0954 - val_leftLayer1_loss: 0.1032 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 1.1581 - val_leftLayer2_loss: 0.0999 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 1.0876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1934/1950 [============================>.] - ETA: 0s - loss: 5.0145 - leftLayer1_loss: 0.1019 - midLayer1_loss: 1.2760 - rightLayer1_loss: 1.1171 - leftLayer2_loss: 0.0872 - midLayer2_loss: 1.5400 - rightLayer2_loss: 0.8923\n",
      "Epoch 00004: val_loss improved from 5.09537 to 4.91306, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 5.0161 - leftLayer1_loss: 0.1019 - midLayer1_loss: 1.2764 - rightLayer1_loss: 1.1171 - leftLayer2_loss: 0.0872 - midLayer2_loss: 1.5404 - rightLayer2_loss: 0.8931 - val_loss: 4.9131 - val_leftLayer1_loss: 0.0987 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 1.0523 - val_leftLayer2_loss: 0.0937 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 1.0219\n",
      "Epoch 5/11\n",
      "1941/1950 [============================>.] - ETA: 0s - loss: 4.8777 - leftLayer1_loss: 0.0976 - midLayer1_loss: 1.2764 - rightLayer1_loss: 1.0334 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.5310 - rightLayer2_loss: 0.8597\n",
      "Epoch 00005: val_loss improved from 4.91306 to 4.78956, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8796 - leftLayer1_loss: 0.0976 - midLayer1_loss: 1.2769 - rightLayer1_loss: 1.0337 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.5315 - rightLayer2_loss: 0.8604 - val_loss: 4.7896 - val_leftLayer1_loss: 0.0945 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.9815 - val_leftLayer2_loss: 0.0883 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.9788\n",
      "Epoch 6/11\n",
      "1945/1950 [============================>.] - ETA: 0s - loss: 4.7993 - leftLayer1_loss: 0.0935 - midLayer1_loss: 1.2760 - rightLayer1_loss: 0.9771 - leftLayer2_loss: 0.0733 - midLayer2_loss: 1.5403 - rightLayer2_loss: 0.8390\n",
      "Epoch 00006: val_loss improved from 4.78956 to 4.70059, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7988 - leftLayer1_loss: 0.0935 - midLayer1_loss: 1.2758 - rightLayer1_loss: 0.9769 - leftLayer2_loss: 0.0733 - midLayer2_loss: 1.5403 - rightLayer2_loss: 0.8389 - val_loss: 4.7006 - val_leftLayer1_loss: 0.0906 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.9324 - val_leftLayer2_loss: 0.0836 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.9475\n",
      "Epoch 7/11\n",
      "1945/1950 [============================>.] - ETA: 0s - loss: 4.7324 - leftLayer1_loss: 0.0898 - midLayer1_loss: 1.2769 - rightLayer1_loss: 0.9381 - leftLayer2_loss: 0.0678 - midLayer2_loss: 1.5331 - rightLayer2_loss: 0.8267\n",
      "Epoch 00007: val_loss improved from 4.70059 to 4.63404, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7320 - leftLayer1_loss: 0.0898 - midLayer1_loss: 1.2767 - rightLayer1_loss: 0.9379 - leftLayer2_loss: 0.0678 - midLayer2_loss: 1.5331 - rightLayer2_loss: 0.8267 - val_loss: 4.6340 - val_leftLayer1_loss: 0.0869 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.8969 - val_leftLayer2_loss: 0.0795 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.9241\n",
      "Epoch 8/11\n",
      "1940/1950 [============================>.] - ETA: 0s - loss: 4.6748 - leftLayer1_loss: 0.0863 - midLayer1_loss: 1.2749 - rightLayer1_loss: 0.9077 - leftLayer2_loss: 0.0636 - midLayer2_loss: 1.5263 - rightLayer2_loss: 0.8158\n",
      "Epoch 00008: val_loss improved from 4.63404 to 4.58238, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6774 - leftLayer1_loss: 0.0863 - midLayer1_loss: 1.2754 - rightLayer1_loss: 0.9085 - leftLayer2_loss: 0.0637 - midLayer2_loss: 1.5268 - rightLayer2_loss: 0.8167 - val_loss: 4.5824 - val_leftLayer1_loss: 0.0836 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.8705 - val_leftLayer2_loss: 0.0760 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.9057\n",
      "Epoch 9/11\n",
      "1935/1950 [============================>.] - ETA: 0s - loss: 4.6409 - leftLayer1_loss: 0.0832 - midLayer1_loss: 1.2756 - rightLayer1_loss: 0.8865 - leftLayer2_loss: 0.0600 - midLayer2_loss: 1.5283 - rightLayer2_loss: 0.8072\n",
      "Epoch 00009: val_loss improved from 4.58238 to 4.54067, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6437 - leftLayer1_loss: 0.0832 - midLayer1_loss: 1.2761 - rightLayer1_loss: 0.8873 - leftLayer2_loss: 0.0600 - midLayer2_loss: 1.5285 - rightLayer2_loss: 0.8085 - val_loss: 4.5407 - val_leftLayer1_loss: 0.0805 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.8502 - val_leftLayer2_loss: 0.0729 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.8906\n",
      "Epoch 10/11\n",
      "1946/1950 [============================>.] - ETA: 0s - loss: 4.6135 - leftLayer1_loss: 0.0802 - midLayer1_loss: 1.2760 - rightLayer1_loss: 0.8703 - leftLayer2_loss: 0.0566 - midLayer2_loss: 1.5279 - rightLayer2_loss: 0.8025\n",
      "Epoch 00010: val_loss improved from 4.54067 to 4.50649, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6137 - leftLayer1_loss: 0.0802 - midLayer1_loss: 1.2759 - rightLayer1_loss: 0.8704 - leftLayer2_loss: 0.0566 - midLayer2_loss: 1.5280 - rightLayer2_loss: 0.8027 - val_loss: 4.5065 - val_leftLayer1_loss: 0.0776 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.8340 - val_leftLayer2_loss: 0.0702 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.8781\n",
      "Epoch 11/11\n",
      "1935/1950 [============================>.] - ETA: 0s - loss: 4.5901 - leftLayer1_loss: 0.0773 - midLayer1_loss: 1.2761 - rightLayer1_loss: 0.8560 - leftLayer2_loss: 0.0539 - midLayer2_loss: 1.5288 - rightLayer2_loss: 0.7979\n",
      "Epoch 00011: val_loss improved from 4.50649 to 4.47766, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.5934 - leftLayer1_loss: 0.0774 - midLayer1_loss: 1.2766 - rightLayer1_loss: 0.8569 - leftLayer2_loss: 0.0540 - midLayer2_loss: 1.5293 - rightLayer2_loss: 0.7992 - val_loss: 4.4777 - val_leftLayer1_loss: 0.0749 - val_midLayer1_loss: 1.2550 - val_rightLayer1_loss: 0.8210 - val_leftLayer2_loss: 0.0677 - val_midLayer2_loss: 1.3916 - val_rightLayer2_loss: 0.8675\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Cardiomegaly: 0.6305545084240484\n",
      "\n",
      "auprc 0Cardiomegaly: 0.04588425196880451\n",
      "\n",
      "auroc 1Cardiomegaly: 0.738153954595015\n",
      "\n",
      "auprc 1Cardiomegaly: 0.06849167066692419\n",
      "\n",
      "auroc 2Cardiomegaly: 0.8169045476855826\n",
      "\n",
      "auprc 2Cardiomegaly: 0.10873801582282187\n",
      "\n",
      "auroc 3Cardiomegaly: 0.7755178347071331\n",
      "\n",
      "auprc 3Cardiomegaly: 0.10149348671461744\n",
      "\n",
      "auroc 4Cardiomegaly: 0.5948673623813642\n",
      "\n",
      "auprc 4Cardiomegaly: 0.032669536297862435\n",
      "\n",
      "auroc 5Cardiomegaly: 0.7371136379613191\n",
      "\n",
      "auprc 5Cardiomegaly: 0.0899219268692038\n",
      "\n",
      "mean auroc: 0.7155186409590771\n",
      "\n",
      "mean auprc: 0.0745331480567057\n",
      "\n",
      "max auroc: 0.8169045476855826\n",
      "\n",
      "max auprc: 0.10873801582282187\n",
      "\n",
      "83.037926197052\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 6.4730 - leftLayer1_loss: 0.1283 - midLayer1_loss: 1.4474 - rightLayer1_loss: 1.7198 - leftLayer2_loss: 0.1157 - midLayer2_loss: 1.5266 - rightLayer2_loss: 1.5353\n",
      "Epoch 00001: val_loss improved from inf to 6.08039, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.4729 - leftLayer1_loss: 0.1283 - midLayer1_loss: 1.4474 - rightLayer1_loss: 1.7197 - leftLayer2_loss: 0.1157 - midLayer2_loss: 1.5266 - rightLayer2_loss: 1.5352 - val_loss: 6.0804 - val_leftLayer1_loss: 0.1255 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 1.5814 - val_leftLayer2_loss: 0.1118 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 1.4034\n",
      "Epoch 2/11\n",
      "1936/1950 [============================>.] - ETA: 0s - loss: 5.7813 - leftLayer1_loss: 0.1229 - midLayer1_loss: 1.4474 - rightLayer1_loss: 1.4733 - leftLayer2_loss: 0.1030 - midLayer2_loss: 1.5268 - rightLayer2_loss: 1.1080\n",
      "Epoch 00002: val_loss improved from 6.08039 to 5.62158, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.7822 - leftLayer1_loss: 0.1229 - midLayer1_loss: 1.4477 - rightLayer1_loss: 1.4728 - leftLayer2_loss: 0.1029 - midLayer2_loss: 1.5277 - rightLayer2_loss: 1.1082 - val_loss: 5.6216 - val_leftLayer1_loss: 0.1203 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 1.3599 - val_leftLayer2_loss: 0.1039 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 1.1792\n",
      "Epoch 3/11\n",
      "1932/1950 [============================>.] - ETA: 0s - loss: 5.4328 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4469 - rightLayer1_loss: 1.2881 - leftLayer2_loss: 0.0927 - midLayer2_loss: 1.5320 - rightLayer2_loss: 0.9551\n",
      "Epoch 00003: val_loss improved from 5.62158 to 5.33890, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.4336 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4472 - rightLayer1_loss: 1.2877 - leftLayer2_loss: 0.0927 - midLayer2_loss: 1.5329 - rightLayer2_loss: 0.9552 - val_loss: 5.3389 - val_leftLayer1_loss: 0.1154 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 1.2006 - val_leftLayer2_loss: 0.0971 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 1.0675\n",
      "Epoch 4/11\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 5.2265 - leftLayer1_loss: 0.1133 - midLayer1_loss: 1.4464 - rightLayer1_loss: 1.1589 - leftLayer2_loss: 0.0840 - midLayer2_loss: 1.5343 - rightLayer2_loss: 0.8895\n",
      "Epoch 00004: val_loss improved from 5.33890 to 5.15313, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.2282 - leftLayer1_loss: 0.1133 - midLayer1_loss: 1.4467 - rightLayer1_loss: 1.1591 - leftLayer2_loss: 0.0840 - midLayer2_loss: 1.5350 - rightLayer2_loss: 0.8901 - val_loss: 5.1531 - val_leftLayer1_loss: 0.1107 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 1.0902 - val_leftLayer2_loss: 0.0913 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 1.0025\n",
      "Epoch 5/11\n",
      "1932/1950 [============================>.] - ETA: 0s - loss: 5.0919 - leftLayer1_loss: 0.1089 - midLayer1_loss: 1.4480 - rightLayer1_loss: 1.0708 - leftLayer2_loss: 0.0770 - midLayer2_loss: 1.5328 - rightLayer2_loss: 0.8544\n",
      "Epoch 00005: val_loss improved from 5.15313 to 5.02444, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.0936 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.4484 - rightLayer1_loss: 1.0709 - leftLayer2_loss: 0.0770 - midLayer2_loss: 1.5333 - rightLayer2_loss: 0.8552 - val_loss: 5.0244 - val_leftLayer1_loss: 0.1064 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 1.0134 - val_leftLayer2_loss: 0.0862 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.9601\n",
      "Epoch 6/11\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 5.0000 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4474 - rightLayer1_loss: 1.0085 - leftLayer2_loss: 0.0713 - midLayer2_loss: 1.5332 - rightLayer2_loss: 0.8349\n",
      "Epoch 00006: val_loss improved from 5.02444 to 4.93078, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.0011 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4475 - rightLayer1_loss: 1.0086 - leftLayer2_loss: 0.0713 - midLayer2_loss: 1.5337 - rightLayer2_loss: 0.8352 - val_loss: 4.9308 - val_leftLayer1_loss: 0.1022 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 0.9587 - val_leftLayer2_loss: 0.0818 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.9297\n",
      "Epoch 7/11\n",
      "1936/1950 [============================>.] - ETA: 0s - loss: 4.9266 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.4461 - rightLayer1_loss: 0.9631 - leftLayer2_loss: 0.0665 - midLayer2_loss: 1.5295 - rightLayer2_loss: 0.8206\n",
      "Epoch 00007: val_loss improved from 4.93078 to 4.86011, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.9295 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.4465 - rightLayer1_loss: 0.9638 - leftLayer2_loss: 0.0665 - midLayer2_loss: 1.5303 - rightLayer2_loss: 0.8217 - val_loss: 4.8601 - val_leftLayer1_loss: 0.0984 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 0.9186 - val_leftLayer2_loss: 0.0780 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.9068\n",
      "Epoch 8/11\n",
      "1937/1950 [============================>.] - ETA: 0s - loss: 4.8674 - leftLayer1_loss: 0.0970 - midLayer1_loss: 1.4473 - rightLayer1_loss: 0.9300 - leftLayer2_loss: 0.0622 - midLayer2_loss: 1.5210 - rightLayer2_loss: 0.8099\n",
      "Epoch 00008: val_loss improved from 4.86011 to 4.80473, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8707 - leftLayer1_loss: 0.0970 - midLayer1_loss: 1.4476 - rightLayer1_loss: 0.9308 - leftLayer2_loss: 0.0622 - midLayer2_loss: 1.5220 - rightLayer2_loss: 0.8111 - val_loss: 4.8047 - val_leftLayer1_loss: 0.0947 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 0.8883 - val_leftLayer2_loss: 0.0747 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.8888\n",
      "Epoch 9/11\n",
      "1930/1950 [============================>.] - ETA: 0s - loss: 4.8343 - leftLayer1_loss: 0.0936 - midLayer1_loss: 1.4468 - rightLayer1_loss: 0.9038 - leftLayer2_loss: 0.0588 - midLayer2_loss: 1.5289 - rightLayer2_loss: 0.8024\n",
      "Epoch 00009: val_loss improved from 4.80473 to 4.76013, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8374 - leftLayer1_loss: 0.0936 - midLayer1_loss: 1.4471 - rightLayer1_loss: 0.9045 - leftLayer2_loss: 0.0588 - midLayer2_loss: 1.5296 - rightLayer2_loss: 0.8037 - val_loss: 4.7601 - val_leftLayer1_loss: 0.0913 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 0.8647 - val_leftLayer2_loss: 0.0717 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.8741\n",
      "Epoch 10/11\n",
      "1933/1950 [============================>.] - ETA: 0s - loss: 4.8020 - leftLayer1_loss: 0.0904 - midLayer1_loss: 1.4454 - rightLayer1_loss: 0.8853 - leftLayer2_loss: 0.0559 - midLayer2_loss: 1.5279 - rightLayer2_loss: 0.7971\n",
      "Epoch 00010: val_loss improved from 4.76013 to 4.72367, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8049 - leftLayer1_loss: 0.0904 - midLayer1_loss: 1.4457 - rightLayer1_loss: 0.8860 - leftLayer2_loss: 0.0559 - midLayer2_loss: 1.5287 - rightLayer2_loss: 0.7983 - val_loss: 4.7237 - val_leftLayer1_loss: 0.0881 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 0.8460 - val_leftLayer2_loss: 0.0691 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.8621\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1950 [============================>.] - ETA: 0s - loss: 4.7841 - leftLayer1_loss: 0.0873 - midLayer1_loss: 1.4472 - rightLayer1_loss: 0.8683 - leftLayer2_loss: 0.0534 - midLayer2_loss: 1.5340 - rightLayer2_loss: 0.7940\n",
      "Epoch 00011: val_loss improved from 4.72367 to 4.69299, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7854 - leftLayer1_loss: 0.0873 - midLayer1_loss: 1.4473 - rightLayer1_loss: 0.8686 - leftLayer2_loss: 0.0534 - midLayer2_loss: 1.5345 - rightLayer2_loss: 0.7943 - val_loss: 4.6930 - val_leftLayer1_loss: 0.0851 - val_midLayer1_loss: 1.4383 - val_rightLayer1_loss: 0.8308 - val_leftLayer2_loss: 0.0668 - val_midLayer2_loss: 1.4200 - val_rightLayer2_loss: 0.8519\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Cardiomegaly: 0.6109862940839088\n",
      "\n",
      "auprc 0Cardiomegaly: 0.03318195808001881\n",
      "\n",
      "auroc 1Cardiomegaly: 0.48268670931414437\n",
      "\n",
      "auprc 1Cardiomegaly: 0.023545074426601822\n",
      "\n",
      "auroc 2Cardiomegaly: 0.7237734839881667\n",
      "\n",
      "auprc 2Cardiomegaly: 0.06500090341746981\n",
      "\n",
      "auroc 3Cardiomegaly: 0.5688486737968066\n",
      "\n",
      "auprc 3Cardiomegaly: 0.031834447776353705\n",
      "\n",
      "auroc 4Cardiomegaly: 0.3765890777604838\n",
      "\n",
      "auprc 4Cardiomegaly: 0.019123454108296935\n",
      "\n",
      "auroc 5Cardiomegaly: 0.5639859208909577\n",
      "\n",
      "auprc 5Cardiomegaly: 0.02945283197040363\n",
      "\n",
      "mean auroc: 0.5544783599724113\n",
      "\n",
      "mean auprc: 0.03368977829652412\n",
      "\n",
      "max auroc: 0.7237734839881667\n",
      "\n",
      "max auprc: 0.06500090341746981\n",
      "\n",
      "83.36482906341553\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1950 steps, validate for 240 steps\n",
      "Epoch 1/11\n",
      "1937/1950 [============================>.] - ETA: 0s - loss: 6.3073 - leftLayer1_loss: 0.1237 - midLayer1_loss: 1.3221 - rightLayer1_loss: 1.7429 - leftLayer2_loss: 0.1196 - midLayer2_loss: 1.4144 - rightLayer2_loss: 1.5846\n",
      "Epoch 00001: val_loss improved from inf to 5.94850, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 6s 3ms/step - loss: 6.3064 - leftLayer1_loss: 0.1237 - midLayer1_loss: 1.3229 - rightLayer1_loss: 1.7422 - leftLayer2_loss: 0.1196 - midLayer2_loss: 1.4150 - rightLayer2_loss: 1.5830 - val_loss: 5.9485 - val_leftLayer1_loss: 0.1212 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 1.6042 - val_leftLayer2_loss: 0.1170 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 1.4656\n",
      "Epoch 2/11\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 5.6059 - leftLayer1_loss: 0.1187 - midLayer1_loss: 1.3228 - rightLayer1_loss: 1.4935 - leftLayer2_loss: 0.1072 - midLayer2_loss: 1.4213 - rightLayer2_loss: 1.1425\n",
      "Epoch 00002: val_loss improved from 5.94850 to 5.48244, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.6060 - leftLayer1_loss: 0.1187 - midLayer1_loss: 1.3230 - rightLayer1_loss: 1.4933 - leftLayer2_loss: 0.1072 - midLayer2_loss: 1.4213 - rightLayer2_loss: 1.1425 - val_loss: 5.4824 - val_leftLayer1_loss: 0.1163 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 1.3782 - val_leftLayer2_loss: 0.1095 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 1.2380\n",
      "Epoch 3/11\n",
      "1933/1950 [============================>.] - ETA: 0s - loss: 5.2271 - leftLayer1_loss: 0.1140 - midLayer1_loss: 1.3216 - rightLayer1_loss: 1.3052 - leftLayer2_loss: 0.0972 - midLayer2_loss: 1.4134 - rightLayer2_loss: 0.9756\n",
      "Epoch 00003: val_loss improved from 5.48244 to 5.18920, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 5.2284 - leftLayer1_loss: 0.1140 - midLayer1_loss: 1.3222 - rightLayer1_loss: 1.3051 - leftLayer2_loss: 0.0972 - midLayer2_loss: 1.4139 - rightLayer2_loss: 0.9760 - val_loss: 5.1892 - val_leftLayer1_loss: 0.1116 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 1.2139 - val_leftLayer2_loss: 0.1028 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 1.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1946/1950 [============================>.] - ETA: 0s - loss: 5.0180 - leftLayer1_loss: 0.1096 - midLayer1_loss: 1.3222 - rightLayer1_loss: 1.1726 - leftLayer2_loss: 0.0885 - midLayer2_loss: 1.4210 - rightLayer2_loss: 0.9042\n",
      "Epoch 00004: val_loss improved from 5.18920 to 4.99408, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 2ms/step - loss: 5.0181 - leftLayer1_loss: 0.1096 - midLayer1_loss: 1.3223 - rightLayer1_loss: 1.1725 - leftLayer2_loss: 0.0885 - midLayer2_loss: 1.4209 - rightLayer2_loss: 0.9043 - val_loss: 4.9941 - val_leftLayer1_loss: 0.1072 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 1.0992 - val_leftLayer2_loss: 0.0970 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 1.0502\n",
      "Epoch 5/11\n",
      "1943/1950 [============================>.] - ETA: 0s - loss: 4.8711 - leftLayer1_loss: 0.1054 - midLayer1_loss: 1.3217 - rightLayer1_loss: 1.0799 - leftLayer2_loss: 0.0808 - midLayer2_loss: 1.4190 - rightLayer2_loss: 0.8642\n",
      "Epoch 00005: val_loss improved from 4.99408 to 4.85836, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.8716 - leftLayer1_loss: 0.1054 - midLayer1_loss: 1.3219 - rightLayer1_loss: 1.0801 - leftLayer2_loss: 0.0808 - midLayer2_loss: 1.4191 - rightLayer2_loss: 0.8644 - val_loss: 4.8584 - val_leftLayer1_loss: 0.1031 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 1.0190 - val_leftLayer2_loss: 0.0920 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 1.0039\n",
      "Epoch 6/11\n",
      "1930/1950 [============================>.] - ETA: 0s - loss: 4.7717 - leftLayer1_loss: 0.1015 - midLayer1_loss: 1.3218 - rightLayer1_loss: 1.0137 - leftLayer2_loss: 0.0749 - midLayer2_loss: 1.4190 - rightLayer2_loss: 0.8409\n",
      "Epoch 00006: val_loss improved from 4.85836 to 4.75983, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7745 - leftLayer1_loss: 0.1015 - midLayer1_loss: 1.3224 - rightLayer1_loss: 1.0143 - leftLayer2_loss: 0.0749 - midLayer2_loss: 1.4195 - rightLayer2_loss: 0.8419 - val_loss: 4.7598 - val_leftLayer1_loss: 0.0992 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 0.9619 - val_leftLayer2_loss: 0.0875 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 0.9708\n",
      "Epoch 7/11\n",
      "1939/1950 [============================>.] - ETA: 0s - loss: 4.7042 - leftLayer1_loss: 0.0978 - midLayer1_loss: 1.3212 - rightLayer1_loss: 0.9675 - leftLayer2_loss: 0.0694 - midLayer2_loss: 1.4223 - rightLayer2_loss: 0.8260\n",
      "Epoch 00007: val_loss improved from 4.75983 to 4.68546, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.7074 - leftLayer1_loss: 0.0978 - midLayer1_loss: 1.3219 - rightLayer1_loss: 0.9685 - leftLayer2_loss: 0.0694 - midLayer2_loss: 1.4226 - rightLayer2_loss: 0.8273 - val_loss: 4.6855 - val_leftLayer1_loss: 0.0955 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 0.9201 - val_leftLayer2_loss: 0.0836 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 0.9457\n",
      "Epoch 8/11\n",
      "1945/1950 [============================>.] - ETA: 0s - loss: 4.6541 - leftLayer1_loss: 0.0943 - midLayer1_loss: 1.3217 - rightLayer1_loss: 0.9334 - leftLayer2_loss: 0.0652 - midLayer2_loss: 1.4213 - rightLayer2_loss: 0.8181\n",
      "Epoch 00008: val_loss improved from 4.68546 to 4.62724, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6534 - leftLayer1_loss: 0.0943 - midLayer1_loss: 1.3217 - rightLayer1_loss: 0.9334 - leftLayer2_loss: 0.0652 - midLayer2_loss: 1.4209 - rightLayer2_loss: 0.8179 - val_loss: 4.6272 - val_leftLayer1_loss: 0.0921 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 0.8888 - val_leftLayer2_loss: 0.0802 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 0.9258\n",
      "Epoch 9/11\n",
      "1935/1950 [============================>.] - ETA: 0s - loss: 4.6045 - leftLayer1_loss: 0.0910 - midLayer1_loss: 1.3222 - rightLayer1_loss: 0.9060 - leftLayer2_loss: 0.0614 - midLayer2_loss: 1.4163 - rightLayer2_loss: 0.8075\n",
      "Epoch 00009: val_loss improved from 4.62724 to 4.58071, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.6080 - leftLayer1_loss: 0.0911 - midLayer1_loss: 1.3229 - rightLayer1_loss: 0.9070 - leftLayer2_loss: 0.0615 - midLayer2_loss: 1.4168 - rightLayer2_loss: 0.8088 - val_loss: 4.5807 - val_leftLayer1_loss: 0.0889 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 0.8646 - val_leftLayer2_loss: 0.0771 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 0.9097\n",
      "Epoch 10/11\n",
      "1931/1950 [============================>.] - ETA: 0s - loss: 4.5792 - leftLayer1_loss: 0.0880 - midLayer1_loss: 1.3212 - rightLayer1_loss: 0.8861 - leftLayer2_loss: 0.0581 - midLayer2_loss: 1.4245 - rightLayer2_loss: 0.8013\n",
      "Epoch 00010: val_loss improved from 4.58071 to 4.54227, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.5827 - leftLayer1_loss: 0.0880 - midLayer1_loss: 1.3218 - rightLayer1_loss: 0.8871 - leftLayer2_loss: 0.0581 - midLayer2_loss: 1.4253 - rightLayer2_loss: 0.8024 - val_loss: 4.5423 - val_leftLayer1_loss: 0.0858 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 0.8454 - val_leftLayer2_loss: 0.0744 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 0.8962\n",
      "Epoch 11/11\n",
      "1933/1950 [============================>.] - ETA: 0s - loss: 4.5422 - leftLayer1_loss: 0.0851 - midLayer1_loss: 1.3214 - rightLayer1_loss: 0.8692 - leftLayer2_loss: 0.0554 - midLayer2_loss: 1.4163 - rightLayer2_loss: 0.7948\n",
      "Epoch 00011: val_loss improved from 4.54227 to 4.51002, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1950/1950 [==============================] - 5s 3ms/step - loss: 4.5452 - leftLayer1_loss: 0.0851 - midLayer1_loss: 1.3220 - rightLayer1_loss: 0.8702 - leftLayer2_loss: 0.0554 - midLayer2_loss: 1.4165 - rightLayer2_loss: 0.7960 - val_loss: 4.5100 - val_leftLayer1_loss: 0.0830 - val_midLayer1_loss: 1.3146 - val_rightLayer1_loss: 0.8299 - val_leftLayer2_loss: 0.0720 - val_midLayer2_loss: 1.3258 - val_rightLayer2_loss: 0.8847\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Cardiomegaly: 0.6731887363982335\n",
      "\n",
      "auprc 0Cardiomegaly: 0.053394429375974876\n",
      "\n",
      "auroc 1Cardiomegaly: 0.5890118265836993\n",
      "\n",
      "auprc 1Cardiomegaly: 0.03217496836935916\n",
      "\n",
      "auroc 2Cardiomegaly: 0.6859616701115853\n",
      "\n",
      "auprc 2Cardiomegaly: 0.044551147001205625\n",
      "\n",
      "auroc 3Cardiomegaly: 0.657999602430771\n",
      "\n",
      "auprc 3Cardiomegaly: 0.04226003383581814\n",
      "\n",
      "auroc 4Cardiomegaly: 0.7730815043654767\n",
      "\n",
      "auprc 4Cardiomegaly: 0.07360592350390244\n",
      "\n",
      "auroc 5Cardiomegaly: 0.6064434994836161\n",
      "\n",
      "auprc 5Cardiomegaly: 0.03467744400638598\n",
      "\n",
      "mean auroc: 0.6642811398955636\n",
      "\n",
      "mean auprc: 0.04677732434877437\n",
      "\n",
      "max auroc: 0.7730815043654767\n",
      "\n",
      "max auprc: 0.07360592350390244\n",
      "\n",
      "83.1353178024292\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8574073846911628\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
