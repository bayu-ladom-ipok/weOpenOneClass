{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Nodule\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "405: 4375\n",
      "80: 4375\n",
      "645: 4375\n",
      "1057: 4375\n",
      "605: 4375\n",
      "4375: 4375\n",
      "41: 4375\n",
      "232: 4375\n",
      "289: 4375\n",
      "92: 4375\n",
      "71: 4375\n",
      "114: 4375\n",
      "274: 4375\n",
      "6: 4375\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4360/4375 [============================>.] - ETA: 0s - loss: 6.2818 - leftLayer1_loss: 0.1194 - midLayer1_loss: 1.4080 - rightLayer1_loss: 1.5763 - leftLayer2_loss: 0.1134 - midLayer2_loss: 1.7953 - rightLayer2_loss: 1.2696\n",
      "Epoch 00001: val_loss improved from inf to 5.70534, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 12s 3ms/step - loss: 6.2793 - leftLayer1_loss: 0.1194 - midLayer1_loss: 1.4079 - rightLayer1_loss: 1.5753 - leftLayer2_loss: 0.1133 - midLayer2_loss: 1.7950 - rightLayer2_loss: 1.2684 - val_loss: 5.7053 - val_leftLayer1_loss: 0.1138 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 1.3289 - val_leftLayer2_loss: 0.1087 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 1.1850\n",
      "Epoch 2/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 5.4145 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.4081 - rightLayer1_loss: 1.1579 - leftLayer2_loss: 0.0888 - midLayer2_loss: 1.7928 - rightLayer2_loss: 0.8585\n",
      "Epoch 00002: val_loss improved from 5.70534 to 5.24770, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 5.4145 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.4081 - rightLayer1_loss: 1.1578 - leftLayer2_loss: 0.0888 - midLayer2_loss: 1.7928 - rightLayer2_loss: 0.8585 - val_loss: 5.2477 - val_leftLayer1_loss: 0.1037 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 1.0622 - val_leftLayer2_loss: 0.0945 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 1.0183\n",
      "Epoch 3/11\n",
      "4360/4375 [============================>.] - ETA: 0s - loss: 5.1295 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.4084 - rightLayer1_loss: 0.9703 - leftLayer2_loss: 0.0723 - midLayer2_loss: 1.7962 - rightLayer2_loss: 0.7834\n",
      "Epoch 00003: val_loss improved from 5.24770 to 5.04268, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 5.1284 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.4083 - rightLayer1_loss: 0.9700 - leftLayer2_loss: 0.0723 - midLayer2_loss: 1.7959 - rightLayer2_loss: 0.7831 - val_loss: 5.0427 - val_leftLayer1_loss: 0.0950 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.9447 - val_leftLayer2_loss: 0.0843 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.9496\n",
      "Epoch 4/11\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 4.9859 - leftLayer1_loss: 0.0906 - midLayer1_loss: 1.4079 - rightLayer1_loss: 0.8820 - leftLayer2_loss: 0.0613 - midLayer2_loss: 1.7894 - rightLayer2_loss: 0.7546\n",
      "Epoch 00004: val_loss improved from 5.04268 to 4.92968, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.9859 - leftLayer1_loss: 0.0906 - midLayer1_loss: 1.4079 - rightLayer1_loss: 0.8820 - leftLayer2_loss: 0.0613 - midLayer2_loss: 1.7894 - rightLayer2_loss: 0.7546 - val_loss: 4.9297 - val_leftLayer1_loss: 0.0876 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.8853 - val_leftLayer2_loss: 0.0767 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.9111\n",
      "Epoch 5/11\n",
      "4354/4375 [============================>.] - ETA: 0s - loss: 4.9144 - leftLayer1_loss: 0.0836 - midLayer1_loss: 1.4078 - rightLayer1_loss: 0.8336 - leftLayer2_loss: 0.0540 - midLayer2_loss: 1.7953 - rightLayer2_loss: 0.7400\n",
      "Epoch 00005: val_loss improved from 4.92968 to 4.85803, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.9137 - leftLayer1_loss: 0.0836 - midLayer1_loss: 1.4077 - rightLayer1_loss: 0.8334 - leftLayer2_loss: 0.0540 - midLayer2_loss: 1.7953 - rightLayer2_loss: 0.7399 - val_loss: 4.8580 - val_leftLayer1_loss: 0.0811 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.8508 - val_leftLayer2_loss: 0.0710 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "4354/4375 [============================>.] - ETA: 0s - loss: 4.8611 - leftLayer1_loss: 0.0775 - midLayer1_loss: 1.4074 - rightLayer1_loss: 0.8036 - leftLayer2_loss: 0.0490 - midLayer2_loss: 1.7920 - rightLayer2_loss: 0.7315\n",
      "Epoch 00006: val_loss improved from 4.85803 to 4.80794, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.8602 - leftLayer1_loss: 0.0775 - midLayer1_loss: 1.4073 - rightLayer1_loss: 0.8035 - leftLayer2_loss: 0.0489 - midLayer2_loss: 1.7917 - rightLayer2_loss: 0.7313 - val_loss: 4.8079 - val_leftLayer1_loss: 0.0756 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.8287 - val_leftLayer2_loss: 0.0665 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8681\n",
      "Epoch 7/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.8267 - leftLayer1_loss: 0.0723 - midLayer1_loss: 1.4075 - rightLayer1_loss: 0.7833 - leftLayer2_loss: 0.0450 - midLayer2_loss: 1.7947 - rightLayer2_loss: 0.7240\n",
      "Epoch 00007: val_loss improved from 4.80794 to 4.77103, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.8265 - leftLayer1_loss: 0.0723 - midLayer1_loss: 1.4075 - rightLayer1_loss: 0.7833 - leftLayer2_loss: 0.0450 - midLayer2_loss: 1.7945 - rightLayer2_loss: 0.7240 - val_loss: 4.7710 - val_leftLayer1_loss: 0.0709 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.8135 - val_leftLayer2_loss: 0.0630 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8547\n",
      "Epoch 8/11\n",
      "4354/4375 [============================>.] - ETA: 0s - loss: 4.7978 - leftLayer1_loss: 0.0678 - midLayer1_loss: 1.4090 - rightLayer1_loss: 0.7693 - leftLayer2_loss: 0.0422 - midLayer2_loss: 1.7897 - rightLayer2_loss: 0.7198\n",
      "Epoch 00008: val_loss improved from 4.77103 to 4.74228, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.7972 - leftLayer1_loss: 0.0678 - midLayer1_loss: 1.4088 - rightLayer1_loss: 0.7692 - leftLayer2_loss: 0.0422 - midLayer2_loss: 1.7896 - rightLayer2_loss: 0.7196 - val_loss: 4.7423 - val_leftLayer1_loss: 0.0668 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.8023 - val_leftLayer2_loss: 0.0601 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8440\n",
      "Epoch 9/11\n",
      "4362/4375 [============================>.] - ETA: 0s - loss: 4.7812 - leftLayer1_loss: 0.0639 - midLayer1_loss: 1.4085 - rightLayer1_loss: 0.7584 - leftLayer2_loss: 0.0402 - midLayer2_loss: 1.7942 - rightLayer2_loss: 0.7160\n",
      "Epoch 00009: val_loss improved from 4.74228 to 4.71928, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.7808 - leftLayer1_loss: 0.0639 - midLayer1_loss: 1.4084 - rightLayer1_loss: 0.7582 - leftLayer2_loss: 0.0402 - midLayer2_loss: 1.7942 - rightLayer2_loss: 0.7158 - val_loss: 4.7193 - val_leftLayer1_loss: 0.0632 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.7939 - val_leftLayer2_loss: 0.0577 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8354\n",
      "Epoch 10/11\n",
      "4353/4375 [============================>.] - ETA: 0s - loss: 4.7673 - leftLayer1_loss: 0.0605 - midLayer1_loss: 1.4085 - rightLayer1_loss: 0.7501 - leftLayer2_loss: 0.0385 - midLayer2_loss: 1.7969 - rightLayer2_loss: 0.7128\n",
      "Epoch 00010: val_loss improved from 4.71928 to 4.70040, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.7662 - leftLayer1_loss: 0.0605 - midLayer1_loss: 1.4084 - rightLayer1_loss: 0.7500 - leftLayer2_loss: 0.0384 - midLayer2_loss: 1.7963 - rightLayer2_loss: 0.7126 - val_loss: 4.7004 - val_leftLayer1_loss: 0.0601 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.7873 - val_leftLayer2_loss: 0.0557 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8283\n",
      "Epoch 11/11\n",
      "4368/4375 [============================>.] - ETA: 0s - loss: 4.7485 - leftLayer1_loss: 0.0576 - midLayer1_loss: 1.4084 - rightLayer1_loss: 0.7428 - leftLayer2_loss: 0.0371 - midLayer2_loss: 1.7916 - rightLayer2_loss: 0.7110\n",
      "Epoch 00011: val_loss improved from 4.70040 to 4.68464, saving model to ./experiments/0.009_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.7486 - leftLayer1_loss: 0.0576 - midLayer1_loss: 1.4084 - rightLayer1_loss: 0.7429 - leftLayer2_loss: 0.0371 - midLayer2_loss: 1.7915 - rightLayer2_loss: 0.7111 - val_loss: 4.6846 - val_leftLayer1_loss: 0.0574 - val_midLayer1_loss: 1.4052 - val_rightLayer1_loss: 0.7819 - val_leftLayer2_loss: 0.0540 - val_midLayer2_loss: 1.5638 - val_rightLayer2_loss: 0.8222\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Nodule: 0.5332141818650471\n",
      "\n",
      "auprc 0Nodule: 0.06075253468225625\n",
      "\n",
      "auroc 1Nodule: 0.5489391400856996\n",
      "\n",
      "auprc 1Nodule: 0.06591448875372292\n",
      "\n",
      "auroc 2Nodule: 0.5000832391589383\n",
      "\n",
      "auprc 2Nodule: 0.055415361345449145\n",
      "\n",
      "auroc 3Nodule: 0.48788281758428564\n",
      "\n",
      "auprc 3Nodule: 0.05302282149420139\n",
      "\n",
      "auroc 4Nodule: 0.4897350442007212\n",
      "\n",
      "auprc 4Nodule: 0.056483250170945715\n",
      "\n",
      "auroc 5Nodule: 0.5874940486397879\n",
      "\n",
      "auprc 5Nodule: 0.07416524009418005\n",
      "\n",
      "mean auroc: 0.52455807858908\n",
      "\n",
      "mean auprc: 0.06095894942345925\n",
      "\n",
      "max auroc: 0.5874940486397879\n",
      "\n",
      "max auprc: 0.07416524009418005\n",
      "\n",
      "151.3181607723236\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 5.9636 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.3888 - rightLayer1_loss: 1.5400 - leftLayer2_loss: 0.1194 - midLayer2_loss: 1.5092 - rightLayer2_loss: 1.2878\n",
      "Epoch 00001: val_loss improved from inf to 5.49640, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 12s 3ms/step - loss: 5.9634 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.3888 - rightLayer1_loss: 1.5398 - leftLayer2_loss: 0.1194 - midLayer2_loss: 1.5092 - rightLayer2_loss: 1.2876 - val_loss: 5.4964 - val_leftLayer1_loss: 0.1120 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 1.2711 - val_leftLayer2_loss: 0.1117 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 1.2077\n",
      "Epoch 2/11\n",
      "4361/4375 [============================>.] - ETA: 0s - loss: 5.0685 - leftLayer1_loss: 0.1061 - midLayer1_loss: 1.3891 - rightLayer1_loss: 1.1001 - leftLayer2_loss: 0.0938 - midLayer2_loss: 1.5088 - rightLayer2_loss: 0.8706\n",
      "Epoch 00002: val_loss improved from 5.49640 to 5.04246, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 5.0676 - leftLayer1_loss: 0.1061 - midLayer1_loss: 1.3890 - rightLayer1_loss: 1.0997 - leftLayer2_loss: 0.0938 - midLayer2_loss: 1.5085 - rightLayer2_loss: 0.8704 - val_loss: 5.0425 - val_leftLayer1_loss: 0.1008 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 1.0132 - val_leftLayer2_loss: 0.0976 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 1.0369\n",
      "Epoch 3/11\n",
      "4370/4375 [============================>.] - ETA: 0s - loss: 4.7904 - leftLayer1_loss: 0.0956 - midLayer1_loss: 1.3894 - rightLayer1_loss: 0.9259 - leftLayer2_loss: 0.0767 - midLayer2_loss: 1.5137 - rightLayer2_loss: 0.7891\n",
      "Epoch 00003: val_loss improved from 5.04246 to 4.84723, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.7906 - leftLayer1_loss: 0.0956 - midLayer1_loss: 1.3894 - rightLayer1_loss: 0.9259 - leftLayer2_loss: 0.0767 - midLayer2_loss: 1.5136 - rightLayer2_loss: 0.7893 - val_loss: 4.8472 - val_leftLayer1_loss: 0.0914 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.9096 - val_leftLayer2_loss: 0.0871 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.9653\n",
      "Epoch 4/11\n",
      "4366/4375 [============================>.] - ETA: 0s - loss: 4.6586 - leftLayer1_loss: 0.0868 - midLayer1_loss: 1.3883 - rightLayer1_loss: 0.8485 - leftLayer2_loss: 0.0649 - midLayer2_loss: 1.5099 - rightLayer2_loss: 0.7601\n",
      "Epoch 00004: val_loss improved from 4.84723 to 4.74012, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.6584 - leftLayer1_loss: 0.0868 - midLayer1_loss: 1.3883 - rightLayer1_loss: 0.8486 - leftLayer2_loss: 0.0649 - midLayer2_loss: 1.5098 - rightLayer2_loss: 0.7601 - val_loss: 4.7401 - val_leftLayer1_loss: 0.0835 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.8588 - val_leftLayer2_loss: 0.0793 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.9246\n",
      "Epoch 5/11\n",
      "4365/4375 [============================>.] - ETA: 0s - loss: 4.5858 - leftLayer1_loss: 0.0794 - midLayer1_loss: 1.3887 - rightLayer1_loss: 0.8068 - leftLayer2_loss: 0.0567 - midLayer2_loss: 1.5109 - rightLayer2_loss: 0.7433\n",
      "Epoch 00005: val_loss improved from 4.74012 to 4.67192, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.5854 - leftLayer1_loss: 0.0794 - midLayer1_loss: 1.3887 - rightLayer1_loss: 0.8067 - leftLayer2_loss: 0.0567 - midLayer2_loss: 1.5108 - rightLayer2_loss: 0.7432 - val_loss: 4.6719 - val_leftLayer1_loss: 0.0769 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.8298 - val_leftLayer2_loss: 0.0733 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8980\n",
      "Epoch 6/11\n",
      "4356/4375 [============================>.] - ETA: 0s - loss: 4.5380 - leftLayer1_loss: 0.0731 - midLayer1_loss: 1.3891 - rightLayer1_loss: 0.7821 - leftLayer2_loss: 0.0509 - midLayer2_loss: 1.5089 - rightLayer2_loss: 0.7338\n",
      "Epoch 00006: val_loss improved from 4.67192 to 4.62418, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.5376 - leftLayer1_loss: 0.0731 - midLayer1_loss: 1.3891 - rightLayer1_loss: 0.7819 - leftLayer2_loss: 0.0509 - midLayer2_loss: 1.5090 - rightLayer2_loss: 0.7337 - val_loss: 4.6242 - val_leftLayer1_loss: 0.0713 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.8112 - val_leftLayer2_loss: 0.0687 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8791\n",
      "Epoch 7/11\n",
      "4354/4375 [============================>.] - ETA: 0s - loss: 4.5050 - leftLayer1_loss: 0.0679 - midLayer1_loss: 1.3893 - rightLayer1_loss: 0.7646 - leftLayer2_loss: 0.0468 - midLayer2_loss: 1.5101 - rightLayer2_loss: 0.7263\n",
      "Epoch 00007: val_loss improved from 4.62418 to 4.58864, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.5047 - leftLayer1_loss: 0.0678 - midLayer1_loss: 1.3892 - rightLayer1_loss: 0.7645 - leftLayer2_loss: 0.0468 - midLayer2_loss: 1.5103 - rightLayer2_loss: 0.7261 - val_loss: 4.5886 - val_leftLayer1_loss: 0.0666 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.7984 - val_leftLayer2_loss: 0.0650 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8648\n",
      "Epoch 8/11\n",
      "4370/4375 [============================>.] - ETA: 0s - loss: 4.4808 - leftLayer1_loss: 0.0634 - midLayer1_loss: 1.3893 - rightLayer1_loss: 0.7525 - leftLayer2_loss: 0.0437 - midLayer2_loss: 1.5105 - rightLayer2_loss: 0.7213\n",
      "Epoch 00008: val_loss improved from 4.58864 to 4.56094, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4812 - leftLayer1_loss: 0.0634 - midLayer1_loss: 1.3893 - rightLayer1_loss: 0.7527 - leftLayer2_loss: 0.0437 - midLayer2_loss: 1.5106 - rightLayer2_loss: 0.7215 - val_loss: 4.5609 - val_leftLayer1_loss: 0.0626 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.7890 - val_leftLayer2_loss: 0.0620 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8534\n",
      "Epoch 9/11\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 4.4665 - leftLayer1_loss: 0.0597 - midLayer1_loss: 1.3897 - rightLayer1_loss: 0.7434 - leftLayer2_loss: 0.0413 - midLayer2_loss: 1.5147 - rightLayer2_loss: 0.7176\n",
      "Epoch 00009: val_loss improved from 4.56094 to 4.53877, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4665 - leftLayer1_loss: 0.0597 - midLayer1_loss: 1.3897 - rightLayer1_loss: 0.7434 - leftLayer2_loss: 0.0413 - midLayer2_loss: 1.5147 - rightLayer2_loss: 0.7176 - val_loss: 4.5388 - val_leftLayer1_loss: 0.0592 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.7819 - val_leftLayer2_loss: 0.0595 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8443\n",
      "Epoch 10/11\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 4.4474 - leftLayer1_loss: 0.0565 - midLayer1_loss: 1.3889 - rightLayer1_loss: 0.7364 - leftLayer2_loss: 0.0395 - midLayer2_loss: 1.5122 - rightLayer2_loss: 0.7139\n",
      "Epoch 00010: val_loss improved from 4.53877 to 4.52046, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4474 - leftLayer1_loss: 0.0565 - midLayer1_loss: 1.3889 - rightLayer1_loss: 0.7364 - leftLayer2_loss: 0.0395 - midLayer2_loss: 1.5122 - rightLayer2_loss: 0.7139 - val_loss: 4.5205 - val_leftLayer1_loss: 0.0563 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.7763 - val_leftLayer2_loss: 0.0574 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8366\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4370/4375 [============================>.] - ETA: 0s - loss: 4.4322 - leftLayer1_loss: 0.0537 - midLayer1_loss: 1.3890 - rightLayer1_loss: 0.7306 - leftLayer2_loss: 0.0381 - midLayer2_loss: 1.5092 - rightLayer2_loss: 0.7117\n",
      "Epoch 00011: val_loss improved from 4.52046 to 4.50513, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4326 - leftLayer1_loss: 0.0537 - midLayer1_loss: 1.3890 - rightLayer1_loss: 0.7307 - leftLayer2_loss: 0.0381 - midLayer2_loss: 1.5092 - rightLayer2_loss: 0.7119 - val_loss: 4.5051 - val_leftLayer1_loss: 0.0538 - val_midLayer1_loss: 1.3955 - val_rightLayer1_loss: 0.7717 - val_leftLayer2_loss: 0.0556 - val_midLayer2_loss: 1.3984 - val_rightLayer2_loss: 0.8301\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Nodule: 0.5829634702758626\n",
      "\n",
      "auprc 0Nodule: 0.08316849298769124\n",
      "\n",
      "auroc 1Nodule: 0.5276756623184902\n",
      "\n",
      "auprc 1Nodule: 0.06279376877684072\n",
      "\n",
      "auroc 2Nodule: 0.5230102219604393\n",
      "\n",
      "auprc 2Nodule: 0.05901149327250921\n",
      "\n",
      "auroc 3Nodule: 0.5908832439874842\n",
      "\n",
      "auprc 3Nodule: 0.08424306869058538\n",
      "\n",
      "auroc 4Nodule: 0.3521402706754958\n",
      "\n",
      "auprc 4Nodule: 0.04230653138387535\n",
      "\n",
      "auroc 5Nodule: 0.6000339418366155\n",
      "\n",
      "auprc 5Nodule: 0.07748076920036157\n",
      "\n",
      "mean auroc: 0.5294511351757313\n",
      "\n",
      "mean auprc: 0.06816735405197726\n",
      "\n",
      "max auroc: 0.6000339418366155\n",
      "\n",
      "max auprc: 0.08424306869058538\n",
      "\n",
      "151.56843519210815\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4355/4375 [============================>.] - ETA: 0s - loss: 5.9088 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.3315 - rightLayer1_loss: 1.5471 - leftLayer2_loss: 0.1127 - midLayer2_loss: 1.5305 - rightLayer2_loss: 1.2662\n",
      "Epoch 00001: val_loss improved from inf to 5.48214, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 12s 3ms/step - loss: 5.9058 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.3314 - rightLayer1_loss: 1.5458 - leftLayer2_loss: 0.1127 - midLayer2_loss: 1.5306 - rightLayer2_loss: 1.2645 - val_loss: 5.4821 - val_leftLayer1_loss: 0.1140 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 1.2862 - val_leftLayer2_loss: 0.1066 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 1.2085\n",
      "Epoch 2/11\n",
      "4364/4375 [============================>.] - ETA: 0s - loss: 5.0461 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.3313 - rightLayer1_loss: 1.1207 - leftLayer2_loss: 0.0891 - midLayer2_loss: 1.5291 - rightLayer2_loss: 0.8676\n",
      "Epoch 00002: val_loss improved from 5.48214 to 5.03374, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 5.0457 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.3313 - rightLayer1_loss: 1.1204 - leftLayer2_loss: 0.0890 - midLayer2_loss: 1.5292 - rightLayer2_loss: 0.8674 - val_loss: 5.0337 - val_leftLayer1_loss: 0.1029 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 1.0288 - val_leftLayer2_loss: 0.0936 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 1.0418\n",
      "Epoch 3/11\n",
      "4372/4375 [============================>.] - ETA: 0s - loss: 4.7623 - leftLayer1_loss: 0.0979 - midLayer1_loss: 1.3316 - rightLayer1_loss: 0.9437 - leftLayer2_loss: 0.0730 - midLayer2_loss: 1.5260 - rightLayer2_loss: 0.7900\n",
      "Epoch 00003: val_loss improved from 5.03374 to 4.83703, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.7620 - leftLayer1_loss: 0.0979 - midLayer1_loss: 1.3316 - rightLayer1_loss: 0.9437 - leftLayer2_loss: 0.0730 - midLayer2_loss: 1.5259 - rightLayer2_loss: 0.7899 - val_loss: 4.8370 - val_leftLayer1_loss: 0.0934 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.9221 - val_leftLayer2_loss: 0.0840 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "4366/4375 [============================>.] - ETA: 0s - loss: 4.6373 - leftLayer1_loss: 0.0891 - midLayer1_loss: 1.3330 - rightLayer1_loss: 0.8636 - leftLayer2_loss: 0.0623 - midLayer2_loss: 1.5294 - rightLayer2_loss: 0.7600\n",
      "Epoch 00004: val_loss improved from 4.83703 to 4.72860, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.6375 - leftLayer1_loss: 0.0891 - midLayer1_loss: 1.3330 - rightLayer1_loss: 0.8636 - leftLayer2_loss: 0.0623 - midLayer2_loss: 1.5295 - rightLayer2_loss: 0.7600 - val_loss: 4.7286 - val_leftLayer1_loss: 0.0854 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.8694 - val_leftLayer2_loss: 0.0768 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.9303\n",
      "Epoch 5/11\n",
      "4363/4375 [============================>.] - ETA: 0s - loss: 4.5542 - leftLayer1_loss: 0.0815 - midLayer1_loss: 1.3315 - rightLayer1_loss: 0.8202 - leftLayer2_loss: 0.0549 - midLayer2_loss: 1.5219 - rightLayer2_loss: 0.7441\n",
      "Epoch 00005: val_loss improved from 4.72860 to 4.65946, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.5541 - leftLayer1_loss: 0.0815 - midLayer1_loss: 1.3315 - rightLayer1_loss: 0.8202 - leftLayer2_loss: 0.0549 - midLayer2_loss: 1.5219 - rightLayer2_loss: 0.7441 - val_loss: 4.6595 - val_leftLayer1_loss: 0.0786 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.8391 - val_leftLayer2_loss: 0.0713 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.9037\n",
      "Epoch 6/11\n",
      "4354/4375 [============================>.] - ETA: 0s - loss: 4.5138 - leftLayer1_loss: 0.0752 - midLayer1_loss: 1.3316 - rightLayer1_loss: 0.7939 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.5297 - rightLayer2_loss: 0.7338\n",
      "Epoch 00006: val_loss improved from 4.65946 to 4.61094, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.5130 - leftLayer1_loss: 0.0752 - midLayer1_loss: 1.3315 - rightLayer1_loss: 0.7937 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.5294 - rightLayer2_loss: 0.7336 - val_loss: 4.6109 - val_leftLayer1_loss: 0.0729 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.8197 - val_leftLayer2_loss: 0.0670 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.8846\n",
      "Epoch 7/11\n",
      "4372/4375 [============================>.] - ETA: 0s - loss: 4.4798 - leftLayer1_loss: 0.0699 - midLayer1_loss: 1.3322 - rightLayer1_loss: 0.7761 - leftLayer2_loss: 0.0458 - midLayer2_loss: 1.5287 - rightLayer2_loss: 0.7272\n",
      "Epoch 00007: val_loss improved from 4.61094 to 4.57479, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4796 - leftLayer1_loss: 0.0698 - midLayer1_loss: 1.3322 - rightLayer1_loss: 0.7760 - leftLayer2_loss: 0.0458 - midLayer2_loss: 1.5286 - rightLayer2_loss: 0.7271 - val_loss: 4.5748 - val_leftLayer1_loss: 0.0681 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.8062 - val_leftLayer2_loss: 0.0636 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.8701\n",
      "Epoch 8/11\n",
      "4368/4375 [============================>.] - ETA: 0s - loss: 4.4528 - leftLayer1_loss: 0.0653 - midLayer1_loss: 1.3309 - rightLayer1_loss: 0.7628 - leftLayer2_loss: 0.0432 - midLayer2_loss: 1.5281 - rightLayer2_loss: 0.7225\n",
      "Epoch 00008: val_loss improved from 4.57479 to 4.54652, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4529 - leftLayer1_loss: 0.0653 - midLayer1_loss: 1.3309 - rightLayer1_loss: 0.7629 - leftLayer2_loss: 0.0432 - midLayer2_loss: 1.5281 - rightLayer2_loss: 0.7226 - val_loss: 4.5465 - val_leftLayer1_loss: 0.0640 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.7965 - val_leftLayer2_loss: 0.0608 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.8586\n",
      "Epoch 9/11\n",
      "4358/4375 [============================>.] - ETA: 0s - loss: 4.4333 - leftLayer1_loss: 0.0614 - midLayer1_loss: 1.3315 - rightLayer1_loss: 0.7535 - leftLayer2_loss: 0.0407 - midLayer2_loss: 1.5277 - rightLayer2_loss: 0.7185\n",
      "Epoch 00009: val_loss improved from 4.54652 to 4.52390, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4328 - leftLayer1_loss: 0.0614 - midLayer1_loss: 1.3314 - rightLayer1_loss: 0.7532 - leftLayer2_loss: 0.0407 - midLayer2_loss: 1.5279 - rightLayer2_loss: 0.7182 - val_loss: 4.5239 - val_leftLayer1_loss: 0.0604 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.7890 - val_leftLayer2_loss: 0.0584 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.8493\n",
      "Epoch 10/11\n",
      "4370/4375 [============================>.] - ETA: 0s - loss: 4.4178 - leftLayer1_loss: 0.0580 - midLayer1_loss: 1.3316 - rightLayer1_loss: 0.7449 - leftLayer2_loss: 0.0390 - midLayer2_loss: 1.5288 - rightLayer2_loss: 0.7154\n",
      "Epoch 00010: val_loss improved from 4.52390 to 4.50532, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4182 - leftLayer1_loss: 0.0580 - midLayer1_loss: 1.3317 - rightLayer1_loss: 0.7451 - leftLayer2_loss: 0.0391 - midLayer2_loss: 1.5288 - rightLayer2_loss: 0.7156 - val_loss: 4.5053 - val_leftLayer1_loss: 0.0574 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.7832 - val_leftLayer2_loss: 0.0565 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.8415\n",
      "Epoch 11/11\n",
      "4358/4375 [============================>.] - ETA: 0s - loss: 4.4074 - leftLayer1_loss: 0.0552 - midLayer1_loss: 1.3310 - rightLayer1_loss: 0.7398 - leftLayer2_loss: 0.0376 - midLayer2_loss: 1.5300 - rightLayer2_loss: 0.7137\n",
      "Epoch 00011: val_loss improved from 4.50532 to 4.48972, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4068 - leftLayer1_loss: 0.0552 - midLayer1_loss: 1.3309 - rightLayer1_loss: 0.7395 - leftLayer2_loss: 0.0376 - midLayer2_loss: 1.5301 - rightLayer2_loss: 0.7134 - val_loss: 4.4897 - val_leftLayer1_loss: 0.0548 - val_midLayer1_loss: 1.3332 - val_rightLayer1_loss: 0.7785 - val_leftLayer2_loss: 0.0548 - val_midLayer2_loss: 1.4336 - val_rightLayer2_loss: 0.8349\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Nodule: 0.5809810504430369\n",
      "\n",
      "auprc 0Nodule: 0.08099000583417104\n",
      "\n",
      "auroc 1Nodule: 0.47208573296082523\n",
      "\n",
      "auprc 1Nodule: 0.054511198987996286\n",
      "\n",
      "auroc 2Nodule: 0.5952287931866378\n",
      "\n",
      "auprc 2Nodule: 0.08800051502200379\n",
      "\n",
      "auroc 3Nodule: 0.4805898317216286\n",
      "\n",
      "auprc 3Nodule: 0.05301532377170469\n",
      "\n",
      "auroc 4Nodule: 0.48330801897192455\n",
      "\n",
      "auprc 4Nodule: 0.054441614237324173\n",
      "\n",
      "auroc 5Nodule: 0.49328748700109315\n",
      "\n",
      "auprc 5Nodule: 0.055568359051149374\n",
      "\n",
      "mean auroc: 0.5175801523808577\n",
      "\n",
      "mean auprc: 0.06442116948405822\n",
      "\n",
      "max auroc: 0.5952287931866378\n",
      "\n",
      "max auprc: 0.08800051502200379\n",
      "\n",
      "151.6911907196045\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4369/4375 [============================>.] - ETA: 0s - loss: 5.8612 - leftLayer1_loss: 0.1145 - midLayer1_loss: 1.3560 - rightLayer1_loss: 1.5947 - leftLayer2_loss: 0.1154 - midLayer2_loss: 1.3893 - rightLayer2_loss: 1.2915\n",
      "Epoch 00001: val_loss improved from inf to 5.43301, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 12s 3ms/step - loss: 5.8606 - leftLayer1_loss: 0.1145 - midLayer1_loss: 1.3560 - rightLayer1_loss: 1.5944 - leftLayer2_loss: 0.1153 - midLayer2_loss: 1.3892 - rightLayer2_loss: 1.2912 - val_loss: 5.4330 - val_leftLayer1_loss: 0.1097 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 1.3440 - val_leftLayer2_loss: 0.1076 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 1.1956\n",
      "Epoch 2/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.9783 - leftLayer1_loss: 0.1043 - midLayer1_loss: 1.3560 - rightLayer1_loss: 1.1706 - leftLayer2_loss: 0.0907 - midLayer2_loss: 1.3888 - rightLayer2_loss: 0.8679\n",
      "Epoch 00002: val_loss improved from 5.43301 to 4.96744, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.9782 - leftLayer1_loss: 0.1043 - midLayer1_loss: 1.3560 - rightLayer1_loss: 1.1705 - leftLayer2_loss: 0.0907 - midLayer2_loss: 1.3888 - rightLayer2_loss: 0.8679 - val_loss: 4.9674 - val_leftLayer1_loss: 0.1004 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 1.0713 - val_leftLayer2_loss: 0.0939 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 1.0258\n",
      "Epoch 3/11\n",
      "4359/4375 [============================>.] - ETA: 0s - loss: 4.6791 - leftLayer1_loss: 0.0954 - midLayer1_loss: 1.3558 - rightLayer1_loss: 0.9778 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3880 - rightLayer2_loss: 0.7882\n",
      "Epoch 00003: val_loss improved from 4.96744 to 4.75845, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.6783 - leftLayer1_loss: 0.0954 - midLayer1_loss: 1.3557 - rightLayer1_loss: 0.9775 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3879 - rightLayer2_loss: 0.7880 - val_loss: 4.7584 - val_leftLayer1_loss: 0.0923 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.9506 - val_leftLayer2_loss: 0.0838 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.9557\n",
      "Epoch 4/11\n",
      "4357/4375 [============================>.] - ETA: 0s - loss: 4.5390 - leftLayer1_loss: 0.0877 - midLayer1_loss: 1.3559 - rightLayer1_loss: 0.8869 - leftLayer2_loss: 0.0626 - midLayer2_loss: 1.3869 - rightLayer2_loss: 0.7591\n",
      "Epoch 00004: val_loss improved from 4.75845 to 4.64341, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.5381 - leftLayer1_loss: 0.0877 - midLayer1_loss: 1.3559 - rightLayer1_loss: 0.8865 - leftLayer2_loss: 0.0625 - midLayer2_loss: 1.3866 - rightLayer2_loss: 0.7588 - val_loss: 4.6434 - val_leftLayer1_loss: 0.0853 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.8895 - val_leftLayer2_loss: 0.0764 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.9161\n",
      "Epoch 5/11\n",
      "4356/4375 [============================>.] - ETA: 0s - loss: 4.4572 - leftLayer1_loss: 0.0812 - midLayer1_loss: 1.3563 - rightLayer1_loss: 0.8374 - leftLayer2_loss: 0.0552 - midLayer2_loss: 1.3846 - rightLayer2_loss: 0.7425\n",
      "Epoch 00005: val_loss improved from 4.64341 to 4.57071, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4565 - leftLayer1_loss: 0.0812 - midLayer1_loss: 1.3563 - rightLayer1_loss: 0.8371 - leftLayer2_loss: 0.0551 - midLayer2_loss: 1.3845 - rightLayer2_loss: 0.7423 - val_loss: 4.5707 - val_leftLayer1_loss: 0.0793 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.8541 - val_leftLayer2_loss: 0.0707 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8904\n",
      "Epoch 6/11\n",
      "4358/4375 [============================>.] - ETA: 0s - loss: 4.4132 - leftLayer1_loss: 0.0755 - midLayer1_loss: 1.3563 - rightLayer1_loss: 0.8062 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.3927 - rightLayer2_loss: 0.7328\n",
      "Epoch 00006: val_loss improved from 4.57071 to 4.52031, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.4125 - leftLayer1_loss: 0.0755 - midLayer1_loss: 1.3562 - rightLayer1_loss: 0.8059 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.3927 - rightLayer2_loss: 0.7325 - val_loss: 4.5203 - val_leftLayer1_loss: 0.0742 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.8315 - val_leftLayer2_loss: 0.0663 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8722\n",
      "Epoch 7/11\n",
      "4362/4375 [============================>.] - ETA: 0s - loss: 4.3721 - leftLayer1_loss: 0.0707 - midLayer1_loss: 1.3565 - rightLayer1_loss: 0.7854 - leftLayer2_loss: 0.0457 - midLayer2_loss: 1.3879 - rightLayer2_loss: 0.7259\n",
      "Epoch 00007: val_loss improved from 4.52031 to 4.48283, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.3717 - leftLayer1_loss: 0.0707 - midLayer1_loss: 1.3564 - rightLayer1_loss: 0.7853 - leftLayer2_loss: 0.0457 - midLayer2_loss: 1.3878 - rightLayer2_loss: 0.7258 - val_loss: 4.4828 - val_leftLayer1_loss: 0.0697 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.8159 - val_leftLayer2_loss: 0.0629 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8583\n",
      "Epoch 8/11\n",
      "4359/4375 [============================>.] - ETA: 0s - loss: 4.3447 - leftLayer1_loss: 0.0664 - midLayer1_loss: 1.3560 - rightLayer1_loss: 0.7708 - leftLayer2_loss: 0.0430 - midLayer2_loss: 1.3877 - rightLayer2_loss: 0.7208\n",
      "Epoch 00008: val_loss improved from 4.48283 to 4.45392, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.3442 - leftLayer1_loss: 0.0664 - midLayer1_loss: 1.3559 - rightLayer1_loss: 0.7706 - leftLayer2_loss: 0.0430 - midLayer2_loss: 1.3877 - rightLayer2_loss: 0.7206 - val_loss: 4.4539 - val_leftLayer1_loss: 0.0659 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.8045 - val_leftLayer2_loss: 0.0600 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8474\n",
      "Epoch 9/11\n",
      "4360/4375 [============================>.] - ETA: 0s - loss: 4.3265 - leftLayer1_loss: 0.0628 - midLayer1_loss: 1.3566 - rightLayer1_loss: 0.7597 - leftLayer2_loss: 0.0405 - midLayer2_loss: 1.3898 - rightLayer2_loss: 0.7171\n",
      "Epoch 00009: val_loss improved from 4.45392 to 4.43079, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.3258 - leftLayer1_loss: 0.0628 - midLayer1_loss: 1.3566 - rightLayer1_loss: 0.7596 - leftLayer2_loss: 0.0405 - midLayer2_loss: 1.3896 - rightLayer2_loss: 0.7168 - val_loss: 4.4308 - val_leftLayer1_loss: 0.0625 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.7959 - val_leftLayer2_loss: 0.0577 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8386\n",
      "Epoch 10/11\n",
      "4353/4375 [============================>.] - ETA: 0s - loss: 4.3077 - leftLayer1_loss: 0.0597 - midLayer1_loss: 1.3558 - rightLayer1_loss: 0.7515 - leftLayer2_loss: 0.0388 - midLayer2_loss: 1.3879 - rightLayer2_loss: 0.7140\n",
      "Epoch 00010: val_loss improved from 4.43079 to 4.41176, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.3074 - leftLayer1_loss: 0.0596 - midLayer1_loss: 1.3557 - rightLayer1_loss: 0.7514 - leftLayer2_loss: 0.0388 - midLayer2_loss: 1.3880 - rightLayer2_loss: 0.7139 - val_loss: 4.4118 - val_leftLayer1_loss: 0.0596 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.7891 - val_leftLayer2_loss: 0.0557 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8313\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4370/4375 [============================>.] - ETA: 0s - loss: 4.2940 - leftLayer1_loss: 0.0568 - midLayer1_loss: 1.3561 - rightLayer1_loss: 0.7440 - leftLayer2_loss: 0.0374 - midLayer2_loss: 1.3881 - rightLayer2_loss: 0.7115\n",
      "Epoch 00011: val_loss improved from 4.41176 to 4.39590, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.2943 - leftLayer1_loss: 0.0568 - midLayer1_loss: 1.3562 - rightLayer1_loss: 0.7442 - leftLayer2_loss: 0.0374 - midLayer2_loss: 1.3880 - rightLayer2_loss: 0.7117 - val_loss: 4.3959 - val_leftLayer1_loss: 0.0570 - val_midLayer1_loss: 1.3641 - val_rightLayer1_loss: 0.7836 - val_leftLayer2_loss: 0.0540 - val_midLayer2_loss: 1.3121 - val_rightLayer2_loss: 0.8251\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Nodule: 0.7027865324756983\n",
      "\n",
      "auprc 0Nodule: 0.17196485647360554\n",
      "\n",
      "auroc 1Nodule: 0.37919834068443925\n",
      "\n",
      "auprc 1Nodule: 0.04497395040190226\n",
      "\n",
      "auroc 2Nodule: 0.6306193710606078\n",
      "\n",
      "auprc 2Nodule: 0.09918901867793048\n",
      "\n",
      "auroc 3Nodule: 0.5819622926077449\n",
      "\n",
      "auprc 3Nodule: 0.07461902944841772\n",
      "\n",
      "auroc 4Nodule: 0.4120017943728269\n",
      "\n",
      "auprc 4Nodule: 0.046216487581625935\n",
      "\n",
      "auroc 5Nodule: 0.5354623847406592\n",
      "\n",
      "auprc 5Nodule: 0.06291501468243527\n",
      "\n",
      "mean auroc: 0.540338452656996\n",
      "\n",
      "mean auprc: 0.08331305954431954\n",
      "\n",
      "max auroc: 0.7027865324756983\n",
      "\n",
      "max auprc: 0.17196485647360554\n",
      "\n",
      "151.08675932884216\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4352/4375 [============================>.] - ETA: 0s - loss: 5.9075 - leftLayer1_loss: 0.1250 - midLayer1_loss: 1.3430 - rightLayer1_loss: 1.6547 - leftLayer2_loss: 0.1146 - midLayer2_loss: 1.3882 - rightLayer2_loss: 1.2820\n",
      "Epoch 00001: val_loss improved from inf to 5.52784, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 5.9037 - leftLayer1_loss: 0.1250 - midLayer1_loss: 1.3429 - rightLayer1_loss: 1.6534 - leftLayer2_loss: 0.1146 - midLayer2_loss: 1.3878 - rightLayer2_loss: 1.2800 - val_loss: 5.5278 - val_leftLayer1_loss: 0.1201 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.4236 - val_leftLayer2_loss: 0.1119 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 1.2082\n",
      "Epoch 2/11\n",
      "4365/4375 [============================>.] - ETA: 0s - loss: 5.0669 - leftLayer1_loss: 0.1153 - midLayer1_loss: 1.3427 - rightLayer1_loss: 1.2539 - leftLayer2_loss: 0.0909 - midLayer2_loss: 1.3905 - rightLayer2_loss: 0.8736\n",
      "Epoch 00002: val_loss improved from 5.52784 to 5.05072, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 5.0664 - leftLayer1_loss: 0.1153 - midLayer1_loss: 1.3427 - rightLayer1_loss: 1.2536 - leftLayer2_loss: 0.0909 - midLayer2_loss: 1.3906 - rightLayer2_loss: 0.8734 - val_loss: 5.0507 - val_leftLayer1_loss: 0.1109 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.1392 - val_leftLayer2_loss: 0.0981 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 1.0383\n",
      "Epoch 3/11\n",
      "4369/4375 [============================>.] - ETA: 0s - loss: 4.7449 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.3425 - rightLayer1_loss: 1.0421 - leftLayer2_loss: 0.0746 - midLayer2_loss: 1.3854 - rightLayer2_loss: 0.7936\n",
      "Epoch 00003: val_loss improved from 5.05072 to 4.82068, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.7452 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.3426 - rightLayer1_loss: 1.0421 - leftLayer2_loss: 0.0746 - midLayer2_loss: 1.3855 - rightLayer2_loss: 0.7937 - val_loss: 4.8207 - val_leftLayer1_loss: 0.1028 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.9990 - val_leftLayer2_loss: 0.0879 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.9668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "4353/4375 [============================>.] - ETA: 0s - loss: 4.5914 - leftLayer1_loss: 0.0988 - midLayer1_loss: 1.3431 - rightLayer1_loss: 0.9344 - leftLayer2_loss: 0.0633 - midLayer2_loss: 1.3900 - rightLayer2_loss: 0.7617\n",
      "Epoch 00004: val_loss improved from 4.82068 to 4.69161, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.5910 - leftLayer1_loss: 0.0988 - midLayer1_loss: 1.3430 - rightLayer1_loss: 0.9341 - leftLayer2_loss: 0.0633 - midLayer2_loss: 1.3902 - rightLayer2_loss: 0.7615 - val_loss: 4.6916 - val_leftLayer1_loss: 0.0956 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.9250 - val_leftLayer2_loss: 0.0803 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.9265\n",
      "Epoch 5/11\n",
      "4357/4375 [============================>.] - ETA: 0s - loss: 4.5014 - leftLayer1_loss: 0.0920 - midLayer1_loss: 1.3433 - rightLayer1_loss: 0.8742 - leftLayer2_loss: 0.0558 - midLayer2_loss: 1.3905 - rightLayer2_loss: 0.7455\n",
      "Epoch 00005: val_loss improved from 4.69161 to 4.60973, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.5009 - leftLayer1_loss: 0.0920 - midLayer1_loss: 1.3432 - rightLayer1_loss: 0.8739 - leftLayer2_loss: 0.0558 - midLayer2_loss: 1.3907 - rightLayer2_loss: 0.7453 - val_loss: 4.6097 - val_leftLayer1_loss: 0.0892 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.8816 - val_leftLayer2_loss: 0.0744 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.9003\n",
      "Epoch 6/11\n",
      "4366/4375 [============================>.] - ETA: 0s - loss: 4.4425 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.3433 - rightLayer1_loss: 0.8357 - leftLayer2_loss: 0.0504 - midLayer2_loss: 1.3921 - rightLayer2_loss: 0.7350\n",
      "Epoch 00006: val_loss improved from 4.60973 to 4.55269, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.4425 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.3433 - rightLayer1_loss: 0.8357 - leftLayer2_loss: 0.0504 - midLayer2_loss: 1.3921 - rightLayer2_loss: 0.7350 - val_loss: 4.5527 - val_leftLayer1_loss: 0.0836 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.8537 - val_leftLayer2_loss: 0.0698 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.8814\n",
      "Epoch 7/11\n",
      "4362/4375 [============================>.] - ETA: 0s - loss: 4.3968 - leftLayer1_loss: 0.0806 - midLayer1_loss: 1.3425 - rightLayer1_loss: 0.8100 - leftLayer2_loss: 0.0464 - midLayer2_loss: 1.3888 - rightLayer2_loss: 0.7285\n",
      "Epoch 00007: val_loss improved from 4.55269 to 4.51049, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3965 - leftLayer1_loss: 0.0806 - midLayer1_loss: 1.3425 - rightLayer1_loss: 0.8099 - leftLayer2_loss: 0.0463 - midLayer2_loss: 1.3888 - rightLayer2_loss: 0.7284 - val_loss: 4.5105 - val_leftLayer1_loss: 0.0786 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.8346 - val_leftLayer2_loss: 0.0661 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.8670\n",
      "Epoch 8/11\n",
      "4353/4375 [============================>.] - ETA: 0s - loss: 4.3689 - leftLayer1_loss: 0.0758 - midLayer1_loss: 1.3429 - rightLayer1_loss: 0.7921 - leftLayer2_loss: 0.0435 - midLayer2_loss: 1.3905 - rightLayer2_loss: 0.7241\n",
      "Epoch 00008: val_loss improved from 4.51049 to 4.47772, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3689 - leftLayer1_loss: 0.0758 - midLayer1_loss: 1.3428 - rightLayer1_loss: 0.7919 - leftLayer2_loss: 0.0435 - midLayer2_loss: 1.3908 - rightLayer2_loss: 0.7240 - val_loss: 4.4777 - val_leftLayer1_loss: 0.0743 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.8206 - val_leftLayer2_loss: 0.0631 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.8556\n",
      "Epoch 9/11\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 4.3425 - leftLayer1_loss: 0.0717 - midLayer1_loss: 1.3426 - rightLayer1_loss: 0.7782 - leftLayer2_loss: 0.0412 - midLayer2_loss: 1.3884 - rightLayer2_loss: 0.7204\n",
      "Epoch 00009: val_loss improved from 4.47772 to 4.45151, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.3427 - leftLayer1_loss: 0.0717 - midLayer1_loss: 1.3426 - rightLayer1_loss: 0.7782 - leftLayer2_loss: 0.0412 - midLayer2_loss: 1.3885 - rightLayer2_loss: 0.7205 - val_loss: 4.4515 - val_leftLayer1_loss: 0.0704 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.8101 - val_leftLayer2_loss: 0.0606 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.8463\n",
      "Epoch 10/11\n",
      "4366/4375 [============================>.] - ETA: 0s - loss: 4.3236 - leftLayer1_loss: 0.0680 - midLayer1_loss: 1.3433 - rightLayer1_loss: 0.7681 - leftLayer2_loss: 0.0393 - midLayer2_loss: 1.3889 - rightLayer2_loss: 0.7160\n",
      "Epoch 00010: val_loss improved from 4.45151 to 4.43020, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3236 - leftLayer1_loss: 0.0680 - midLayer1_loss: 1.3432 - rightLayer1_loss: 0.7681 - leftLayer2_loss: 0.0393 - midLayer2_loss: 1.3889 - rightLayer2_loss: 0.7160 - val_loss: 4.4302 - val_leftLayer1_loss: 0.0670 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.8018 - val_leftLayer2_loss: 0.0585 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.8388\n",
      "Epoch 11/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.3079 - leftLayer1_loss: 0.0648 - midLayer1_loss: 1.3426 - rightLayer1_loss: 0.7596 - leftLayer2_loss: 0.0380 - midLayer2_loss: 1.3895 - rightLayer2_loss: 0.7134\n",
      "Epoch 00011: val_loss improved from 4.43020 to 4.41230, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3081 - leftLayer1_loss: 0.0648 - midLayer1_loss: 1.3426 - rightLayer1_loss: 0.7597 - leftLayer2_loss: 0.0380 - midLayer2_loss: 1.3896 - rightLayer2_loss: 0.7135 - val_loss: 4.4123 - val_leftLayer1_loss: 0.0640 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.7951 - val_leftLayer2_loss: 0.0566 - val_midLayer2_loss: 1.3164 - val_rightLayer2_loss: 0.8324\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Nodule: 0.6198576608606954\n",
      "\n",
      "auprc 0Nodule: 0.08421633058888356\n",
      "\n",
      "auroc 1Nodule: 0.6806761242257019\n",
      "\n",
      "auprc 1Nodule: 0.12307364496361035\n",
      "\n",
      "auroc 2Nodule: 0.44701791141961733\n",
      "\n",
      "auprc 2Nodule: 0.0494284856147318\n",
      "\n",
      "auroc 3Nodule: 0.6076715118993475\n",
      "\n",
      "auprc 3Nodule: 0.08478413197018199\n",
      "\n",
      "auroc 4Nodule: 0.5302580644703173\n",
      "\n",
      "auprc 4Nodule: 0.06450694317747283\n",
      "\n",
      "auroc 5Nodule: 0.4941056059771717\n",
      "\n",
      "auprc 5Nodule: 0.05516131358499533\n",
      "\n",
      "mean auroc: 0.5632644798088086\n",
      "\n",
      "mean auprc: 0.07686180831664596\n",
      "\n",
      "max auroc: 0.6806761242257019\n",
      "\n",
      "max auprc: 0.12307364496361035\n",
      "\n",
      "145.343022108078\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4353/4375 [============================>.] - ETA: 0s - loss: 5.9279 - leftLayer1_loss: 0.1189 - midLayer1_loss: 1.3506 - rightLayer1_loss: 1.5585 - leftLayer2_loss: 0.1117 - midLayer2_loss: 1.4808 - rightLayer2_loss: 1.3072\n",
      "Epoch 00001: val_loss improved from inf to 5.40873, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 5.9242 - leftLayer1_loss: 0.1189 - midLayer1_loss: 1.3506 - rightLayer1_loss: 1.5571 - leftLayer2_loss: 0.1116 - midLayer2_loss: 1.4807 - rightLayer2_loss: 1.3053 - val_loss: 5.4087 - val_leftLayer1_loss: 0.1129 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 1.2913 - val_leftLayer2_loss: 0.1066 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 1.2106\n",
      "Epoch 2/11\n",
      "4363/4375 [============================>.] - ETA: 0s - loss: 5.0160 - leftLayer1_loss: 0.1067 - midLayer1_loss: 1.3504 - rightLayer1_loss: 1.1155 - leftLayer2_loss: 0.0883 - midLayer2_loss: 1.4819 - rightLayer2_loss: 0.8733\n",
      "Epoch 00002: val_loss improved from 5.40873 to 4.94771, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 5.0154 - leftLayer1_loss: 0.1067 - midLayer1_loss: 1.3504 - rightLayer1_loss: 1.1151 - leftLayer2_loss: 0.0883 - midLayer2_loss: 1.4817 - rightLayer2_loss: 0.8731 - val_loss: 4.9477 - val_leftLayer1_loss: 0.1018 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 1.0277 - val_leftLayer2_loss: 0.0937 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 1.0372\n",
      "Epoch 3/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.7268 - leftLayer1_loss: 0.0963 - midLayer1_loss: 1.3497 - rightLayer1_loss: 0.9365 - leftLayer2_loss: 0.0726 - midLayer2_loss: 1.4811 - rightLayer2_loss: 0.7906\n",
      "Epoch 00003: val_loss improved from 4.94771 to 4.74911, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.7270 - leftLayer1_loss: 0.0963 - midLayer1_loss: 1.3498 - rightLayer1_loss: 0.9365 - leftLayer2_loss: 0.0726 - midLayer2_loss: 1.4813 - rightLayer2_loss: 0.7906 - val_loss: 4.7491 - val_leftLayer1_loss: 0.0924 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.9200 - val_leftLayer2_loss: 0.0842 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.9653\n",
      "Epoch 4/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.5957 - leftLayer1_loss: 0.0874 - midLayer1_loss: 1.3493 - rightLayer1_loss: 0.8565 - leftLayer2_loss: 0.0620 - midLayer2_loss: 1.4803 - rightLayer2_loss: 0.7602\n",
      "Epoch 00004: val_loss improved from 4.74911 to 4.64041, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.5958 - leftLayer1_loss: 0.0874 - midLayer1_loss: 1.3494 - rightLayer1_loss: 0.8565 - leftLayer2_loss: 0.0620 - midLayer2_loss: 1.4803 - rightLayer2_loss: 0.7602 - val_loss: 4.6404 - val_leftLayer1_loss: 0.0845 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.8670 - val_leftLayer2_loss: 0.0770 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.9246\n",
      "Epoch 5/11\n",
      "4365/4375 [============================>.] - ETA: 0s - loss: 4.5250 - leftLayer1_loss: 0.0800 - midLayer1_loss: 1.3504 - rightLayer1_loss: 0.8133 - leftLayer2_loss: 0.0550 - midLayer2_loss: 1.4818 - rightLayer2_loss: 0.7446\n",
      "Epoch 00005: val_loss improved from 4.64041 to 4.57115, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.5248 - leftLayer1_loss: 0.0800 - midLayer1_loss: 1.3504 - rightLayer1_loss: 0.8131 - leftLayer2_loss: 0.0550 - midLayer2_loss: 1.4819 - rightLayer2_loss: 0.7444 - val_loss: 4.5712 - val_leftLayer1_loss: 0.0778 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.8366 - val_leftLayer2_loss: 0.0715 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8979\n",
      "Epoch 6/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.4749 - leftLayer1_loss: 0.0737 - midLayer1_loss: 1.3502 - rightLayer1_loss: 0.7871 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.4804 - rightLayer2_loss: 0.7339\n",
      "Epoch 00006: val_loss improved from 4.57115 to 4.52284, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.4751 - leftLayer1_loss: 0.0737 - midLayer1_loss: 1.3502 - rightLayer1_loss: 0.7872 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.4805 - rightLayer2_loss: 0.7339 - val_loss: 4.5228 - val_leftLayer1_loss: 0.0721 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.8172 - val_leftLayer2_loss: 0.0673 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8789\n",
      "Epoch 7/11\n",
      "4353/4375 [============================>.] - ETA: 0s - loss: 4.4404 - leftLayer1_loss: 0.0685 - midLayer1_loss: 1.3496 - rightLayer1_loss: 0.7703 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.4797 - rightLayer2_loss: 0.7264\n",
      "Epoch 00007: val_loss improved from 4.52284 to 4.48691, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.4397 - leftLayer1_loss: 0.0685 - midLayer1_loss: 1.3496 - rightLayer1_loss: 0.7701 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.4795 - rightLayer2_loss: 0.7262 - val_loss: 4.4869 - val_leftLayer1_loss: 0.0674 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.8037 - val_leftLayer2_loss: 0.0638 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8647\n",
      "Epoch 8/11\n",
      "4357/4375 [============================>.] - ETA: 0s - loss: 4.4169 - leftLayer1_loss: 0.0640 - midLayer1_loss: 1.3496 - rightLayer1_loss: 0.7575 - leftLayer2_loss: 0.0430 - midLayer2_loss: 1.4818 - rightLayer2_loss: 0.7209\n",
      "Epoch 00008: val_loss improved from 4.48691 to 4.45906, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.4160 - leftLayer1_loss: 0.0640 - midLayer1_loss: 1.3496 - rightLayer1_loss: 0.7573 - leftLayer2_loss: 0.0430 - midLayer2_loss: 1.4815 - rightLayer2_loss: 0.7206 - val_loss: 4.4591 - val_leftLayer1_loss: 0.0633 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.7939 - val_leftLayer2_loss: 0.0610 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8535\n",
      "Epoch 9/11\n",
      "4357/4375 [============================>.] - ETA: 0s - loss: 4.3956 - leftLayer1_loss: 0.0602 - midLayer1_loss: 1.3498 - rightLayer1_loss: 0.7481 - leftLayer2_loss: 0.0408 - midLayer2_loss: 1.4786 - rightLayer2_loss: 0.7180\n",
      "Epoch 00009: val_loss improved from 4.45906 to 4.43662, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3948 - leftLayer1_loss: 0.0602 - midLayer1_loss: 1.3498 - rightLayer1_loss: 0.7479 - leftLayer2_loss: 0.0408 - midLayer2_loss: 1.4785 - rightLayer2_loss: 0.7177 - val_loss: 4.4366 - val_leftLayer1_loss: 0.0599 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.7865 - val_leftLayer2_loss: 0.0586 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8443\n",
      "Epoch 10/11\n",
      "4371/4375 [============================>.] - ETA: 0s - loss: 4.3846 - leftLayer1_loss: 0.0570 - midLayer1_loss: 1.3503 - rightLayer1_loss: 0.7404 - leftLayer2_loss: 0.0390 - midLayer2_loss: 1.4837 - rightLayer2_loss: 0.7142\n",
      "Epoch 00010: val_loss improved from 4.43662 to 4.41820, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3846 - leftLayer1_loss: 0.0570 - midLayer1_loss: 1.3504 - rightLayer1_loss: 0.7405 - leftLayer2_loss: 0.0390 - midLayer2_loss: 1.4836 - rightLayer2_loss: 0.7142 - val_loss: 4.4182 - val_leftLayer1_loss: 0.0569 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.7807 - val_leftLayer2_loss: 0.0566 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8367\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4367/4375 [============================>.] - ETA: 0s - loss: 4.3671 - leftLayer1_loss: 0.0541 - midLayer1_loss: 1.3496 - rightLayer1_loss: 0.7344 - leftLayer2_loss: 0.0376 - midLayer2_loss: 1.4788 - rightLayer2_loss: 0.7126\n",
      "Epoch 00011: val_loss improved from 4.41820 to 4.40278, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3670 - leftLayer1_loss: 0.0541 - midLayer1_loss: 1.3497 - rightLayer1_loss: 0.7344 - leftLayer2_loss: 0.0376 - midLayer2_loss: 1.4787 - rightLayer2_loss: 0.7126 - val_loss: 4.4028 - val_leftLayer1_loss: 0.0543 - val_midLayer1_loss: 1.3523 - val_rightLayer1_loss: 0.7760 - val_leftLayer2_loss: 0.0549 - val_midLayer2_loss: 1.3350 - val_rightLayer2_loss: 0.8303\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Nodule: 0.5754144649740484\n",
      "\n",
      "auprc 0Nodule: 0.07674711570011476\n",
      "\n",
      "auroc 1Nodule: 0.42335755772153705\n",
      "\n",
      "auprc 1Nodule: 0.04695281318536163\n",
      "\n",
      "auroc 2Nodule: 0.5666084755890382\n",
      "\n",
      "auprc 2Nodule: 0.07405042504545142\n",
      "\n",
      "auroc 3Nodule: 0.5086750150803296\n",
      "\n",
      "auprc 3Nodule: 0.05895444323078333\n",
      "\n",
      "auroc 4Nodule: 0.27367235405454055\n",
      "\n",
      "auprc 4Nodule: 0.0371705263956547\n",
      "\n",
      "auroc 5Nodule: 0.49887576542214446\n",
      "\n",
      "auprc 5Nodule: 0.05464561575478753\n",
      "\n",
      "mean auroc: 0.4744339388069397\n",
      "\n",
      "mean auprc: 0.058086823218692234\n",
      "\n",
      "max auroc: 0.5754144649740484\n",
      "\n",
      "max auprc: 0.07674711570011476\n",
      "\n",
      "144.03850054740906\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 4375 steps, validate for 613 steps\n",
      "Epoch 1/11\n",
      "4370/4375 [============================>.] - ETA: 0s - loss: 5.8312 - leftLayer1_loss: 0.1254 - midLayer1_loss: 1.3127 - rightLayer1_loss: 1.5949 - leftLayer2_loss: 0.1152 - midLayer2_loss: 1.3743 - rightLayer2_loss: 1.3089\n",
      "Epoch 00001: val_loss improved from inf to 5.41194, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 12s 3ms/step - loss: 5.8311 - leftLayer1_loss: 0.1254 - midLayer1_loss: 1.3128 - rightLayer1_loss: 1.5947 - leftLayer2_loss: 0.1151 - midLayer2_loss: 1.3744 - rightLayer2_loss: 1.3087 - val_loss: 5.4119 - val_leftLayer1_loss: 0.1195 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 1.3603 - val_leftLayer2_loss: 0.1091 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 1.2085\n",
      "Epoch 2/11\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 4.9522 - leftLayer1_loss: 0.1146 - midLayer1_loss: 1.3121 - rightLayer1_loss: 1.1926 - leftLayer2_loss: 0.0906 - midLayer2_loss: 1.3711 - rightLayer2_loss: 0.8712\n",
      "Epoch 00002: val_loss improved from 5.41194 to 4.94434, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.9520 - leftLayer1_loss: 0.1146 - midLayer1_loss: 1.3121 - rightLayer1_loss: 1.1926 - leftLayer2_loss: 0.0906 - midLayer2_loss: 1.3710 - rightLayer2_loss: 0.8711 - val_loss: 4.9443 - val_leftLayer1_loss: 0.1095 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 1.0921 - val_leftLayer2_loss: 0.0953 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 1.0329\n",
      "Epoch 3/11\n",
      "4357/4375 [============================>.] - ETA: 0s - loss: 4.6543 - leftLayer1_loss: 0.1051 - midLayer1_loss: 1.3133 - rightLayer1_loss: 0.9996 - leftLayer2_loss: 0.0741 - midLayer2_loss: 1.3725 - rightLayer2_loss: 0.7898\n",
      "Epoch 00003: val_loss improved from 4.94434 to 4.72838, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.6535 - leftLayer1_loss: 0.1051 - midLayer1_loss: 1.3132 - rightLayer1_loss: 0.9992 - leftLayer2_loss: 0.0740 - midLayer2_loss: 1.3726 - rightLayer2_loss: 0.7895 - val_loss: 4.7284 - val_leftLayer1_loss: 0.1008 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.9672 - val_leftLayer2_loss: 0.0851 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "4362/4375 [============================>.] - ETA: 0s - loss: 4.5102 - leftLayer1_loss: 0.0967 - midLayer1_loss: 1.3119 - rightLayer1_loss: 0.9037 - leftLayer2_loss: 0.0629 - midLayer2_loss: 1.3760 - rightLayer2_loss: 0.7590\n",
      "Epoch 00004: val_loss improved from 4.72838 to 4.60829, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.5097 - leftLayer1_loss: 0.0967 - midLayer1_loss: 1.3119 - rightLayer1_loss: 0.9036 - leftLayer2_loss: 0.0628 - midLayer2_loss: 1.3758 - rightLayer2_loss: 0.7588 - val_loss: 4.6083 - val_leftLayer1_loss: 0.0932 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.9026 - val_leftLayer2_loss: 0.0776 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.9204\n",
      "Epoch 5/11\n",
      "4362/4375 [============================>.] - ETA: 0s - loss: 4.4255 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.8510 - leftLayer2_loss: 0.0553 - midLayer2_loss: 1.3738 - rightLayer2_loss: 0.7433\n",
      "Epoch 00005: val_loss improved from 4.60829 to 4.53167, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.4251 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.8509 - leftLayer2_loss: 0.0553 - midLayer2_loss: 1.3737 - rightLayer2_loss: 0.7432 - val_loss: 4.5317 - val_leftLayer1_loss: 0.0866 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.8646 - val_leftLayer2_loss: 0.0718 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8941\n",
      "Epoch 6/11\n",
      "4363/4375 [============================>.] - ETA: 0s - loss: 4.3728 - leftLayer1_loss: 0.0832 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.8178 - leftLayer2_loss: 0.0499 - midLayer2_loss: 1.3753 - rightLayer2_loss: 0.7340\n",
      "Epoch 00006: val_loss improved from 4.53167 to 4.47815, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3727 - leftLayer1_loss: 0.0832 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.8178 - leftLayer2_loss: 0.0499 - midLayer2_loss: 1.3752 - rightLayer2_loss: 0.7340 - val_loss: 4.4781 - val_leftLayer1_loss: 0.0808 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.8401 - val_leftLayer2_loss: 0.0673 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8753\n",
      "Epoch 7/11\n",
      "4358/4375 [============================>.] - ETA: 0s - loss: 4.3343 - leftLayer1_loss: 0.0777 - midLayer1_loss: 1.3127 - rightLayer1_loss: 0.7955 - leftLayer2_loss: 0.0460 - midLayer2_loss: 1.3768 - rightLayer2_loss: 0.7255\n",
      "Epoch 00007: val_loss improved from 4.47815 to 4.43863, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3333 - leftLayer1_loss: 0.0776 - midLayer1_loss: 1.3127 - rightLayer1_loss: 0.7952 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.7252 - val_loss: 4.4386 - val_leftLayer1_loss: 0.0758 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.8232 - val_leftLayer2_loss: 0.0638 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8613\n",
      "Epoch 8/11\n",
      "4360/4375 [============================>.] - ETA: 0s - loss: 4.3053 - leftLayer1_loss: 0.0729 - midLayer1_loss: 1.3122 - rightLayer1_loss: 0.7795 - leftLayer2_loss: 0.0429 - midLayer2_loss: 1.3770 - rightLayer2_loss: 0.7209\n",
      "Epoch 00008: val_loss improved from 4.43863 to 4.40795, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.3048 - leftLayer1_loss: 0.0728 - midLayer1_loss: 1.3121 - rightLayer1_loss: 0.7793 - leftLayer2_loss: 0.0429 - midLayer2_loss: 1.3770 - rightLayer2_loss: 0.7207 - val_loss: 4.4080 - val_leftLayer1_loss: 0.0714 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.8109 - val_leftLayer2_loss: 0.0609 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8503\n",
      "Epoch 9/11\n",
      "4362/4375 [============================>.] - ETA: 0s - loss: 4.2797 - leftLayer1_loss: 0.0687 - midLayer1_loss: 1.3122 - rightLayer1_loss: 0.7673 - leftLayer2_loss: 0.0408 - midLayer2_loss: 1.3730 - rightLayer2_loss: 0.7177\n",
      "Epoch 00009: val_loss improved from 4.40795 to 4.38328, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.2795 - leftLayer1_loss: 0.0687 - midLayer1_loss: 1.3122 - rightLayer1_loss: 0.7672 - leftLayer2_loss: 0.0408 - midLayer2_loss: 1.3731 - rightLayer2_loss: 0.7176 - val_loss: 4.3833 - val_leftLayer1_loss: 0.0676 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.8015 - val_leftLayer2_loss: 0.0584 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8412\n",
      "Epoch 10/11\n",
      "4355/4375 [============================>.] - ETA: 0s - loss: 4.2661 - leftLayer1_loss: 0.0651 - midLayer1_loss: 1.3123 - rightLayer1_loss: 0.7585 - leftLayer2_loss: 0.0391 - midLayer2_loss: 1.3767 - rightLayer2_loss: 0.7144\n",
      "Epoch 00010: val_loss improved from 4.38328 to 4.36299, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 2ms/step - loss: 4.2653 - leftLayer1_loss: 0.0650 - midLayer1_loss: 1.3123 - rightLayer1_loss: 0.7582 - leftLayer2_loss: 0.0391 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.7141 - val_loss: 4.3630 - val_leftLayer1_loss: 0.0642 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.7942 - val_leftLayer2_loss: 0.0564 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8336\n",
      "Epoch 11/11\n",
      "4365/4375 [============================>.] - ETA: 0s - loss: 4.2474 - leftLayer1_loss: 0.0619 - midLayer1_loss: 1.3125 - rightLayer1_loss: 0.7507 - leftLayer2_loss: 0.0375 - midLayer2_loss: 1.3728 - rightLayer2_loss: 0.7121\n",
      "Epoch 00011: val_loss improved from 4.36299 to 4.34613, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "4375/4375 [==============================] - 11s 3ms/step - loss: 4.2470 - leftLayer1_loss: 0.0618 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.7506 - leftLayer2_loss: 0.0375 - midLayer2_loss: 1.3726 - rightLayer2_loss: 0.7120 - val_loss: 4.3461 - val_leftLayer1_loss: 0.0613 - val_midLayer1_loss: 1.3156 - val_rightLayer1_loss: 0.7883 - val_leftLayer2_loss: 0.0547 - val_midLayer2_loss: 1.2990 - val_rightLayer2_loss: 0.8274\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Nodule: 0.4984077692721997\n",
      "\n",
      "auprc 0Nodule: 0.056249086105223334\n",
      "\n",
      "auroc 1Nodule: 0.49405219018931806\n",
      "\n",
      "auprc 1Nodule: 0.05499764480178204\n",
      "\n",
      "auroc 2Nodule: 0.5502366342479522\n",
      "\n",
      "auprc 2Nodule: 0.0684551738034291\n",
      "\n",
      "auroc 3Nodule: 0.5343214455245948\n",
      "\n",
      "auprc 3Nodule: 0.06452052628532146\n",
      "\n",
      "auroc 4Nodule: 0.39688436307398\n",
      "\n",
      "auprc 4Nodule: 0.04574057773474592\n",
      "\n",
      "auroc 5Nodule: 0.4606996491848456\n",
      "\n",
      "auprc 5Nodule: 0.05088301499283113\n",
      "\n",
      "mean auroc: 0.48910034191548163\n",
      "\n",
      "mean auprc: 0.056807670620555493\n",
      "\n",
      "max auroc: 0.5502366342479522\n",
      "\n",
      "max auprc: 0.0684551738034291\n",
      "\n",
      "147.83062958717346\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7027865324756983\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
