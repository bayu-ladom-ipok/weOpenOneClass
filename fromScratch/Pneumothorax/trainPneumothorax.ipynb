{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Pneumothorax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "522: 3705\n",
      "32: 3705\n",
      "711: 3705\n",
      "662: 3705\n",
      "291: 3705\n",
      "232: 3705\n",
      "23: 3705\n",
      "3705: 3705\n",
      "173: 3705\n",
      "24: 3705\n",
      "539: 3705\n",
      "62: 3705\n",
      "192: 3705\n",
      "7: 3705\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3699/3705 [============================>.] - ETA: 0s - loss: 6.0644 - leftLayer1_loss: 0.1243 - midLayer1_loss: 1.3393 - rightLayer1_loss: 1.6334 - leftLayer2_loss: 0.1132 - midLayer2_loss: 1.4822 - rightLayer2_loss: 1.3719\n",
      "Epoch 00001: val_loss improved from inf to 5.70248, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 6.0634 - leftLayer1_loss: 0.1243 - midLayer1_loss: 1.3393 - rightLayer1_loss: 1.6330 - leftLayer2_loss: 0.1132 - midLayer2_loss: 1.4822 - rightLayer2_loss: 1.3714 - val_loss: 5.7025 - val_leftLayer1_loss: 0.1199 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 1.4342 - val_leftLayer2_loss: 0.1115 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 1.3333\n",
      "Epoch 2/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 5.2405 - leftLayer1_loss: 0.1153 - midLayer1_loss: 1.3393 - rightLayer1_loss: 1.2669 - leftLayer2_loss: 0.0941 - midLayer2_loss: 1.4805 - rightLayer2_loss: 0.9444\n",
      "Epoch 00002: val_loss improved from 5.70248 to 5.22806, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.2396 - leftLayer1_loss: 0.1153 - midLayer1_loss: 1.3393 - rightLayer1_loss: 1.2665 - leftLayer2_loss: 0.0941 - midLayer2_loss: 1.4802 - rightLayer2_loss: 0.9443 - val_loss: 5.2281 - val_leftLayer1_loss: 0.1116 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 1.1703 - val_leftLayer2_loss: 0.1010 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 1.1416\n",
      "Epoch 3/11\n",
      "3698/3705 [============================>.] - ETA: 0s - loss: 4.9166 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.3396 - rightLayer1_loss: 1.0703 - leftLayer2_loss: 0.0798 - midLayer2_loss: 1.4766 - rightLayer2_loss: 0.8431\n",
      "Epoch 00003: val_loss improved from 5.22806 to 4.98521, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 12s 3ms/step - loss: 4.9163 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.3395 - rightLayer1_loss: 1.0702 - leftLayer2_loss: 0.0798 - midLayer2_loss: 1.4765 - rightLayer2_loss: 0.8431 - val_loss: 4.9852 - val_leftLayer1_loss: 0.1042 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 1.0307 - val_leftLayer2_loss: 0.0926 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 1.0541\n",
      "Epoch 4/11\n",
      "3698/3705 [============================>.] - ETA: 0s - loss: 4.7560 - leftLayer1_loss: 0.0999 - midLayer1_loss: 1.3385 - rightLayer1_loss: 0.9668 - leftLayer2_loss: 0.0696 - midLayer2_loss: 1.4758 - rightLayer2_loss: 0.8054\n",
      "Epoch 00004: val_loss improved from 4.98521 to 4.84119, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 12s 3ms/step - loss: 4.7559 - leftLayer1_loss: 0.0999 - midLayer1_loss: 1.3385 - rightLayer1_loss: 0.9668 - leftLayer2_loss: 0.0696 - midLayer2_loss: 1.4759 - rightLayer2_loss: 0.8054 - val_loss: 4.8412 - val_leftLayer1_loss: 0.0975 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.9518 - val_leftLayer2_loss: 0.0859 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 1.0023\n",
      "Epoch 5/11\n",
      "3691/3705 [============================>.] - ETA: 0s - loss: 4.6656 - leftLayer1_loss: 0.0934 - midLayer1_loss: 1.3392 - rightLayer1_loss: 0.9066 - leftLayer2_loss: 0.0620 - midLayer2_loss: 1.4800 - rightLayer2_loss: 0.7844\n",
      "Epoch 00005: val_loss improved from 4.84119 to 4.74651, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.6660 - leftLayer1_loss: 0.0934 - midLayer1_loss: 1.3392 - rightLayer1_loss: 0.9067 - leftLayer2_loss: 0.0620 - midLayer2_loss: 1.4800 - rightLayer2_loss: 0.7846 - val_loss: 4.7465 - val_leftLayer1_loss: 0.0916 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.9030 - val_leftLayer2_loss: 0.0806 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.9677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "3693/3705 [============================>.] - ETA: 0s - loss: 4.6033 - leftLayer1_loss: 0.0876 - midLayer1_loss: 1.3394 - rightLayer1_loss: 0.8681 - leftLayer2_loss: 0.0564 - midLayer2_loss: 1.4802 - rightLayer2_loss: 0.7717\n",
      "Epoch 00006: val_loss improved from 4.74651 to 4.67896, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6037 - leftLayer1_loss: 0.0876 - midLayer1_loss: 1.3394 - rightLayer1_loss: 0.8682 - leftLayer2_loss: 0.0563 - midLayer2_loss: 1.4803 - rightLayer2_loss: 0.7718 - val_loss: 4.6790 - val_leftLayer1_loss: 0.0863 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.8705 - val_leftLayer2_loss: 0.0762 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.9423\n",
      "Epoch 7/11\n",
      "3690/3705 [============================>.] - ETA: 0s - loss: 4.5639 - leftLayer1_loss: 0.0825 - midLayer1_loss: 1.3392 - rightLayer1_loss: 0.8424 - leftLayer2_loss: 0.0521 - midLayer2_loss: 1.4847 - rightLayer2_loss: 0.7629\n",
      "Epoch 00007: val_loss improved from 4.67896 to 4.62816, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5642 - leftLayer1_loss: 0.0825 - midLayer1_loss: 1.3393 - rightLayer1_loss: 0.8425 - leftLayer2_loss: 0.0521 - midLayer2_loss: 1.4848 - rightLayer2_loss: 0.7630 - val_loss: 4.6282 - val_leftLayer1_loss: 0.0816 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.8474 - val_leftLayer2_loss: 0.0726 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.9229\n",
      "Epoch 8/11\n",
      "3687/3705 [============================>.] - ETA: 0s - loss: 4.5256 - leftLayer1_loss: 0.0780 - midLayer1_loss: 1.3391 - rightLayer1_loss: 0.8237 - leftLayer2_loss: 0.0484 - midLayer2_loss: 1.4802 - rightLayer2_loss: 0.7561\n",
      "Epoch 00008: val_loss improved from 4.62816 to 4.58831, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.5258 - leftLayer1_loss: 0.0780 - midLayer1_loss: 1.3391 - rightLayer1_loss: 0.8239 - leftLayer2_loss: 0.0484 - midLayer2_loss: 1.4801 - rightLayer2_loss: 0.7563 - val_loss: 4.5883 - val_leftLayer1_loss: 0.0775 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.8302 - val_leftLayer2_loss: 0.0696 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.9074\n",
      "Epoch 9/11\n",
      "3700/3705 [============================>.] - ETA: 0s - loss: 4.4999 - leftLayer1_loss: 0.0740 - midLayer1_loss: 1.3387 - rightLayer1_loss: 0.8102 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.4792 - rightLayer2_loss: 0.7520\n",
      "Epoch 00009: val_loss improved from 4.58831 to 4.55596, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.5000 - leftLayer1_loss: 0.0739 - midLayer1_loss: 1.3387 - rightLayer1_loss: 0.8102 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.4792 - rightLayer2_loss: 0.7520 - val_loss: 4.5560 - val_leftLayer1_loss: 0.0737 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.8170 - val_leftLayer2_loss: 0.0670 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.8946\n",
      "Epoch 10/11\n",
      "3692/3705 [============================>.] - ETA: 0s - loss: 4.4815 - leftLayer1_loss: 0.0703 - midLayer1_loss: 1.3392 - rightLayer1_loss: 0.7987 - leftLayer2_loss: 0.0441 - midLayer2_loss: 1.4809 - rightLayer2_loss: 0.7483\n",
      "Epoch 00010: val_loss improved from 4.55596 to 4.52909, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 9s 3ms/step - loss: 4.4823 - leftLayer1_loss: 0.0703 - midLayer1_loss: 1.3393 - rightLayer1_loss: 0.7990 - leftLayer2_loss: 0.0441 - midLayer2_loss: 1.4807 - rightLayer2_loss: 0.7487 - val_loss: 4.5291 - val_leftLayer1_loss: 0.0704 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.8065 - val_leftLayer2_loss: 0.0648 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.8837\n",
      "Epoch 11/11\n",
      "3694/3705 [============================>.] - ETA: 0s - loss: 4.4674 - leftLayer1_loss: 0.0672 - midLayer1_loss: 1.3397 - rightLayer1_loss: 0.7901 - leftLayer2_loss: 0.0421 - midLayer2_loss: 1.4826 - rightLayer2_loss: 0.7457\n",
      "Epoch 00011: val_loss improved from 4.52909 to 4.50639, saving model to ./experiments/0.009_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.4678 - leftLayer1_loss: 0.0672 - midLayer1_loss: 1.3398 - rightLayer1_loss: 0.7902 - leftLayer2_loss: 0.0421 - midLayer2_loss: 1.4827 - rightLayer2_loss: 0.7459 - val_loss: 4.5064 - val_leftLayer1_loss: 0.0674 - val_midLayer1_loss: 1.3429 - val_rightLayer1_loss: 0.7980 - val_leftLayer2_loss: 0.0629 - val_midLayer2_loss: 1.3607 - val_rightLayer2_loss: 0.8745\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Pneumothorax: 0.6143768250172434\n",
      "\n",
      "auprc 0Pneumothorax: 0.09012963395122647\n",
      "\n",
      "auroc 1Pneumothorax: 0.6104780340545981\n",
      "\n",
      "auprc 1Pneumothorax: 0.06757716585932577\n",
      "\n",
      "auroc 2Pneumothorax: 0.6008141547339279\n",
      "\n",
      "auprc 2Pneumothorax: 0.07656741685760293\n",
      "\n",
      "auroc 3Pneumothorax: 0.3422067375403207\n",
      "\n",
      "auprc 3Pneumothorax: 0.0332302270482702\n",
      "\n",
      "auroc 4Pneumothorax: 0.5257889306035687\n",
      "\n",
      "auprc 4Pneumothorax: 0.04807923413001699\n",
      "\n",
      "auroc 5Pneumothorax: 0.34279025260097223\n",
      "\n",
      "auprc 5Pneumothorax: 0.03349428214423373\n",
      "\n",
      "mean auroc: 0.5060758224251052\n",
      "\n",
      "mean auprc: 0.058179659998446015\n",
      "\n",
      "max auroc: 0.6143768250172434\n",
      "\n",
      "max auprc: 0.09012963395122647\n",
      "\n",
      "145.4396104812622\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3701/3705 [============================>.] - ETA: 0s - loss: 6.2111 - leftLayer1_loss: 0.1167 - midLayer1_loss: 1.4155 - rightLayer1_loss: 1.6141 - leftLayer2_loss: 0.1159 - midLayer2_loss: 1.6046 - rightLayer2_loss: 1.3444\n",
      "Epoch 00001: val_loss improved from inf to 5.73546, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 6.2105 - leftLayer1_loss: 0.1167 - midLayer1_loss: 1.4155 - rightLayer1_loss: 1.6138 - leftLayer2_loss: 0.1159 - midLayer2_loss: 1.6045 - rightLayer2_loss: 1.3441 - val_loss: 5.7355 - val_leftLayer1_loss: 0.1119 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 1.3985 - val_leftLayer2_loss: 0.1132 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 1.2620\n",
      "Epoch 2/11\n",
      "3687/3705 [============================>.] - ETA: 0s - loss: 5.3869 - leftLayer1_loss: 0.1078 - midLayer1_loss: 1.4162 - rightLayer1_loss: 1.2359 - leftLayer2_loss: 0.0946 - midLayer2_loss: 1.6045 - rightLayer2_loss: 0.9278\n",
      "Epoch 00002: val_loss improved from 5.73546 to 5.26292, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.3863 - leftLayer1_loss: 0.1078 - midLayer1_loss: 1.4162 - rightLayer1_loss: 1.2354 - leftLayer2_loss: 0.0946 - midLayer2_loss: 1.6045 - rightLayer2_loss: 0.9278 - val_loss: 5.2629 - val_leftLayer1_loss: 0.1038 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 1.1308 - val_leftLayer2_loss: 0.1008 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 1.0778\n",
      "Epoch 3/11\n",
      "3698/3705 [============================>.] - ETA: 0s - loss: 5.0750 - leftLayer1_loss: 0.1000 - midLayer1_loss: 1.4167 - rightLayer1_loss: 1.0421 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.5985 - rightLayer2_loss: 0.8381\n",
      "Epoch 00003: val_loss improved from 5.26292 to 5.03039, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.0750 - leftLayer1_loss: 0.0999 - midLayer1_loss: 1.4167 - rightLayer1_loss: 1.0420 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.5987 - rightLayer2_loss: 0.8382 - val_loss: 5.0304 - val_leftLayer1_loss: 0.0965 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.9965 - val_leftLayer2_loss: 0.0912 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.9964\n",
      "Epoch 4/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 4.9302 - leftLayer1_loss: 0.0930 - midLayer1_loss: 1.4160 - rightLayer1_loss: 0.9437 - leftLayer2_loss: 0.0687 - midLayer2_loss: 1.6086 - rightLayer2_loss: 0.8002\n",
      "Epoch 00004: val_loss improved from 5.03039 to 4.89687, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.9306 - leftLayer1_loss: 0.0930 - midLayer1_loss: 1.4160 - rightLayer1_loss: 0.9438 - leftLayer2_loss: 0.0687 - midLayer2_loss: 1.6087 - rightLayer2_loss: 0.8004 - val_loss: 4.8969 - val_leftLayer1_loss: 0.0901 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.9231 - val_leftLayer2_loss: 0.0838 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.9500\n",
      "Epoch 5/11\n",
      "3699/3705 [============================>.] - ETA: 0s - loss: 4.8313 - leftLayer1_loss: 0.0869 - midLayer1_loss: 1.4165 - rightLayer1_loss: 0.8873 - leftLayer2_loss: 0.0610 - midLayer2_loss: 1.5982 - rightLayer2_loss: 0.7816\n",
      "Epoch 00005: val_loss improved from 4.89687 to 4.81039, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.8315 - leftLayer1_loss: 0.0869 - midLayer1_loss: 1.4165 - rightLayer1_loss: 0.8873 - leftLayer2_loss: 0.0610 - midLayer2_loss: 1.5981 - rightLayer2_loss: 0.7818 - val_loss: 4.8104 - val_leftLayer1_loss: 0.0844 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.8787 - val_leftLayer2_loss: 0.0779 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.9195\n",
      "Epoch 6/11\n",
      "3692/3705 [============================>.] - ETA: 0s - loss: 4.7772 - leftLayer1_loss: 0.0815 - midLayer1_loss: 1.4157 - rightLayer1_loss: 0.8527 - leftLayer2_loss: 0.0550 - midLayer2_loss: 1.6028 - rightLayer2_loss: 0.7696\n",
      "Epoch 00006: val_loss improved from 4.81039 to 4.74939, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7782 - leftLayer1_loss: 0.0815 - midLayer1_loss: 1.4158 - rightLayer1_loss: 0.8529 - leftLayer2_loss: 0.0550 - midLayer2_loss: 1.6030 - rightLayer2_loss: 0.7700 - val_loss: 4.7494 - val_leftLayer1_loss: 0.0795 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.8495 - val_leftLayer2_loss: 0.0732 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.8974\n",
      "Epoch 7/11\n",
      "3692/3705 [============================>.] - ETA: 0s - loss: 4.7383 - leftLayer1_loss: 0.0767 - midLayer1_loss: 1.4162 - rightLayer1_loss: 0.8290 - leftLayer2_loss: 0.0507 - midLayer2_loss: 1.6040 - rightLayer2_loss: 0.7616\n",
      "Epoch 00007: val_loss improved from 4.74939 to 4.70376, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.7392 - leftLayer1_loss: 0.0767 - midLayer1_loss: 1.4163 - rightLayer1_loss: 0.8294 - leftLayer2_loss: 0.0508 - midLayer2_loss: 1.6040 - rightLayer2_loss: 0.7621 - val_loss: 4.7038 - val_leftLayer1_loss: 0.0750 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.8290 - val_leftLayer2_loss: 0.0694 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.8805\n",
      "Epoch 8/11\n",
      "3691/3705 [============================>.] - ETA: 0s - loss: 4.7094 - leftLayer1_loss: 0.0725 - midLayer1_loss: 1.4163 - rightLayer1_loss: 0.8120 - leftLayer2_loss: 0.0476 - midLayer2_loss: 1.6057 - rightLayer2_loss: 0.7553\n",
      "Epoch 00008: val_loss improved from 4.70376 to 4.66822, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.7097 - leftLayer1_loss: 0.0725 - midLayer1_loss: 1.4163 - rightLayer1_loss: 0.8122 - leftLayer2_loss: 0.0476 - midLayer2_loss: 1.6055 - rightLayer2_loss: 0.7555 - val_loss: 4.6682 - val_leftLayer1_loss: 0.0711 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.8138 - val_leftLayer2_loss: 0.0662 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.8672\n",
      "Epoch 9/11\n",
      "3695/3705 [============================>.] - ETA: 0s - loss: 4.6838 - leftLayer1_loss: 0.0688 - midLayer1_loss: 1.4160 - rightLayer1_loss: 0.7995 - leftLayer2_loss: 0.0450 - midLayer2_loss: 1.6031 - rightLayer2_loss: 0.7514\n",
      "Epoch 00009: val_loss improved from 4.66822 to 4.63963, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 12s 3ms/step - loss: 4.6839 - leftLayer1_loss: 0.0688 - midLayer1_loss: 1.4159 - rightLayer1_loss: 0.7996 - leftLayer2_loss: 0.0450 - midLayer2_loss: 1.6030 - rightLayer2_loss: 0.7516 - val_loss: 4.6396 - val_leftLayer1_loss: 0.0677 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.8022 - val_leftLayer2_loss: 0.0636 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.8563\n",
      "Epoch 10/11\n",
      "3684/3705 [============================>.] - ETA: 0s - loss: 4.6639 - leftLayer1_loss: 0.0655 - midLayer1_loss: 1.4161 - rightLayer1_loss: 0.7898 - leftLayer2_loss: 0.0431 - midLayer2_loss: 1.6017 - rightLayer2_loss: 0.7478\n",
      "Epoch 00010: val_loss improved from 4.63963 to 4.61604, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.6638 - leftLayer1_loss: 0.0655 - midLayer1_loss: 1.4160 - rightLayer1_loss: 0.7897 - leftLayer2_loss: 0.0430 - midLayer2_loss: 1.6017 - rightLayer2_loss: 0.7477 - val_loss: 4.6160 - val_leftLayer1_loss: 0.0646 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.7930 - val_leftLayer2_loss: 0.0613 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.8472\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3697/3705 [============================>.] - ETA: 0s - loss: 4.6521 - leftLayer1_loss: 0.0626 - midLayer1_loss: 1.4159 - rightLayer1_loss: 0.7819 - leftLayer2_loss: 0.0414 - midLayer2_loss: 1.6046 - rightLayer2_loss: 0.7456\n",
      "Epoch 00011: val_loss improved from 4.61604 to 4.59612, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6523 - leftLayer1_loss: 0.0626 - midLayer1_loss: 1.4159 - rightLayer1_loss: 0.7820 - leftLayer2_loss: 0.0414 - midLayer2_loss: 1.6047 - rightLayer2_loss: 0.7457 - val_loss: 4.5961 - val_leftLayer1_loss: 0.0619 - val_midLayer1_loss: 1.4058 - val_rightLayer1_loss: 0.7856 - val_leftLayer2_loss: 0.0594 - val_midLayer2_loss: 1.4440 - val_rightLayer2_loss: 0.8394\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Pneumothorax: 0.6371718367744501\n",
      "\n",
      "auprc 0Pneumothorax: 0.07350588334798666\n",
      "\n",
      "auroc 1Pneumothorax: 0.3206415043167121\n",
      "\n",
      "auprc 1Pneumothorax: 0.0323283309702635\n",
      "\n",
      "auroc 2Pneumothorax: 0.6578750268460811\n",
      "\n",
      "auprc 2Pneumothorax: 0.09123116914726159\n",
      "\n",
      "auroc 3Pneumothorax: 0.4448730352454626\n",
      "\n",
      "auprc 3Pneumothorax: 0.04176844170334609\n",
      "\n",
      "auroc 4Pneumothorax: 0.5410104219584423\n",
      "\n",
      "auprc 4Pneumothorax: 0.05874833405848391\n",
      "\n",
      "auroc 5Pneumothorax: 0.6459462460574121\n",
      "\n",
      "auprc 5Pneumothorax: 0.08208535505811582\n",
      "\n",
      "mean auroc: 0.5412530118664267\n",
      "\n",
      "mean auprc: 0.06327791904757626\n",
      "\n",
      "max auroc: 0.6578750268460811\n",
      "\n",
      "max auprc: 0.09123116914726159\n",
      "\n",
      "142.69108390808105\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3695/3705 [============================>.] - ETA: 0s - loss: 6.2276 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.4255 - rightLayer1_loss: 1.6219 - leftLayer2_loss: 0.1191 - midLayer2_loss: 1.5320 - rightLayer2_loss: 1.4059\n",
      "Epoch 00001: val_loss improved from inf to 5.75109, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 6.2260 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.4255 - rightLayer1_loss: 1.6213 - leftLayer2_loss: 0.1191 - midLayer2_loss: 1.5319 - rightLayer2_loss: 1.4049 - val_loss: 5.7511 - val_leftLayer1_loss: 0.1182 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 1.4125 - val_leftLayer2_loss: 0.1122 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 1.3071\n",
      "Epoch 2/11\n",
      "3699/3705 [============================>.] - ETA: 0s - loss: 5.3742 - leftLayer1_loss: 0.1138 - midLayer1_loss: 1.4254 - rightLayer1_loss: 1.2494 - leftLayer2_loss: 0.0979 - midLayer2_loss: 1.5390 - rightLayer2_loss: 0.9487\n",
      "Epoch 00002: val_loss improved from 5.75109 to 5.26796, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.3742 - leftLayer1_loss: 0.1138 - midLayer1_loss: 1.4255 - rightLayer1_loss: 1.2492 - leftLayer2_loss: 0.0979 - midLayer2_loss: 1.5391 - rightLayer2_loss: 0.9486 - val_loss: 5.2680 - val_leftLayer1_loss: 0.1096 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 1.1455 - val_leftLayer2_loss: 0.1006 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 1.1112\n",
      "Epoch 3/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 5.0428 - leftLayer1_loss: 0.1055 - midLayer1_loss: 1.4257 - rightLayer1_loss: 1.0548 - leftLayer2_loss: 0.0823 - midLayer2_loss: 1.5303 - rightLayer2_loss: 0.8442\n",
      "Epoch 00003: val_loss improved from 5.26796 to 5.02711, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.0432 - leftLayer1_loss: 0.1055 - midLayer1_loss: 1.4258 - rightLayer1_loss: 1.0547 - leftLayer2_loss: 0.0823 - midLayer2_loss: 1.5306 - rightLayer2_loss: 0.8443 - val_loss: 5.0271 - val_leftLayer1_loss: 0.1019 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 1.0082 - val_leftLayer2_loss: 0.0916 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 1.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 4.8875 - leftLayer1_loss: 0.0980 - midLayer1_loss: 1.4250 - rightLayer1_loss: 0.9536 - leftLayer2_loss: 0.0713 - midLayer2_loss: 1.5347 - rightLayer2_loss: 0.8049\n",
      "Epoch 00004: val_loss improved from 5.02711 to 4.88729, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.8879 - leftLayer1_loss: 0.0980 - midLayer1_loss: 1.4250 - rightLayer1_loss: 0.9537 - leftLayer2_loss: 0.0712 - midLayer2_loss: 1.5348 - rightLayer2_loss: 0.8051 - val_loss: 4.8873 - val_leftLayer1_loss: 0.0951 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.9325 - val_leftLayer2_loss: 0.0845 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.9742\n",
      "Epoch 5/11\n",
      "3703/3705 [============================>.] - ETA: 0s - loss: 4.7979 - leftLayer1_loss: 0.0915 - midLayer1_loss: 1.4250 - rightLayer1_loss: 0.8969 - leftLayer2_loss: 0.0631 - midLayer2_loss: 1.5378 - rightLayer2_loss: 0.7837\n",
      "Epoch 00005: val_loss improved from 4.88729 to 4.79642, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7978 - leftLayer1_loss: 0.0915 - midLayer1_loss: 1.4250 - rightLayer1_loss: 0.8967 - leftLayer2_loss: 0.0631 - midLayer2_loss: 1.5380 - rightLayer2_loss: 0.7836 - val_loss: 4.7964 - val_leftLayer1_loss: 0.0890 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.8864 - val_leftLayer2_loss: 0.0788 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.9411\n",
      "Epoch 6/11\n",
      "3704/3705 [============================>.] - ETA: 0s - loss: 4.7418 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.4263 - rightLayer1_loss: 0.8597 - leftLayer2_loss: 0.0569 - midLayer2_loss: 1.5419 - rightLayer2_loss: 0.7713\n",
      "Epoch 00006: val_loss improved from 4.79642 to 4.73227, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7418 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.4263 - rightLayer1_loss: 0.8597 - leftLayer2_loss: 0.0569 - midLayer2_loss: 1.5419 - rightLayer2_loss: 0.7714 - val_loss: 4.7323 - val_leftLayer1_loss: 0.0837 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.8559 - val_leftLayer2_loss: 0.0743 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.9173\n",
      "Epoch 7/11\n",
      "3697/3705 [============================>.] - ETA: 0s - loss: 4.6882 - leftLayer1_loss: 0.0805 - midLayer1_loss: 1.4255 - rightLayer1_loss: 0.8355 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.5317 - rightLayer2_loss: 0.7626\n",
      "Epoch 00007: val_loss improved from 4.73227 to 4.68407, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 4.6883 - leftLayer1_loss: 0.0805 - midLayer1_loss: 1.4256 - rightLayer1_loss: 0.8355 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.5316 - rightLayer2_loss: 0.7627 - val_loss: 4.6841 - val_leftLayer1_loss: 0.0790 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.8345 - val_leftLayer2_loss: 0.0705 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.8990\n",
      "Epoch 8/11\n",
      "3695/3705 [============================>.] - ETA: 0s - loss: 4.6573 - leftLayer1_loss: 0.0760 - midLayer1_loss: 1.4262 - rightLayer1_loss: 0.8178 - leftLayer2_loss: 0.0489 - midLayer2_loss: 1.5322 - rightLayer2_loss: 0.7561\n",
      "Epoch 00008: val_loss improved from 4.68407 to 4.64628, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6577 - leftLayer1_loss: 0.0760 - midLayer1_loss: 1.4263 - rightLayer1_loss: 0.8179 - leftLayer2_loss: 0.0489 - midLayer2_loss: 1.5325 - rightLayer2_loss: 0.7562 - val_loss: 4.6463 - val_leftLayer1_loss: 0.0748 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.8187 - val_leftLayer2_loss: 0.0674 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.8844\n",
      "Epoch 9/11\n",
      "3703/3705 [============================>.] - ETA: 0s - loss: 4.6327 - leftLayer1_loss: 0.0720 - midLayer1_loss: 1.4248 - rightLayer1_loss: 0.8048 - leftLayer2_loss: 0.0460 - midLayer2_loss: 1.5333 - rightLayer2_loss: 0.7518\n",
      "Epoch 00009: val_loss improved from 4.64628 to 4.61586, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6324 - leftLayer1_loss: 0.0720 - midLayer1_loss: 1.4248 - rightLayer1_loss: 0.8046 - leftLayer2_loss: 0.0460 - midLayer2_loss: 1.5332 - rightLayer2_loss: 0.7517 - val_loss: 4.6159 - val_leftLayer1_loss: 0.0711 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.8065 - val_leftLayer2_loss: 0.0648 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.8724\n",
      "Epoch 10/11\n",
      "3683/3705 [============================>.] - ETA: 0s - loss: 4.6165 - leftLayer1_loss: 0.0685 - midLayer1_loss: 1.4257 - rightLayer1_loss: 0.7942 - leftLayer2_loss: 0.0439 - midLayer2_loss: 1.5364 - rightLayer2_loss: 0.7478\n",
      "Epoch 00010: val_loss improved from 4.61586 to 4.59074, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6164 - leftLayer1_loss: 0.0685 - midLayer1_loss: 1.4257 - rightLayer1_loss: 0.7942 - leftLayer2_loss: 0.0439 - midLayer2_loss: 1.5363 - rightLayer2_loss: 0.7478 - val_loss: 4.5907 - val_leftLayer1_loss: 0.0678 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.7969 - val_leftLayer2_loss: 0.0625 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.8625\n",
      "Epoch 11/11\n",
      "3685/3705 [============================>.] - ETA: 0s - loss: 4.6024 - leftLayer1_loss: 0.0653 - midLayer1_loss: 1.4257 - rightLayer1_loss: 0.7858 - leftLayer2_loss: 0.0421 - midLayer2_loss: 1.5384 - rightLayer2_loss: 0.7450\n",
      "Epoch 00011: val_loss improved from 4.59074 to 4.56957, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6025 - leftLayer1_loss: 0.0653 - midLayer1_loss: 1.4257 - rightLayer1_loss: 0.7859 - leftLayer2_loss: 0.0421 - midLayer2_loss: 1.5383 - rightLayer2_loss: 0.7451 - val_loss: 4.5696 - val_leftLayer1_loss: 0.0648 - val_midLayer1_loss: 1.4129 - val_rightLayer1_loss: 0.7891 - val_leftLayer2_loss: 0.0606 - val_midLayer2_loss: 1.3882 - val_rightLayer2_loss: 0.8540\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Pneumothorax: 0.5878752901441842\n",
      "\n",
      "auprc 0Pneumothorax: 0.07133339837554947\n",
      "\n",
      "auroc 1Pneumothorax: 0.5800110447531055\n",
      "\n",
      "auprc 1Pneumothorax: 0.056677840007642075\n",
      "\n",
      "auroc 2Pneumothorax: 0.5988259313869236\n",
      "\n",
      "auprc 2Pneumothorax: 0.06875714138402347\n",
      "\n",
      "auroc 3Pneumothorax: 0.4459189138213263\n",
      "\n",
      "auprc 3Pneumothorax: 0.04071831480668515\n",
      "\n",
      "auroc 4Pneumothorax: 0.4029896424033163\n",
      "\n",
      "auprc 4Pneumothorax: 0.037418541609975826\n",
      "\n",
      "auroc 5Pneumothorax: 0.4813077276788603\n",
      "\n",
      "auprc 5Pneumothorax: 0.04422714376221927\n",
      "\n",
      "mean auroc: 0.5161547583646194\n",
      "\n",
      "mean auprc: 0.05318872999101588\n",
      "\n",
      "max auroc: 0.5988259313869236\n",
      "\n",
      "max auprc: 0.07133339837554947\n",
      "\n",
      "136.738920211792\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3690/3705 [============================>.] - ETA: 0s - loss: 5.9544 - leftLayer1_loss: 0.1191 - midLayer1_loss: 1.3975 - rightLayer1_loss: 1.5684 - leftLayer2_loss: 0.1205 - midLayer2_loss: 1.4410 - rightLayer2_loss: 1.3079\n",
      "Epoch 00001: val_loss improved from inf to 5.58265, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.9523 - leftLayer1_loss: 0.1191 - midLayer1_loss: 1.3975 - rightLayer1_loss: 1.5675 - leftLayer2_loss: 0.1205 - midLayer2_loss: 1.4409 - rightLayer2_loss: 1.3068 - val_loss: 5.5826 - val_leftLayer1_loss: 0.1136 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 1.3464 - val_leftLayer2_loss: 0.1114 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 1.2660\n",
      "Epoch 2/11\n",
      "3702/3705 [============================>.] - ETA: 0s - loss: 5.1442 - leftLayer1_loss: 0.1090 - midLayer1_loss: 1.3974 - rightLayer1_loss: 1.1853 - leftLayer2_loss: 0.0976 - midLayer2_loss: 1.4410 - rightLayer2_loss: 0.9139\n",
      "Epoch 00002: val_loss improved from 5.58265 to 5.12429, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 9s 3ms/step - loss: 5.1441 - leftLayer1_loss: 0.1090 - midLayer1_loss: 1.3974 - rightLayer1_loss: 1.1852 - leftLayer2_loss: 0.0976 - midLayer2_loss: 1.4410 - rightLayer2_loss: 0.9139 - val_loss: 5.1243 - val_leftLayer1_loss: 0.1044 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 1.0903 - val_leftLayer2_loss: 0.0987 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 1.0856\n",
      "Epoch 3/11\n",
      "3687/3705 [============================>.] - ETA: 0s - loss: 4.8495 - leftLayer1_loss: 0.1002 - midLayer1_loss: 1.3969 - rightLayer1_loss: 1.0057 - leftLayer2_loss: 0.0811 - midLayer2_loss: 1.4374 - rightLayer2_loss: 0.8282\n",
      "Epoch 00003: val_loss improved from 5.12429 to 4.90427, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 9s 3ms/step - loss: 4.8494 - leftLayer1_loss: 0.1002 - midLayer1_loss: 1.3969 - rightLayer1_loss: 1.0055 - leftLayer2_loss: 0.0811 - midLayer2_loss: 1.4374 - rightLayer2_loss: 0.8283 - val_loss: 4.9043 - val_leftLayer1_loss: 0.0964 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.9683 - val_leftLayer2_loss: 0.0891 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 1.0053\n",
      "Epoch 4/11\n",
      "3696/3705 [============================>.] - ETA: 0s - loss: 4.7088 - leftLayer1_loss: 0.0925 - midLayer1_loss: 1.3972 - rightLayer1_loss: 0.9173 - leftLayer2_loss: 0.0693 - midLayer2_loss: 1.4381 - rightLayer2_loss: 0.7944\n",
      "Epoch 00004: val_loss improved from 4.90427 to 4.77780, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7088 - leftLayer1_loss: 0.0925 - midLayer1_loss: 1.3972 - rightLayer1_loss: 0.9174 - leftLayer2_loss: 0.0693 - midLayer2_loss: 1.4378 - rightLayer2_loss: 0.7946 - val_loss: 4.7778 - val_leftLayer1_loss: 0.0895 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.9028 - val_leftLayer2_loss: 0.0817 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.9586\n",
      "Epoch 5/11\n",
      "3702/3705 [============================>.] - ETA: 0s - loss: 4.6292 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.3988 - rightLayer1_loss: 0.8686 - leftLayer2_loss: 0.0611 - midLayer2_loss: 1.4369 - rightLayer2_loss: 0.7779\n",
      "Epoch 00005: val_loss improved from 4.77780 to 4.69523, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6291 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.3988 - rightLayer1_loss: 0.8686 - leftLayer2_loss: 0.0611 - midLayer2_loss: 1.4368 - rightLayer2_loss: 0.7780 - val_loss: 4.6952 - val_leftLayer1_loss: 0.0834 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.8633 - val_leftLayer2_loss: 0.0759 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.9274\n",
      "Epoch 6/11\n",
      "3683/3705 [============================>.] - ETA: 0s - loss: 4.5725 - leftLayer1_loss: 0.0801 - midLayer1_loss: 1.3978 - rightLayer1_loss: 0.8379 - leftLayer2_loss: 0.0552 - midLayer2_loss: 1.4356 - rightLayer2_loss: 0.7659\n",
      "Epoch 00006: val_loss improved from 4.69523 to 4.63681, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5719 - leftLayer1_loss: 0.0800 - midLayer1_loss: 1.3978 - rightLayer1_loss: 0.8378 - leftLayer2_loss: 0.0551 - midLayer2_loss: 1.4352 - rightLayer2_loss: 0.7659 - val_loss: 4.6368 - val_leftLayer1_loss: 0.0782 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.8372 - val_leftLayer2_loss: 0.0713 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.9049\n",
      "Epoch 7/11\n",
      "3695/3705 [============================>.] - ETA: 0s - loss: 4.5386 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.8170 - leftLayer2_loss: 0.0506 - midLayer2_loss: 1.4399 - rightLayer2_loss: 0.7584\n",
      "Epoch 00007: val_loss improved from 4.63681 to 4.59302, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5388 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.8170 - leftLayer2_loss: 0.0505 - midLayer2_loss: 1.4400 - rightLayer2_loss: 0.7585 - val_loss: 4.5930 - val_leftLayer1_loss: 0.0736 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.8188 - val_leftLayer2_loss: 0.0676 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.8879\n",
      "Epoch 8/11\n",
      "3688/3705 [============================>.] - ETA: 0s - loss: 4.5080 - leftLayer1_loss: 0.0707 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.8016 - leftLayer2_loss: 0.0474 - midLayer2_loss: 1.4381 - rightLayer2_loss: 0.7525\n",
      "Epoch 00008: val_loss improved from 4.59302 to 4.55852, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5087 - leftLayer1_loss: 0.0707 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.8019 - leftLayer2_loss: 0.0474 - midLayer2_loss: 1.4381 - rightLayer2_loss: 0.7529 - val_loss: 4.5585 - val_leftLayer1_loss: 0.0695 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.8051 - val_leftLayer2_loss: 0.0645 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.8741\n",
      "Epoch 9/11\n",
      "3703/3705 [============================>.] - ETA: 0s - loss: 4.4872 - leftLayer1_loss: 0.0669 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.7909 - leftLayer2_loss: 0.0447 - midLayer2_loss: 1.4380 - rightLayer2_loss: 0.7489\n",
      "Epoch 00009: val_loss improved from 4.55852 to 4.53074, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.4868 - leftLayer1_loss: 0.0669 - midLayer1_loss: 1.3976 - rightLayer1_loss: 0.7908 - leftLayer2_loss: 0.0447 - midLayer2_loss: 1.4380 - rightLayer2_loss: 0.7488 - val_loss: 4.5307 - val_leftLayer1_loss: 0.0660 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.7947 - val_leftLayer2_loss: 0.0620 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.8628\n",
      "Epoch 10/11\n",
      "3684/3705 [============================>.] - ETA: 0s - loss: 4.4724 - leftLayer1_loss: 0.0636 - midLayer1_loss: 1.3978 - rightLayer1_loss: 0.7826 - leftLayer2_loss: 0.0427 - midLayer2_loss: 1.4398 - rightLayer2_loss: 0.7460\n",
      "Epoch 00010: val_loss improved from 4.53074 to 4.50767, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.4722 - leftLayer1_loss: 0.0636 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.7825 - leftLayer2_loss: 0.0426 - midLayer2_loss: 1.4398 - rightLayer2_loss: 0.7459 - val_loss: 4.5077 - val_leftLayer1_loss: 0.0629 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.7863 - val_leftLayer2_loss: 0.0598 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.8533\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3705 [============================>.] - ETA: 0s - loss: 4.4533 - leftLayer1_loss: 0.0607 - midLayer1_loss: 1.3972 - rightLayer1_loss: 0.7750 - leftLayer2_loss: 0.0409 - midLayer2_loss: 1.4363 - rightLayer2_loss: 0.7433\n",
      "Epoch 00011: val_loss improved from 4.50767 to 4.48823, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3705/3705 [==============================] - 9s 3ms/step - loss: 4.4535 - leftLayer1_loss: 0.0607 - midLayer1_loss: 1.3972 - rightLayer1_loss: 0.7751 - leftLayer2_loss: 0.0409 - midLayer2_loss: 1.4362 - rightLayer2_loss: 0.7434 - val_loss: 4.4882 - val_leftLayer1_loss: 0.0602 - val_midLayer1_loss: 1.3941 - val_rightLayer1_loss: 0.7796 - val_leftLayer2_loss: 0.0580 - val_midLayer2_loss: 1.3512 - val_rightLayer2_loss: 0.8452\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Pneumothorax: 0.5231419457282378\n",
      "\n",
      "auprc 0Pneumothorax: 0.05094752142526212\n",
      "\n",
      "auroc 1Pneumothorax: 0.4379845846704747\n",
      "\n",
      "auprc 1Pneumothorax: 0.0415674441136443\n",
      "\n",
      "auroc 2Pneumothorax: 0.6110547085272791\n",
      "\n",
      "auprc 2Pneumothorax: 0.06613858553416234\n",
      "\n",
      "auroc 3Pneumothorax: 0.4170196237969169\n",
      "\n",
      "auprc 3Pneumothorax: 0.03959424977989118\n",
      "\n",
      "auroc 4Pneumothorax: 0.3619898039960736\n",
      "\n",
      "auprc 4Pneumothorax: 0.03425343772710811\n",
      "\n",
      "auroc 5Pneumothorax: 0.5285480968193589\n",
      "\n",
      "auprc 5Pneumothorax: 0.05142194928865085\n",
      "\n",
      "mean auroc: 0.4799564605897235\n",
      "\n",
      "mean auprc: 0.04732053131145315\n",
      "\n",
      "max auroc: 0.6110547085272791\n",
      "\n",
      "max auprc: 0.06613858553416234\n",
      "\n",
      "133.94415307044983\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3694/3705 [============================>.] - ETA: 0s - loss: 5.9053 - leftLayer1_loss: 0.1226 - midLayer1_loss: 1.3163 - rightLayer1_loss: 1.5727 - leftLayer2_loss: 0.1158 - midLayer2_loss: 1.4190 - rightLayer2_loss: 1.3589\n",
      "Epoch 00001: val_loss improved from inf to 5.53668, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 5.9039 - leftLayer1_loss: 0.1226 - midLayer1_loss: 1.3163 - rightLayer1_loss: 1.5721 - leftLayer2_loss: 0.1158 - midLayer2_loss: 1.4192 - rightLayer2_loss: 1.3580 - val_loss: 5.5367 - val_leftLayer1_loss: 0.1171 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 1.3448 - val_leftLayer2_loss: 0.1129 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 1.2968\n",
      "Epoch 2/11\n",
      "3691/3705 [============================>.] - ETA: 0s - loss: 5.0667 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.3167 - rightLayer1_loss: 1.1862 - leftLayer2_loss: 0.0959 - midLayer2_loss: 1.4130 - rightLayer2_loss: 0.9429\n",
      "Epoch 00002: val_loss improved from 5.53668 to 5.07037, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.0664 - leftLayer1_loss: 0.1119 - midLayer1_loss: 1.3169 - rightLayer1_loss: 1.1859 - leftLayer2_loss: 0.0959 - midLayer2_loss: 1.4130 - rightLayer2_loss: 0.9428 - val_loss: 5.0704 - val_leftLayer1_loss: 0.1074 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 1.0857 - val_leftLayer2_loss: 0.1016 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 1.1105\n",
      "Epoch 3/11\n",
      "3691/3705 [============================>.] - ETA: 0s - loss: 4.7677 - leftLayer1_loss: 0.1026 - midLayer1_loss: 1.3165 - rightLayer1_loss: 1.0056 - leftLayer2_loss: 0.0813 - midLayer2_loss: 1.4170 - rightLayer2_loss: 0.8448\n",
      "Epoch 00003: val_loss improved from 5.07037 to 4.84673, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7683 - leftLayer1_loss: 0.1026 - midLayer1_loss: 1.3166 - rightLayer1_loss: 1.0056 - leftLayer2_loss: 0.0813 - midLayer2_loss: 1.4173 - rightLayer2_loss: 0.8449 - val_loss: 4.8467 - val_leftLayer1_loss: 0.0989 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.9638 - val_leftLayer2_loss: 0.0928 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 1.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3687/3705 [============================>.] - ETA: 0s - loss: 4.6214 - leftLayer1_loss: 0.0945 - midLayer1_loss: 1.3166 - rightLayer1_loss: 0.9180 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.4165 - rightLayer2_loss: 0.8051\n",
      "Epoch 00004: val_loss improved from 4.84673 to 4.71847, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6218 - leftLayer1_loss: 0.0945 - midLayer1_loss: 1.3167 - rightLayer1_loss: 0.9181 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.4167 - rightLayer2_loss: 0.8052 - val_loss: 4.7185 - val_leftLayer1_loss: 0.0915 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.8989 - val_leftLayer2_loss: 0.0858 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.9772\n",
      "Epoch 5/11\n",
      "3695/3705 [============================>.] - ETA: 0s - loss: 4.5399 - leftLayer1_loss: 0.0875 - midLayer1_loss: 1.3164 - rightLayer1_loss: 0.8692 - leftLayer2_loss: 0.0626 - midLayer2_loss: 1.4191 - rightLayer2_loss: 0.7851\n",
      "Epoch 00005: val_loss improved from 4.71847 to 4.63467, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5400 - leftLayer1_loss: 0.0875 - midLayer1_loss: 1.3164 - rightLayer1_loss: 0.8692 - leftLayer2_loss: 0.0626 - midLayer2_loss: 1.4191 - rightLayer2_loss: 0.7852 - val_loss: 4.6347 - val_leftLayer1_loss: 0.0850 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.8599 - val_leftLayer2_loss: 0.0801 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.9444\n",
      "Epoch 6/11\n",
      "3691/3705 [============================>.] - ETA: 0s - loss: 4.4823 - leftLayer1_loss: 0.0814 - midLayer1_loss: 1.3155 - rightLayer1_loss: 0.8376 - leftLayer2_loss: 0.0570 - midLayer2_loss: 1.4180 - rightLayer2_loss: 0.7728\n",
      "Epoch 00006: val_loss improved from 4.63467 to 4.57500, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.4831 - leftLayer1_loss: 0.0814 - midLayer1_loss: 1.3156 - rightLayer1_loss: 0.8379 - leftLayer2_loss: 0.0570 - midLayer2_loss: 1.4182 - rightLayer2_loss: 0.7731 - val_loss: 4.5750 - val_leftLayer1_loss: 0.0794 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.8343 - val_leftLayer2_loss: 0.0756 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.9205\n",
      "Epoch 7/11\n",
      "3700/3705 [============================>.] - ETA: 0s - loss: 4.4438 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3165 - rightLayer1_loss: 0.8182 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.4162 - rightLayer2_loss: 0.7643\n",
      "Epoch 00007: val_loss improved from 4.57500 to 4.53005, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.4440 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3165 - rightLayer1_loss: 0.8181 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.4163 - rightLayer2_loss: 0.7644 - val_loss: 4.5301 - val_leftLayer1_loss: 0.0746 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.8163 - val_leftLayer2_loss: 0.0718 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.9023\n",
      "Epoch 8/11\n",
      "3699/3705 [============================>.] - ETA: 0s - loss: 4.4171 - leftLayer1_loss: 0.0716 - midLayer1_loss: 1.3164 - rightLayer1_loss: 0.8025 - leftLayer2_loss: 0.0491 - midLayer2_loss: 1.4186 - rightLayer2_loss: 0.7589\n",
      "Epoch 00008: val_loss improved from 4.53005 to 4.49451, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.4176 - leftLayer1_loss: 0.0716 - midLayer1_loss: 1.3165 - rightLayer1_loss: 0.8026 - leftLayer2_loss: 0.0491 - midLayer2_loss: 1.4187 - rightLayer2_loss: 0.7591 - val_loss: 4.4945 - val_leftLayer1_loss: 0.0703 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.8029 - val_leftLayer2_loss: 0.0686 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.8874\n",
      "Epoch 9/11\n",
      "3684/3705 [============================>.] - ETA: 0s - loss: 4.3907 - leftLayer1_loss: 0.0676 - midLayer1_loss: 1.3157 - rightLayer1_loss: 0.7917 - leftLayer2_loss: 0.0463 - midLayer2_loss: 1.4166 - rightLayer2_loss: 0.7529\n",
      "Epoch 00009: val_loss improved from 4.49451 to 4.46603, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.3904 - leftLayer1_loss: 0.0676 - midLayer1_loss: 1.3157 - rightLayer1_loss: 0.7917 - leftLayer2_loss: 0.0463 - midLayer2_loss: 1.4163 - rightLayer2_loss: 0.7528 - val_loss: 4.4660 - val_leftLayer1_loss: 0.0666 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.7927 - val_leftLayer2_loss: 0.0660 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.8756\n",
      "Epoch 10/11\n",
      "3684/3705 [============================>.] - ETA: 0s - loss: 4.3758 - leftLayer1_loss: 0.0641 - midLayer1_loss: 1.3163 - rightLayer1_loss: 0.7827 - leftLayer2_loss: 0.0441 - midLayer2_loss: 1.4194 - rightLayer2_loss: 0.7492\n",
      "Epoch 00010: val_loss improved from 4.46603 to 4.44247, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.3758 - leftLayer1_loss: 0.0641 - midLayer1_loss: 1.3164 - rightLayer1_loss: 0.7826 - leftLayer2_loss: 0.0441 - midLayer2_loss: 1.4194 - rightLayer2_loss: 0.7492 - val_loss: 4.4425 - val_leftLayer1_loss: 0.0634 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.7846 - val_leftLayer2_loss: 0.0637 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.8657\n",
      "Epoch 11/11\n",
      "3690/3705 [============================>.] - ETA: 0s - loss: 4.3602 - leftLayer1_loss: 0.0611 - midLayer1_loss: 1.3155 - rightLayer1_loss: 0.7760 - leftLayer2_loss: 0.0424 - midLayer2_loss: 1.4183 - rightLayer2_loss: 0.7470\n",
      "Epoch 00011: val_loss improved from 4.44247 to 4.42241, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.3606 - leftLayer1_loss: 0.0611 - midLayer1_loss: 1.3155 - rightLayer1_loss: 0.7761 - leftLayer2_loss: 0.0424 - midLayer2_loss: 1.4184 - rightLayer2_loss: 0.7472 - val_loss: 4.4224 - val_leftLayer1_loss: 0.0605 - val_midLayer1_loss: 1.3175 - val_rightLayer1_loss: 0.7780 - val_leftLayer2_loss: 0.0617 - val_midLayer2_loss: 1.3476 - val_rightLayer2_loss: 0.8570\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Pneumothorax: 0.5872525169921926\n",
      "\n",
      "auprc 0Pneumothorax: 0.05990464649312648\n",
      "\n",
      "auroc 1Pneumothorax: 0.7053781347962382\n",
      "\n",
      "auprc 1Pneumothorax: 0.09491610489142038\n",
      "\n",
      "auroc 2Pneumothorax: 0.6429345373800703\n",
      "\n",
      "auprc 2Pneumothorax: 0.08419239058992908\n",
      "\n",
      "auroc 3Pneumothorax: 0.49383626454679\n",
      "\n",
      "auprc 3Pneumothorax: 0.04574899584866324\n",
      "\n",
      "auroc 4Pneumothorax: 0.3670117850854187\n",
      "\n",
      "auprc 4Pneumothorax: 0.034689627096289664\n",
      "\n",
      "auroc 5Pneumothorax: 0.47471066894238834\n",
      "\n",
      "auprc 5Pneumothorax: 0.042926499089237076\n",
      "\n",
      "mean auroc: 0.545187317957183\n",
      "\n",
      "mean auprc: 0.06039637733477765\n",
      "\n",
      "max auroc: 0.7053781347962382\n",
      "\n",
      "max auprc: 0.09491610489142038\n",
      "\n",
      "135.74350261688232\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 6.1104 - leftLayer1_loss: 0.1157 - midLayer1_loss: 1.4580 - rightLayer1_loss: 1.6362 - leftLayer2_loss: 0.1167 - midLayer2_loss: 1.4675 - rightLayer2_loss: 1.3164\n",
      "Epoch 00001: val_loss improved from inf to 5.68133, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 6.1085 - leftLayer1_loss: 0.1157 - midLayer1_loss: 1.4582 - rightLayer1_loss: 1.6352 - leftLayer2_loss: 0.1167 - midLayer2_loss: 1.4676 - rightLayer2_loss: 1.3152 - val_loss: 5.6813 - val_leftLayer1_loss: 0.1108 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 1.4075 - val_leftLayer2_loss: 0.1092 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 1.2310\n",
      "Epoch 2/11\n",
      "3687/3705 [============================>.] - ETA: 0s - loss: 5.2733 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.4581 - rightLayer1_loss: 1.2359 - leftLayer2_loss: 0.0944 - midLayer2_loss: 1.4691 - rightLayer2_loss: 0.9093\n",
      "Epoch 00002: val_loss improved from 5.68133 to 5.20456, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.2727 - leftLayer1_loss: 0.1065 - midLayer1_loss: 1.4582 - rightLayer1_loss: 1.2354 - leftLayer2_loss: 0.0944 - midLayer2_loss: 1.4690 - rightLayer2_loss: 0.9091 - val_loss: 5.2046 - val_leftLayer1_loss: 0.1024 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 1.1281 - val_leftLayer2_loss: 0.0964 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 1.0547\n",
      "Epoch 3/11\n",
      "3686/3705 [============================>.] - ETA: 0s - loss: 4.9692 - leftLayer1_loss: 0.0985 - midLayer1_loss: 1.4585 - rightLayer1_loss: 1.0375 - leftLayer2_loss: 0.0789 - midLayer2_loss: 1.4689 - rightLayer2_loss: 0.8269\n",
      "Epoch 00003: val_loss improved from 5.20456 to 4.97351, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.9689 - leftLayer1_loss: 0.0985 - midLayer1_loss: 1.4586 - rightLayer1_loss: 1.0373 - leftLayer2_loss: 0.0788 - midLayer2_loss: 1.4688 - rightLayer2_loss: 0.8269 - val_loss: 4.9735 - val_leftLayer1_loss: 0.0950 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.9916 - val_leftLayer2_loss: 0.0868 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.9772\n",
      "Epoch 4/11\n",
      "3690/3705 [============================>.] - ETA: 0s - loss: 4.8124 - leftLayer1_loss: 0.0914 - midLayer1_loss: 1.4577 - rightLayer1_loss: 0.9380 - leftLayer2_loss: 0.0678 - midLayer2_loss: 1.4657 - rightLayer2_loss: 0.7919\n",
      "Epoch 00004: val_loss improved from 4.97351 to 4.84248, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.8124 - leftLayer1_loss: 0.0913 - midLayer1_loss: 1.4578 - rightLayer1_loss: 0.9379 - leftLayer2_loss: 0.0677 - midLayer2_loss: 1.4657 - rightLayer2_loss: 0.7920 - val_loss: 4.8425 - val_leftLayer1_loss: 0.0885 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.9185 - val_leftLayer2_loss: 0.0795 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.9331\n",
      "Epoch 5/11\n",
      "3698/3705 [============================>.] - ETA: 0s - loss: 4.7231 - leftLayer1_loss: 0.0852 - midLayer1_loss: 1.4583 - rightLayer1_loss: 0.8829 - leftLayer2_loss: 0.0598 - midLayer2_loss: 1.4629 - rightLayer2_loss: 0.7740\n",
      "Epoch 00005: val_loss improved from 4.84248 to 4.75837, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7230 - leftLayer1_loss: 0.0852 - midLayer1_loss: 1.4584 - rightLayer1_loss: 0.8828 - leftLayer2_loss: 0.0598 - midLayer2_loss: 1.4628 - rightLayer2_loss: 0.7740 - val_loss: 4.7584 - val_leftLayer1_loss: 0.0829 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.8746 - val_leftLayer2_loss: 0.0738 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.9042\n",
      "Epoch 6/11\n",
      "3685/3705 [============================>.] - ETA: 0s - loss: 4.6757 - leftLayer1_loss: 0.0798 - midLayer1_loss: 1.4582 - rightLayer1_loss: 0.8489 - leftLayer2_loss: 0.0542 - midLayer2_loss: 1.4716 - rightLayer2_loss: 0.7630\n",
      "Epoch 00006: val_loss improved from 4.75837 to 4.69940, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6757 - leftLayer1_loss: 0.0797 - midLayer1_loss: 1.4584 - rightLayer1_loss: 0.8489 - leftLayer2_loss: 0.0542 - midLayer2_loss: 1.4714 - rightLayer2_loss: 0.7630 - val_loss: 4.6994 - val_leftLayer1_loss: 0.0779 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.8459 - val_leftLayer2_loss: 0.0692 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.8835\n",
      "Epoch 7/11\n",
      "3696/3705 [============================>.] - ETA: 0s - loss: 4.6315 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.4574 - rightLayer1_loss: 0.8257 - leftLayer2_loss: 0.0500 - midLayer2_loss: 1.4664 - rightLayer2_loss: 0.7569\n",
      "Epoch 00007: val_loss improved from 4.69940 to 4.65518, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6321 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.4576 - rightLayer1_loss: 0.8258 - leftLayer2_loss: 0.0500 - midLayer2_loss: 1.4665 - rightLayer2_loss: 0.7572 - val_loss: 4.6552 - val_leftLayer1_loss: 0.0735 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.8258 - val_leftLayer2_loss: 0.0656 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.8674\n",
      "Epoch 8/11\n",
      "3693/3705 [============================>.] - ETA: 0s - loss: 4.6019 - leftLayer1_loss: 0.0709 - midLayer1_loss: 1.4581 - rightLayer1_loss: 0.8092 - leftLayer2_loss: 0.0466 - midLayer2_loss: 1.4673 - rightLayer2_loss: 0.7498\n",
      "Epoch 00008: val_loss improved from 4.65518 to 4.62109, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6024 - leftLayer1_loss: 0.0709 - midLayer1_loss: 1.4582 - rightLayer1_loss: 0.8094 - leftLayer2_loss: 0.0466 - midLayer2_loss: 1.4673 - rightLayer2_loss: 0.7500 - val_loss: 4.6211 - val_leftLayer1_loss: 0.0697 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.8109 - val_leftLayer2_loss: 0.0626 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.8550\n",
      "Epoch 9/11\n",
      "3700/3705 [============================>.] - ETA: 0s - loss: 4.5844 - leftLayer1_loss: 0.0673 - midLayer1_loss: 1.4576 - rightLayer1_loss: 0.7971 - leftLayer2_loss: 0.0442 - midLayer2_loss: 1.4720 - rightLayer2_loss: 0.7462\n",
      "Epoch 00009: val_loss improved from 4.62109 to 4.59364, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5845 - leftLayer1_loss: 0.0673 - midLayer1_loss: 1.4576 - rightLayer1_loss: 0.7970 - leftLayer2_loss: 0.0442 - midLayer2_loss: 1.4721 - rightLayer2_loss: 0.7463 - val_loss: 4.5936 - val_leftLayer1_loss: 0.0663 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.7995 - val_leftLayer2_loss: 0.0601 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.8448\n",
      "Epoch 10/11\n",
      "3685/3705 [============================>.] - ETA: 0s - loss: 4.5608 - leftLayer1_loss: 0.0640 - midLayer1_loss: 1.4581 - rightLayer1_loss: 0.7871 - leftLayer2_loss: 0.0423 - midLayer2_loss: 1.4662 - rightLayer2_loss: 0.7431\n",
      "Epoch 00010: val_loss improved from 4.59364 to 4.57108, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5607 - leftLayer1_loss: 0.0640 - midLayer1_loss: 1.4582 - rightLayer1_loss: 0.7872 - leftLayer2_loss: 0.0423 - midLayer2_loss: 1.4657 - rightLayer2_loss: 0.7433 - val_loss: 4.5711 - val_leftLayer1_loss: 0.0633 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.7906 - val_leftLayer2_loss: 0.0580 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.8363\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3695/3705 [============================>.] - ETA: 0s - loss: 4.5472 - leftLayer1_loss: 0.0612 - midLayer1_loss: 1.4584 - rightLayer1_loss: 0.7796 - leftLayer2_loss: 0.0407 - midLayer2_loss: 1.4663 - rightLayer2_loss: 0.7409\n",
      "Epoch 00011: val_loss improved from 4.57108 to 4.55209, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3705/3705 [==============================] - 9s 3ms/step - loss: 4.5477 - leftLayer1_loss: 0.0612 - midLayer1_loss: 1.4584 - rightLayer1_loss: 0.7797 - leftLayer2_loss: 0.0407 - midLayer2_loss: 1.4665 - rightLayer2_loss: 0.7411 - val_loss: 4.5521 - val_leftLayer1_loss: 0.0606 - val_midLayer1_loss: 1.4538 - val_rightLayer1_loss: 0.7833 - val_leftLayer2_loss: 0.0562 - val_midLayer2_loss: 1.3690 - val_rightLayer2_loss: 0.8291\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Pneumothorax: 0.4335276404497476\n",
      "\n",
      "auprc 0Pneumothorax: 0.04068765044301817\n",
      "\n",
      "auroc 1Pneumothorax: 0.7771055071637736\n",
      "\n",
      "auprc 1Pneumothorax: 0.13944290310417207\n",
      "\n",
      "auroc 2Pneumothorax: 0.5753074306510657\n",
      "\n",
      "auprc 2Pneumothorax: 0.06466515939962447\n",
      "\n",
      "auroc 3Pneumothorax: 0.5307192521163661\n",
      "\n",
      "auprc 3Pneumothorax: 0.052385143983576354\n",
      "\n",
      "auroc 4Pneumothorax: 0.39797697569947815\n",
      "\n",
      "auprc 4Pneumothorax: 0.038519554039830504\n",
      "\n",
      "auroc 5Pneumothorax: 0.48579964924562513\n",
      "\n",
      "auprc 5Pneumothorax: 0.048163119186425074\n",
      "\n",
      "mean auroc: 0.533406075887676\n",
      "\n",
      "mean auprc: 0.06397725502610778\n",
      "\n",
      "max auroc: 0.7771055071637736\n",
      "\n",
      "max auprc: 0.13944290310417207\n",
      "\n",
      "134.5433166027069\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3705 steps, validate for 504 steps\n",
      "Epoch 1/11\n",
      "3699/3705 [============================>.] - ETA: 0s - loss: 6.0653 - leftLayer1_loss: 0.1156 - midLayer1_loss: 1.3523 - rightLayer1_loss: 1.6301 - leftLayer2_loss: 0.1101 - midLayer2_loss: 1.5187 - rightLayer2_loss: 1.3385\n",
      "Epoch 00001: val_loss improved from inf to 5.61251, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 11s 3ms/step - loss: 6.0646 - leftLayer1_loss: 0.1156 - midLayer1_loss: 1.3525 - rightLayer1_loss: 1.6298 - leftLayer2_loss: 0.1101 - midLayer2_loss: 1.5187 - rightLayer2_loss: 1.3380 - val_loss: 5.6125 - val_leftLayer1_loss: 0.1126 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 1.4349 - val_leftLayer2_loss: 0.1043 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 1.2093\n",
      "Epoch 2/11\n",
      "3704/3705 [============================>.] - ETA: 0s - loss: 5.2565 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.3519 - rightLayer1_loss: 1.2816 - leftLayer2_loss: 0.0883 - midLayer2_loss: 1.5203 - rightLayer2_loss: 0.9064\n",
      "Epoch 00002: val_loss improved from 5.61251 to 5.15435, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 5.2565 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.3519 - rightLayer1_loss: 1.2816 - leftLayer2_loss: 0.0883 - midLayer2_loss: 1.5203 - rightLayer2_loss: 0.9064 - val_loss: 5.1543 - val_leftLayer1_loss: 0.1055 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 1.1776 - val_leftLayer2_loss: 0.0916 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 1.0283\n",
      "Epoch 3/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 4.9509 - leftLayer1_loss: 0.1012 - midLayer1_loss: 1.3511 - rightLayer1_loss: 1.0868 - leftLayer2_loss: 0.0735 - midLayer2_loss: 1.5174 - rightLayer2_loss: 0.8209\n",
      "Epoch 00003: val_loss improved from 5.15435 to 4.92342, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.9511 - leftLayer1_loss: 0.1011 - midLayer1_loss: 1.3513 - rightLayer1_loss: 1.0866 - leftLayer2_loss: 0.0735 - midLayer2_loss: 1.5174 - rightLayer2_loss: 0.8211 - val_loss: 4.9234 - val_leftLayer1_loss: 0.0992 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 1.0370 - val_leftLayer2_loss: 0.0821 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.9537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3684/3705 [============================>.] - ETA: 0s - loss: 4.8008 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3522 - rightLayer1_loss: 0.9799 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.5212 - rightLayer2_loss: 0.7889\n",
      "Epoch 00004: val_loss improved from 4.92342 to 4.78792, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.8007 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3523 - rightLayer1_loss: 0.9798 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.5213 - rightLayer2_loss: 0.7889 - val_loss: 4.7879 - val_leftLayer1_loss: 0.0934 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.9565 - val_leftLayer2_loss: 0.0750 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.9116\n",
      "Epoch 5/11\n",
      "3694/3705 [============================>.] - ETA: 0s - loss: 4.7080 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.3521 - rightLayer1_loss: 0.9171 - leftLayer2_loss: 0.0562 - midLayer2_loss: 1.5206 - rightLayer2_loss: 0.7725\n",
      "Epoch 00005: val_loss improved from 4.78792 to 4.69970, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.7083 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.3522 - rightLayer1_loss: 0.9171 - leftLayer2_loss: 0.0562 - midLayer2_loss: 1.5207 - rightLayer2_loss: 0.7726 - val_loss: 4.6997 - val_leftLayer1_loss: 0.0883 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.9063 - val_leftLayer2_loss: 0.0696 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8841\n",
      "Epoch 6/11\n",
      "3685/3705 [============================>.] - ETA: 0s - loss: 4.6441 - leftLayer1_loss: 0.0845 - midLayer1_loss: 1.3515 - rightLayer1_loss: 0.8759 - leftLayer2_loss: 0.0511 - midLayer2_loss: 1.5192 - rightLayer2_loss: 0.7618\n",
      "Epoch 00006: val_loss improved from 4.69970 to 4.63772, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6444 - leftLayer1_loss: 0.0845 - midLayer1_loss: 1.3516 - rightLayer1_loss: 0.8760 - leftLayer2_loss: 0.0511 - midLayer2_loss: 1.5193 - rightLayer2_loss: 0.7620 - val_loss: 4.6377 - val_leftLayer1_loss: 0.0837 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.8728 - val_leftLayer2_loss: 0.0653 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8645\n",
      "Epoch 7/11\n",
      "3700/3705 [============================>.] - ETA: 0s - loss: 4.6019 - leftLayer1_loss: 0.0801 - midLayer1_loss: 1.3524 - rightLayer1_loss: 0.8492 - leftLayer2_loss: 0.0475 - midLayer2_loss: 1.5173 - rightLayer2_loss: 0.7553\n",
      "Epoch 00007: val_loss improved from 4.63772 to 4.59154, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.6020 - leftLayer1_loss: 0.0801 - midLayer1_loss: 1.3525 - rightLayer1_loss: 0.8492 - leftLayer2_loss: 0.0475 - midLayer2_loss: 1.5173 - rightLayer2_loss: 0.7554 - val_loss: 4.5915 - val_leftLayer1_loss: 0.0795 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.8490 - val_leftLayer2_loss: 0.0619 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8497\n",
      "Epoch 8/11\n",
      "3689/3705 [============================>.] - ETA: 0s - loss: 4.5684 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3515 - rightLayer1_loss: 0.8290 - leftLayer2_loss: 0.0445 - midLayer2_loss: 1.5182 - rightLayer2_loss: 0.7490\n",
      "Epoch 00008: val_loss improved from 4.59154 to 4.55591, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5691 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3517 - rightLayer1_loss: 0.8293 - leftLayer2_loss: 0.0445 - midLayer2_loss: 1.5183 - rightLayer2_loss: 0.7493 - val_loss: 4.5559 - val_leftLayer1_loss: 0.0758 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.8314 - val_leftLayer2_loss: 0.0591 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8382\n",
      "Epoch 9/11\n",
      "3704/3705 [============================>.] - ETA: 0s - loss: 4.5463 - leftLayer1_loss: 0.0727 - midLayer1_loss: 1.3518 - rightLayer1_loss: 0.8144 - leftLayer2_loss: 0.0423 - midLayer2_loss: 1.5190 - rightLayer2_loss: 0.7461\n",
      "Epoch 00009: val_loss improved from 4.55591 to 4.52719, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5464 - leftLayer1_loss: 0.0727 - midLayer1_loss: 1.3519 - rightLayer1_loss: 0.8144 - leftLayer2_loss: 0.0423 - midLayer2_loss: 1.5190 - rightLayer2_loss: 0.7461 - val_loss: 4.5272 - val_leftLayer1_loss: 0.0725 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.8178 - val_leftLayer2_loss: 0.0567 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8288\n",
      "Epoch 10/11\n",
      "3695/3705 [============================>.] - ETA: 0s - loss: 4.5291 - leftLayer1_loss: 0.0695 - midLayer1_loss: 1.3522 - rightLayer1_loss: 0.8024 - leftLayer2_loss: 0.0407 - midLayer2_loss: 1.5220 - rightLayer2_loss: 0.7424\n",
      "Epoch 00010: val_loss improved from 4.52719 to 4.50367, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5292 - leftLayer1_loss: 0.0695 - midLayer1_loss: 1.3523 - rightLayer1_loss: 0.8024 - leftLayer2_loss: 0.0407 - midLayer2_loss: 1.5218 - rightLayer2_loss: 0.7425 - val_loss: 4.5037 - val_leftLayer1_loss: 0.0695 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.8070 - val_leftLayer2_loss: 0.0548 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8210\n",
      "Epoch 11/11\n",
      "3694/3705 [============================>.] - ETA: 0s - loss: 4.5116 - leftLayer1_loss: 0.0666 - midLayer1_loss: 1.3525 - rightLayer1_loss: 0.7931 - leftLayer2_loss: 0.0391 - midLayer2_loss: 1.5201 - rightLayer2_loss: 0.7401\n",
      "Epoch 00011: val_loss improved from 4.50367 to 4.48399, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3705/3705 [==============================] - 10s 3ms/step - loss: 4.5119 - leftLayer1_loss: 0.0666 - midLayer1_loss: 1.3526 - rightLayer1_loss: 0.7932 - leftLayer2_loss: 0.0391 - midLayer2_loss: 1.5202 - rightLayer2_loss: 0.7403 - val_loss: 4.4840 - val_leftLayer1_loss: 0.0668 - val_midLayer1_loss: 1.3524 - val_rightLayer1_loss: 0.7983 - val_leftLayer2_loss: 0.0531 - val_midLayer2_loss: 1.3990 - val_rightLayer2_loss: 0.8145\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Pneumothorax: 0.561703759862493\n",
      "\n",
      "auprc 0Pneumothorax: 0.05675112634673861\n",
      "\n",
      "auroc 1Pneumothorax: 0.5415715867961336\n",
      "\n",
      "auprc 1Pneumothorax: 0.048466893825592\n",
      "\n",
      "auroc 2Pneumothorax: 0.5579367900416183\n",
      "\n",
      "auprc 2Pneumothorax: 0.0669351851643644\n",
      "\n",
      "auroc 3Pneumothorax: 0.5397681023468982\n",
      "\n",
      "auprc 3Pneumothorax: 0.06203076613842947\n",
      "\n",
      "auroc 4Pneumothorax: 0.5066920525618733\n",
      "\n",
      "auprc 4Pneumothorax: 0.04630101707022459\n",
      "\n",
      "auroc 5Pneumothorax: 0.6006954984973079\n",
      "\n",
      "auprc 5Pneumothorax: 0.06570158765090818\n",
      "\n",
      "mean auroc: 0.5513946316843874\n",
      "\n",
      "mean auprc: 0.05769776269937621\n",
      "\n",
      "max auroc: 0.6006954984973079\n",
      "\n",
      "max auprc: 0.0669351851643644\n",
      "\n",
      "135.70186519622803\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7771055071637736\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
