{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Emphysema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "316: 1799\n",
      "38: 1799\n",
      "265: 1799\n",
      "313: 1799\n",
      "141: 1799\n",
      "71: 1799\n",
      "16: 1799\n",
      "539: 1799\n",
      "79: 1799\n",
      "26: 1799\n",
      "1799: 1799\n",
      "25: 1799\n",
      "107: 1799\n",
      "0: 1799\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 6.3410 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.3589 - rightLayer1_loss: 1.7573 - leftLayer2_loss: 0.1221 - midLayer2_loss: 1.4465 - rightLayer2_loss: 1.5335\n",
      "Epoch 00001: val_loss improved from inf to 6.08257, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 6s 3ms/step - loss: 6.3377 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.3597 - rightLayer1_loss: 1.7562 - leftLayer2_loss: 0.1220 - midLayer2_loss: 1.4456 - rightLayer2_loss: 1.5315 - val_loss: 6.0826 - val_leftLayer1_loss: 0.1193 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.6332 - val_leftLayer2_loss: 0.1191 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.4861\n",
      "Epoch 2/11\n",
      "1792/1799 [============================>.] - ETA: 0s - loss: 5.7004 - leftLayer1_loss: 0.1181 - midLayer1_loss: 1.3606 - rightLayer1_loss: 1.5208 - leftLayer2_loss: 0.1095 - midLayer2_loss: 1.4425 - rightLayer2_loss: 1.1490\n",
      "Epoch 00002: val_loss improved from 6.08257 to 5.66211, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.6995 - leftLayer1_loss: 0.1181 - midLayer1_loss: 1.3608 - rightLayer1_loss: 1.5205 - leftLayer2_loss: 0.1095 - midLayer2_loss: 1.4421 - rightLayer2_loss: 1.1486 - val_loss: 5.6621 - val_leftLayer1_loss: 0.1149 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.4271 - val_leftLayer2_loss: 0.1116 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.2837\n",
      "Epoch 3/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 5.3585 - leftLayer1_loss: 0.1137 - midLayer1_loss: 1.3607 - rightLayer1_loss: 1.3405 - leftLayer2_loss: 0.0988 - midLayer2_loss: 1.4440 - rightLayer2_loss: 1.0009\n",
      "Epoch 00003: val_loss improved from 5.66211 to 5.39581, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.3597 - leftLayer1_loss: 0.1137 - midLayer1_loss: 1.3614 - rightLayer1_loss: 1.3403 - leftLayer2_loss: 0.0989 - midLayer2_loss: 1.4441 - rightLayer2_loss: 1.0014 - val_loss: 5.3958 - val_leftLayer1_loss: 0.1107 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.2770 - val_leftLayer2_loss: 0.1050 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.1783\n",
      "Epoch 4/11\n",
      "1777/1799 [============================>.] - ETA: 0s - loss: 5.1605 - leftLayer1_loss: 0.1095 - midLayer1_loss: 1.3591 - rightLayer1_loss: 1.2134 - leftLayer2_loss: 0.0900 - midLayer2_loss: 1.4491 - rightLayer2_loss: 0.9393\n",
      "Epoch 00004: val_loss improved from 5.39581 to 5.21845, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.1623 - leftLayer1_loss: 0.1095 - midLayer1_loss: 1.3598 - rightLayer1_loss: 1.2135 - leftLayer2_loss: 0.0900 - midLayer2_loss: 1.4493 - rightLayer2_loss: 0.9401 - val_loss: 5.2185 - val_leftLayer1_loss: 0.1067 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.1722 - val_leftLayer2_loss: 0.0993 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.1154\n",
      "Epoch 5/11\n",
      "1798/1799 [============================>.] - ETA: 0s - loss: 5.0237 - leftLayer1_loss: 0.1055 - midLayer1_loss: 1.3617 - rightLayer1_loss: 1.1249 - leftLayer2_loss: 0.0830 - midLayer2_loss: 1.4419 - rightLayer2_loss: 0.9066\n",
      "Epoch 00005: val_loss improved from 5.21845 to 5.09356, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.0230 - leftLayer1_loss: 0.1055 - midLayer1_loss: 1.3616 - rightLayer1_loss: 1.1247 - leftLayer2_loss: 0.0830 - midLayer2_loss: 1.4418 - rightLayer2_loss: 0.9064 - val_loss: 5.0936 - val_leftLayer1_loss: 0.1030 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.0988 - val_leftLayer2_loss: 0.0943 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "1776/1799 [============================>.] - ETA: 0s - loss: 4.9297 - leftLayer1_loss: 0.1018 - midLayer1_loss: 1.3594 - rightLayer1_loss: 1.0628 - leftLayer2_loss: 0.0761 - midLayer2_loss: 1.4467 - rightLayer2_loss: 0.8830\n",
      "Epoch 00006: val_loss improved from 5.09356 to 5.00260, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.9322 - leftLayer1_loss: 0.1018 - midLayer1_loss: 1.3602 - rightLayer1_loss: 1.0635 - leftLayer2_loss: 0.0760 - midLayer2_loss: 1.4463 - rightLayer2_loss: 0.8843 - val_loss: 5.0026 - val_leftLayer1_loss: 0.0994 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.0464 - val_leftLayer2_loss: 0.0899 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.0420\n",
      "Epoch 7/11\n",
      "1778/1799 [============================>.] - ETA: 0s - loss: 4.8595 - leftLayer1_loss: 0.0984 - midLayer1_loss: 1.3599 - rightLayer1_loss: 1.0190 - leftLayer2_loss: 0.0715 - midLayer2_loss: 1.4423 - rightLayer2_loss: 0.8683\n",
      "Epoch 00007: val_loss improved from 5.00260 to 4.93400, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.8616 - leftLayer1_loss: 0.0984 - midLayer1_loss: 1.3606 - rightLayer1_loss: 1.0196 - leftLayer2_loss: 0.0715 - midLayer2_loss: 1.4422 - rightLayer2_loss: 0.8693 - val_loss: 4.9340 - val_leftLayer1_loss: 0.0961 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 1.0079 - val_leftLayer2_loss: 0.0860 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.0190\n",
      "Epoch 8/11\n",
      "1795/1799 [============================>.] - ETA: 0s - loss: 4.8129 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3613 - rightLayer1_loss: 0.9861 - leftLayer2_loss: 0.0669 - midLayer2_loss: 1.4435 - rightLayer2_loss: 0.8601\n",
      "Epoch 00008: val_loss improved from 4.93400 to 4.88015, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.8122 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3612 - rightLayer1_loss: 0.9859 - leftLayer2_loss: 0.0669 - midLayer2_loss: 1.4434 - rightLayer2_loss: 0.8599 - val_loss: 4.8802 - val_leftLayer1_loss: 0.0930 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 0.9789 - val_leftLayer2_loss: 0.0826 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 1.0007\n",
      "Epoch 9/11\n",
      "1797/1799 [============================>.] - ETA: 0s - loss: 4.7707 - leftLayer1_loss: 0.0919 - midLayer1_loss: 1.3597 - rightLayer1_loss: 0.9608 - leftLayer2_loss: 0.0632 - midLayer2_loss: 1.4399 - rightLayer2_loss: 0.8551\n",
      "Epoch 00009: val_loss improved from 4.88015 to 4.83665, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7704 - leftLayer1_loss: 0.0919 - midLayer1_loss: 1.3596 - rightLayer1_loss: 0.9607 - leftLayer2_loss: 0.0632 - midLayer2_loss: 1.4398 - rightLayer2_loss: 0.8551 - val_loss: 4.8366 - val_leftLayer1_loss: 0.0901 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 0.9564 - val_leftLayer2_loss: 0.0797 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 0.9856\n",
      "Epoch 10/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 4.7450 - leftLayer1_loss: 0.0890 - midLayer1_loss: 1.3616 - rightLayer1_loss: 0.9411 - leftLayer2_loss: 0.0600 - midLayer2_loss: 1.4452 - rightLayer2_loss: 0.8481\n",
      "Epoch 00010: val_loss improved from 4.83665 to 4.80094, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.7451 - leftLayer1_loss: 0.0890 - midLayer1_loss: 1.3617 - rightLayer1_loss: 0.9412 - leftLayer2_loss: 0.0600 - midLayer2_loss: 1.4452 - rightLayer2_loss: 0.8481 - val_loss: 4.8009 - val_leftLayer1_loss: 0.0873 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 0.9385 - val_leftLayer2_loss: 0.0770 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 0.9732\n",
      "Epoch 11/11\n",
      "1786/1799 [============================>.] - ETA: 0s - loss: 4.7113 - leftLayer1_loss: 0.0863 - midLayer1_loss: 1.3604 - rightLayer1_loss: 0.9257 - leftLayer2_loss: 0.0575 - midLayer2_loss: 1.4384 - rightLayer2_loss: 0.8430\n",
      "Epoch 00011: val_loss improved from 4.80094 to 4.77080, saving model to ./experiments/0.009_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.7139 - leftLayer1_loss: 0.0863 - midLayer1_loss: 1.3610 - rightLayer1_loss: 0.9263 - leftLayer2_loss: 0.0575 - midLayer2_loss: 1.4390 - rightLayer2_loss: 0.8438 - val_loss: 4.7708 - val_leftLayer1_loss: 0.0847 - val_midLayer1_loss: 1.3554 - val_rightLayer1_loss: 0.9240 - val_leftLayer2_loss: 0.0746 - val_midLayer2_loss: 1.3695 - val_rightLayer2_loss: 0.9626\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Emphysema: 0.6481859192803573\n",
      "\n",
      "auprc 0Emphysema: 0.06693625207195927\n",
      "\n",
      "auroc 1Emphysema: 0.19793569785101525\n",
      "\n",
      "auprc 1Emphysema: 0.012904222998920118\n",
      "\n",
      "auroc 2Emphysema: 0.6486781985562555\n",
      "\n",
      "auprc 2Emphysema: 0.0370563912382125\n",
      "\n",
      "auroc 3Emphysema: 0.5400597133372691\n",
      "\n",
      "auprc 3Emphysema: 0.02422509934515364\n",
      "\n",
      "auroc 4Emphysema: 0.5768250491338358\n",
      "\n",
      "auprc 4Emphysema: 0.030355593872318835\n",
      "\n",
      "auroc 5Emphysema: 0.6645033620340172\n",
      "\n",
      "auprc 5Emphysema: 0.036050583568144196\n",
      "\n",
      "mean auroc: 0.5460313233654583\n",
      "\n",
      "mean auprc: 0.0345880238491181\n",
      "\n",
      "max auroc: 0.6645033620340172\n",
      "\n",
      "max auprc: 0.06693625207195927\n",
      "\n",
      "80.10536599159241\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1788/1799 [============================>.] - ETA: 0s - loss: 6.4301 - leftLayer1_loss: 0.1271 - midLayer1_loss: 1.4459 - rightLayer1_loss: 1.7494 - leftLayer2_loss: 0.1271 - midLayer2_loss: 1.4022 - rightLayer2_loss: 1.5785\n",
      "Epoch 00001: val_loss improved from inf to 6.17539, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 6.4282 - leftLayer1_loss: 0.1270 - midLayer1_loss: 1.4461 - rightLayer1_loss: 1.7487 - leftLayer2_loss: 0.1270 - midLayer2_loss: 1.4023 - rightLayer2_loss: 1.5769 - val_loss: 6.1754 - val_leftLayer1_loss: 0.1245 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.6392 - val_leftLayer2_loss: 0.1212 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.5012\n",
      "Epoch 2/11\n",
      "1786/1799 [============================>.] - ETA: 0s - loss: 5.8111 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4461 - rightLayer1_loss: 1.5407 - leftLayer2_loss: 0.1144 - midLayer2_loss: 1.4014 - rightLayer2_loss: 1.1858\n",
      "Epoch 00002: val_loss improved from 6.17539 to 5.77694, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.8106 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4466 - rightLayer1_loss: 1.5401 - leftLayer2_loss: 0.1144 - midLayer2_loss: 1.4016 - rightLayer2_loss: 1.1853 - val_loss: 5.7769 - val_leftLayer1_loss: 0.1203 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.4530 - val_leftLayer2_loss: 0.1139 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.3004\n",
      "Epoch 3/11\n",
      "1795/1799 [============================>.] - ETA: 0s - loss: 5.4741 - leftLayer1_loss: 0.1187 - midLayer1_loss: 1.4461 - rightLayer1_loss: 1.3748 - leftLayer2_loss: 0.1038 - midLayer2_loss: 1.4035 - rightLayer2_loss: 1.0274\n",
      "Epoch 00003: val_loss improved from 5.77694 to 5.51836, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 5.4733 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.4461 - rightLayer1_loss: 1.3745 - leftLayer2_loss: 0.1037 - midLayer2_loss: 1.4032 - rightLayer2_loss: 1.0270 - val_loss: 5.5184 - val_leftLayer1_loss: 0.1163 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.3114 - val_leftLayer2_loss: 0.1075 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.1939\n",
      "Epoch 4/11\n",
      "1788/1799 [============================>.] - ETA: 0s - loss: 5.2618 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.4457 - rightLayer1_loss: 1.2512 - leftLayer2_loss: 0.0948 - midLayer2_loss: 1.4013 - rightLayer2_loss: 0.9541\n",
      "Epoch 00004: val_loss improved from 5.51836 to 5.34115, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.2617 - leftLayer1_loss: 0.1146 - midLayer1_loss: 1.4460 - rightLayer1_loss: 1.2509 - leftLayer2_loss: 0.0948 - midLayer2_loss: 1.4016 - rightLayer2_loss: 0.9538 - val_loss: 5.3411 - val_leftLayer1_loss: 0.1125 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.2075 - val_leftLayer2_loss: 0.1018 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.1300\n",
      "Epoch 5/11\n",
      "1787/1799 [============================>.] - ETA: 0s - loss: 5.1231 - leftLayer1_loss: 0.1110 - midLayer1_loss: 1.4462 - rightLayer1_loss: 1.1629 - leftLayer2_loss: 0.0871 - midLayer2_loss: 1.3969 - rightLayer2_loss: 0.9190\n",
      "Epoch 00005: val_loss improved from 5.34115 to 5.21416, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.1233 - leftLayer1_loss: 0.1110 - midLayer1_loss: 1.4465 - rightLayer1_loss: 1.1627 - leftLayer2_loss: 0.0871 - midLayer2_loss: 1.3968 - rightLayer2_loss: 0.9191 - val_loss: 5.2142 - val_leftLayer1_loss: 0.1089 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.1320 - val_leftLayer2_loss: 0.0968 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.0871\n",
      "Epoch 6/11\n",
      "1785/1799 [============================>.] - ETA: 0s - loss: 5.0283 - leftLayer1_loss: 0.1074 - midLayer1_loss: 1.4468 - rightLayer1_loss: 1.0973 - leftLayer2_loss: 0.0807 - midLayer2_loss: 1.3997 - rightLayer2_loss: 0.8964\n",
      "Epoch 00006: val_loss improved from 5.21416 to 5.11954, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.0295 - leftLayer1_loss: 0.1074 - midLayer1_loss: 1.4472 - rightLayer1_loss: 1.0974 - leftLayer2_loss: 0.0806 - midLayer2_loss: 1.4000 - rightLayer2_loss: 0.8968 - val_loss: 5.1195 - val_leftLayer1_loss: 0.1055 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.0764 - val_leftLayer2_loss: 0.0924 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.0559\n",
      "Epoch 7/11\n",
      "1780/1799 [============================>.] - ETA: 0s - loss: 4.9606 - leftLayer1_loss: 0.1040 - midLayer1_loss: 1.4463 - rightLayer1_loss: 1.0491 - leftLayer2_loss: 0.0750 - midLayer2_loss: 1.4056 - rightLayer2_loss: 0.8806\n",
      "Epoch 00007: val_loss improved from 5.11954 to 5.04721, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9637 - leftLayer1_loss: 0.1040 - midLayer1_loss: 1.4467 - rightLayer1_loss: 1.0497 - leftLayer2_loss: 0.0750 - midLayer2_loss: 1.4066 - rightLayer2_loss: 0.8818 - val_loss: 5.0472 - val_leftLayer1_loss: 0.1022 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.0347 - val_leftLayer2_loss: 0.0885 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.0325\n",
      "Epoch 8/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 4.9032 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.4469 - rightLayer1_loss: 1.0132 - leftLayer2_loss: 0.0704 - midLayer2_loss: 1.4014 - rightLayer2_loss: 0.8706\n",
      "Epoch 00008: val_loss improved from 5.04721 to 4.99005, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9036 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.4470 - rightLayer1_loss: 1.0132 - leftLayer2_loss: 0.0704 - midLayer2_loss: 1.4017 - rightLayer2_loss: 0.8706 - val_loss: 4.9901 - val_leftLayer1_loss: 0.0991 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 1.0027 - val_leftLayer2_loss: 0.0851 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 1.0139\n",
      "Epoch 9/11\n",
      "1784/1799 [============================>.] - ETA: 0s - loss: 4.8488 - leftLayer1_loss: 0.0978 - midLayer1_loss: 1.4451 - rightLayer1_loss: 0.9841 - leftLayer2_loss: 0.0663 - midLayer2_loss: 1.3959 - rightLayer2_loss: 0.8596\n",
      "Epoch 00009: val_loss improved from 4.99005 to 4.94378, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8505 - leftLayer1_loss: 0.0977 - midLayer1_loss: 1.4456 - rightLayer1_loss: 0.9844 - leftLayer2_loss: 0.0663 - midLayer2_loss: 1.3962 - rightLayer2_loss: 0.8603 - val_loss: 4.9438 - val_leftLayer1_loss: 0.0962 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 0.9775 - val_leftLayer2_loss: 0.0821 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 0.9987\n",
      "Epoch 10/11\n",
      "1787/1799 [============================>.] - ETA: 0s - loss: 4.8185 - leftLayer1_loss: 0.0949 - midLayer1_loss: 1.4456 - rightLayer1_loss: 0.9627 - leftLayer2_loss: 0.0629 - midLayer2_loss: 1.3976 - rightLayer2_loss: 0.8547\n",
      "Epoch 00010: val_loss improved from 4.94378 to 4.90552, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8195 - leftLayer1_loss: 0.0949 - midLayer1_loss: 1.4460 - rightLayer1_loss: 0.9628 - leftLayer2_loss: 0.0629 - midLayer2_loss: 1.3977 - rightLayer2_loss: 0.8552 - val_loss: 4.9055 - val_leftLayer1_loss: 0.0934 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 0.9574 - val_leftLayer2_loss: 0.0793 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 0.9860\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1793/1799 [============================>.] - ETA: 0s - loss: 4.7958 - leftLayer1_loss: 0.0922 - midLayer1_loss: 1.4467 - rightLayer1_loss: 0.9448 - leftLayer2_loss: 0.0601 - midLayer2_loss: 1.4015 - rightLayer2_loss: 0.8505\n",
      "Epoch 00011: val_loss improved from 4.90552 to 4.87328, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.7953 - leftLayer1_loss: 0.0921 - midLayer1_loss: 1.4468 - rightLayer1_loss: 0.9447 - leftLayer2_loss: 0.0601 - midLayer2_loss: 1.4014 - rightLayer2_loss: 0.8502 - val_loss: 4.8733 - val_leftLayer1_loss: 0.0908 - val_midLayer1_loss: 1.4402 - val_rightLayer1_loss: 0.9410 - val_leftLayer2_loss: 0.0769 - val_midLayer2_loss: 1.3491 - val_rightLayer2_loss: 0.9753\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Emphysema: 0.6268631518275852\n",
      "\n",
      "auprc 0Emphysema: 0.035985540003138666\n",
      "\n",
      "auroc 1Emphysema: 0.5972883553077984\n",
      "\n",
      "auprc 1Emphysema: 0.027278643992755487\n",
      "\n",
      "auroc 2Emphysema: 0.6362170853482418\n",
      "\n",
      "auprc 2Emphysema: 0.04011498176718559\n",
      "\n",
      "auroc 3Emphysema: 0.3803704904494146\n",
      "\n",
      "auprc 3Emphysema: 0.016367750720864157\n",
      "\n",
      "auroc 4Emphysema: 0.6569413394154265\n",
      "\n",
      "auprc 4Emphysema: 0.037054418496181185\n",
      "\n",
      "auroc 5Emphysema: 0.8088201373632578\n",
      "\n",
      "auprc 5Emphysema: 0.10899340664763284\n",
      "\n",
      "mean auroc: 0.6177500932852874\n",
      "\n",
      "mean auprc: 0.04429912360462632\n",
      "\n",
      "max auroc: 0.8088201373632578\n",
      "\n",
      "max auprc: 0.10899340664763284\n",
      "\n",
      "78.2512149810791\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1791/1799 [============================>.] - ETA: 0s - loss: 6.4539 - leftLayer1_loss: 0.1202 - midLayer1_loss: 1.3326 - rightLayer1_loss: 1.7942 - leftLayer2_loss: 0.1193 - midLayer2_loss: 1.4859 - rightLayer2_loss: 1.6017\n",
      "Epoch 00001: val_loss improved from inf to 6.13924, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 6.4526 - leftLayer1_loss: 0.1202 - midLayer1_loss: 1.3325 - rightLayer1_loss: 1.7937 - leftLayer2_loss: 0.1192 - midLayer2_loss: 1.4861 - rightLayer2_loss: 1.6008 - val_loss: 6.1392 - val_leftLayer1_loss: 0.1171 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.6804 - val_leftLayer2_loss: 0.1170 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.5324\n",
      "Epoch 2/11\n",
      "1778/1799 [============================>.] - ETA: 0s - loss: 5.8362 - leftLayer1_loss: 0.1162 - midLayer1_loss: 1.3318 - rightLayer1_loss: 1.5785 - leftLayer2_loss: 0.1087 - midLayer2_loss: 1.4849 - rightLayer2_loss: 1.2161\n",
      "Epoch 00002: val_loss improved from 6.13924 to 5.73770, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.8345 - leftLayer1_loss: 0.1161 - midLayer1_loss: 1.3320 - rightLayer1_loss: 1.5776 - leftLayer2_loss: 0.1086 - midLayer2_loss: 1.4847 - rightLayer2_loss: 1.2154 - val_loss: 5.7377 - val_leftLayer1_loss: 0.1133 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.4840 - val_leftLayer2_loss: 0.1110 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.3372\n",
      "Epoch 3/11\n",
      "1777/1799 [============================>.] - ETA: 0s - loss: 5.4828 - leftLayer1_loss: 0.1124 - midLayer1_loss: 1.3325 - rightLayer1_loss: 1.4033 - leftLayer2_loss: 0.0997 - midLayer2_loss: 1.4861 - rightLayer2_loss: 1.0488\n",
      "Epoch 00003: val_loss improved from 5.73770 to 5.46727, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.4835 - leftLayer1_loss: 0.1123 - midLayer1_loss: 1.3327 - rightLayer1_loss: 1.4029 - leftLayer2_loss: 0.0996 - midLayer2_loss: 1.4868 - rightLayer2_loss: 1.0491 - val_loss: 5.4673 - val_leftLayer1_loss: 0.1096 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.3322 - val_leftLayer2_loss: 0.1056 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.2276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 5.2660 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.3322 - rightLayer1_loss: 1.2734 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.4889 - rightLayer2_loss: 0.9707\n",
      "Epoch 00004: val_loss improved from 5.46727 to 5.27943, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 5.2674 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.3324 - rightLayer1_loss: 1.2733 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.4894 - rightLayer2_loss: 0.9715 - val_loss: 5.2794 - val_leftLayer1_loss: 0.1060 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.2204 - val_leftLayer2_loss: 0.1008 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.1599\n",
      "Epoch 5/11\n",
      "1791/1799 [============================>.] - ETA: 0s - loss: 5.1190 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.3324 - rightLayer1_loss: 1.1774 - leftLayer2_loss: 0.0855 - midLayer2_loss: 1.4900 - rightLayer2_loss: 0.9285\n",
      "Epoch 00005: val_loss improved from 5.27943 to 5.14429, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.1184 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.3323 - rightLayer1_loss: 1.1773 - leftLayer2_loss: 0.0855 - midLayer2_loss: 1.4897 - rightLayer2_loss: 0.9284 - val_loss: 5.1443 - val_leftLayer1_loss: 0.1027 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.1389 - val_leftLayer2_loss: 0.0965 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.1139\n",
      "Epoch 6/11\n",
      "1793/1799 [============================>.] - ETA: 0s - loss: 5.0103 - leftLayer1_loss: 0.1020 - midLayer1_loss: 1.3331 - rightLayer1_loss: 1.1071 - leftLayer2_loss: 0.0797 - midLayer2_loss: 1.4856 - rightLayer2_loss: 0.9029\n",
      "Epoch 00006: val_loss improved from 5.14429 to 5.04403, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 5.0097 - leftLayer1_loss: 0.1020 - midLayer1_loss: 1.3331 - rightLayer1_loss: 1.1069 - leftLayer2_loss: 0.0796 - midLayer2_loss: 1.4853 - rightLayer2_loss: 0.9027 - val_loss: 5.0440 - val_leftLayer1_loss: 0.0995 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.0790 - val_leftLayer2_loss: 0.0927 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.0805\n",
      "Epoch 7/11\n",
      "1780/1799 [============================>.] - ETA: 0s - loss: 4.9294 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.3321 - rightLayer1_loss: 1.0547 - leftLayer2_loss: 0.0745 - midLayer2_loss: 1.4858 - rightLayer2_loss: 0.8834\n",
      "Epoch 00007: val_loss improved from 5.04403 to 4.96724, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9322 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.3323 - rightLayer1_loss: 1.0553 - leftLayer2_loss: 0.0745 - midLayer2_loss: 1.4865 - rightLayer2_loss: 0.8847 - val_loss: 4.9672 - val_leftLayer1_loss: 0.0966 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.0343 - val_leftLayer2_loss: 0.0893 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.0548\n",
      "Epoch 8/11\n",
      "1785/1799 [============================>.] - ETA: 0s - loss: 4.8757 - leftLayer1_loss: 0.0960 - midLayer1_loss: 1.3329 - rightLayer1_loss: 1.0169 - leftLayer2_loss: 0.0702 - midLayer2_loss: 1.4863 - rightLayer2_loss: 0.8734\n",
      "Epoch 00008: val_loss improved from 4.96724 to 4.90688, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8771 - leftLayer1_loss: 0.0959 - midLayer1_loss: 1.3330 - rightLayer1_loss: 1.0172 - leftLayer2_loss: 0.0702 - midLayer2_loss: 1.4869 - rightLayer2_loss: 0.8738 - val_loss: 4.9069 - val_leftLayer1_loss: 0.0937 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 1.0002 - val_leftLayer2_loss: 0.0863 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.0344\n",
      "Epoch 9/11\n",
      "1784/1799 [============================>.] - ETA: 0s - loss: 4.8255 - leftLayer1_loss: 0.0932 - midLayer1_loss: 1.3312 - rightLayer1_loss: 0.9874 - leftLayer2_loss: 0.0664 - midLayer2_loss: 1.4847 - rightLayer2_loss: 0.8627\n",
      "Epoch 00009: val_loss improved from 4.90688 to 4.85826, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8266 - leftLayer1_loss: 0.0932 - midLayer1_loss: 1.3314 - rightLayer1_loss: 0.9877 - leftLayer2_loss: 0.0664 - midLayer2_loss: 1.4844 - rightLayer2_loss: 0.8635 - val_loss: 4.8583 - val_leftLayer1_loss: 0.0910 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 0.9737 - val_leftLayer2_loss: 0.0835 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.0178\n",
      "Epoch 10/11\n",
      "1792/1799 [============================>.] - ETA: 0s - loss: 4.7957 - leftLayer1_loss: 0.0905 - midLayer1_loss: 1.3318 - rightLayer1_loss: 0.9630 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.4916 - rightLayer2_loss: 0.8554\n",
      "Epoch 00010: val_loss improved from 4.85826 to 4.81816, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7952 - leftLayer1_loss: 0.0905 - midLayer1_loss: 1.3318 - rightLayer1_loss: 0.9630 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.4912 - rightLayer2_loss: 0.8554 - val_loss: 4.8182 - val_leftLayer1_loss: 0.0885 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 0.9526 - val_leftLayer2_loss: 0.0810 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 1.0038\n",
      "Epoch 11/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 4.7578 - leftLayer1_loss: 0.0880 - midLayer1_loss: 1.3319 - rightLayer1_loss: 0.9433 - leftLayer2_loss: 0.0608 - midLayer2_loss: 1.4836 - rightLayer2_loss: 0.8501\n",
      "Epoch 00011: val_loss improved from 4.81816 to 4.78468, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7606 - leftLayer1_loss: 0.0880 - midLayer1_loss: 1.3322 - rightLayer1_loss: 0.9441 - leftLayer2_loss: 0.0609 - midLayer2_loss: 1.4841 - rightLayer2_loss: 0.8512 - val_loss: 4.7847 - val_leftLayer1_loss: 0.0861 - val_midLayer1_loss: 1.3280 - val_rightLayer1_loss: 0.9355 - val_leftLayer2_loss: 0.0788 - val_midLayer2_loss: 1.3642 - val_rightLayer2_loss: 0.9921\n",
      "22433/22433 [==============================] - 31s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Emphysema: 0.2362721872917659\n",
      "\n",
      "auprc 0Emphysema: 0.01356066909686719\n",
      "\n",
      "auroc 1Emphysema: 0.6208930278522448\n",
      "\n",
      "auprc 1Emphysema: 0.03222677025333254\n",
      "\n",
      "auroc 2Emphysema: 0.6820453422055617\n",
      "\n",
      "auprc 2Emphysema: 0.0369347455215338\n",
      "\n",
      "auroc 3Emphysema: 0.6674121424646456\n",
      "\n",
      "auprc 3Emphysema: 0.0356893519091707\n",
      "\n",
      "auroc 4Emphysema: 0.7009685450255194\n",
      "\n",
      "auprc 4Emphysema: 0.041353502387968616\n",
      "\n",
      "auroc 5Emphysema: 0.4994959816533558\n",
      "\n",
      "auprc 5Emphysema: 0.020622249891461285\n",
      "\n",
      "mean auroc: 0.5678478710821823\n",
      "\n",
      "mean auprc: 0.030064548176722352\n",
      "\n",
      "max auroc: 0.7009685450255194\n",
      "\n",
      "max auprc: 0.041353502387968616\n",
      "\n",
      "81.6869523525238\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 6.5708 - leftLayer1_loss: 0.1218 - midLayer1_loss: 1.5190 - rightLayer1_loss: 1.7495 - leftLayer2_loss: 0.1158 - midLayer2_loss: 1.4929 - rightLayer2_loss: 1.5720\n",
      "Epoch 00001: val_loss improved from inf to 6.23641, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 6s 3ms/step - loss: 6.5677 - leftLayer1_loss: 0.1217 - midLayer1_loss: 1.5193 - rightLayer1_loss: 1.7483 - leftLayer2_loss: 0.1157 - midLayer2_loss: 1.4931 - rightLayer2_loss: 1.5696 - val_loss: 6.2364 - val_leftLayer1_loss: 0.1194 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.6269 - val_leftLayer2_loss: 0.1136 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.4932\n",
      "Epoch 2/11\n",
      "1798/1799 [============================>.] - ETA: 0s - loss: 5.9397 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.5193 - rightLayer1_loss: 1.5126 - leftLayer2_loss: 0.1050 - midLayer2_loss: 1.5003 - rightLayer2_loss: 1.1855\n",
      "Epoch 00002: val_loss improved from 6.23641 to 5.82221, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.9396 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.5193 - rightLayer1_loss: 1.5124 - leftLayer2_loss: 0.1050 - midLayer2_loss: 1.5005 - rightLayer2_loss: 1.1854 - val_loss: 5.8222 - val_leftLayer1_loss: 0.1150 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.4220 - val_leftLayer2_loss: 0.1073 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.2946\n",
      "Epoch 3/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 5.5950 - leftLayer1_loss: 0.1128 - midLayer1_loss: 1.5188 - rightLayer1_loss: 1.3337 - leftLayer2_loss: 0.0961 - midLayer2_loss: 1.5089 - rightLayer2_loss: 1.0247\n",
      "Epoch 00003: val_loss improved from 5.82221 to 5.55628, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.5945 - leftLayer1_loss: 0.1127 - midLayer1_loss: 1.5189 - rightLayer1_loss: 1.3336 - leftLayer2_loss: 0.0961 - midLayer2_loss: 1.5086 - rightLayer2_loss: 1.0245 - val_loss: 5.5563 - val_leftLayer1_loss: 0.1108 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.2732 - val_leftLayer2_loss: 0.1018 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.1872\n",
      "Epoch 4/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 5.3783 - leftLayer1_loss: 0.1086 - midLayer1_loss: 1.5189 - rightLayer1_loss: 1.2078 - leftLayer2_loss: 0.0886 - midLayer2_loss: 1.4995 - rightLayer2_loss: 0.9549\n",
      "Epoch 00004: val_loss improved from 5.55628 to 5.37830, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.3780 - leftLayer1_loss: 0.1086 - midLayer1_loss: 1.5191 - rightLayer1_loss: 1.2078 - leftLayer2_loss: 0.0886 - midLayer2_loss: 1.4992 - rightLayer2_loss: 0.9548 - val_loss: 5.3783 - val_leftLayer1_loss: 0.1068 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.1692 - val_leftLayer2_loss: 0.0969 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.1220\n",
      "Epoch 5/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 5.2377 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.5186 - rightLayer1_loss: 1.1208 - leftLayer2_loss: 0.0822 - midLayer2_loss: 1.4994 - rightLayer2_loss: 0.9121\n",
      "Epoch 00005: val_loss improved from 5.37830 to 5.25380, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.2387 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.5189 - rightLayer1_loss: 1.1212 - leftLayer2_loss: 0.0821 - midLayer2_loss: 1.4991 - rightLayer2_loss: 0.9128 - val_loss: 5.2538 - val_leftLayer1_loss: 0.1031 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.0965 - val_leftLayer2_loss: 0.0926 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.0783\n",
      "Epoch 6/11\n",
      "1796/1799 [============================>.] - ETA: 0s - loss: 5.1486 - leftLayer1_loss: 0.1010 - midLayer1_loss: 1.5187 - rightLayer1_loss: 1.0603 - leftLayer2_loss: 0.0763 - midLayer2_loss: 1.5017 - rightLayer2_loss: 0.8906\n",
      "Epoch 00006: val_loss improved from 5.25380 to 5.16302, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.1482 - leftLayer1_loss: 0.1010 - midLayer1_loss: 1.5186 - rightLayer1_loss: 1.0601 - leftLayer2_loss: 0.0763 - midLayer2_loss: 1.5017 - rightLayer2_loss: 0.8904 - val_loss: 5.1630 - val_leftLayer1_loss: 0.0996 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.0444 - val_leftLayer2_loss: 0.0887 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.0469\n",
      "Epoch 7/11\n",
      "1787/1799 [============================>.] - ETA: 0s - loss: 5.0813 - leftLayer1_loss: 0.0976 - midLayer1_loss: 1.5198 - rightLayer1_loss: 1.0157 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.5016 - rightLayer2_loss: 0.8746\n",
      "Epoch 00007: val_loss improved from 5.16302 to 5.09412, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.0821 - leftLayer1_loss: 0.0976 - midLayer1_loss: 1.5202 - rightLayer1_loss: 1.0157 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.5016 - rightLayer2_loss: 0.8749 - val_loss: 5.0941 - val_leftLayer1_loss: 0.0963 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 1.0062 - val_leftLayer2_loss: 0.0853 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.0230\n",
      "Epoch 8/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 5.0308 - leftLayer1_loss: 0.0943 - midLayer1_loss: 1.5196 - rightLayer1_loss: 0.9835 - leftLayer2_loss: 0.0677 - midLayer2_loss: 1.5019 - rightLayer2_loss: 0.8638\n",
      "Epoch 00008: val_loss improved from 5.09412 to 5.04004, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.0312 - leftLayer1_loss: 0.0943 - midLayer1_loss: 1.5197 - rightLayer1_loss: 0.9835 - leftLayer2_loss: 0.0677 - midLayer2_loss: 1.5021 - rightLayer2_loss: 0.8638 - val_loss: 5.0400 - val_leftLayer1_loss: 0.0932 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 0.9773 - val_leftLayer2_loss: 0.0823 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 1.0039\n",
      "Epoch 9/11\n",
      "1791/1799 [============================>.] - ETA: 0s - loss: 4.9915 - leftLayer1_loss: 0.0913 - midLayer1_loss: 1.5181 - rightLayer1_loss: 0.9595 - leftLayer2_loss: 0.0644 - midLayer2_loss: 1.5011 - rightLayer2_loss: 0.8570\n",
      "Epoch 00009: val_loss improved from 5.04004 to 4.99646, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9920 - leftLayer1_loss: 0.0913 - midLayer1_loss: 1.5182 - rightLayer1_loss: 0.9596 - leftLayer2_loss: 0.0644 - midLayer2_loss: 1.5015 - rightLayer2_loss: 0.8570 - val_loss: 4.9965 - val_leftLayer1_loss: 0.0903 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 0.9548 - val_leftLayer2_loss: 0.0796 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 0.9885\n",
      "Epoch 10/11\n",
      "1787/1799 [============================>.] - ETA: 0s - loss: 4.9628 - leftLayer1_loss: 0.0885 - midLayer1_loss: 1.5176 - rightLayer1_loss: 0.9393 - leftLayer2_loss: 0.0614 - midLayer2_loss: 1.5042 - rightLayer2_loss: 0.8518\n",
      "Epoch 00010: val_loss improved from 4.99646 to 4.96037, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9638 - leftLayer1_loss: 0.0885 - midLayer1_loss: 1.5181 - rightLayer1_loss: 0.9395 - leftLayer2_loss: 0.0614 - midLayer2_loss: 1.5044 - rightLayer2_loss: 0.8521 - val_loss: 4.9604 - val_leftLayer1_loss: 0.0876 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 0.9370 - val_leftLayer2_loss: 0.0771 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 0.9753\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1798/1799 [============================>.] - ETA: 0s - loss: 4.9299 - leftLayer1_loss: 0.0858 - midLayer1_loss: 1.5196 - rightLayer1_loss: 0.9237 - leftLayer2_loss: 0.0586 - midLayer2_loss: 1.4987 - rightLayer2_loss: 0.8435\n",
      "Epoch 00011: val_loss improved from 4.96037 to 4.93023, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9293 - leftLayer1_loss: 0.0858 - midLayer1_loss: 1.5195 - rightLayer1_loss: 0.9235 - leftLayer2_loss: 0.0586 - midLayer2_loss: 1.4987 - rightLayer2_loss: 0.8432 - val_loss: 4.9302 - val_leftLayer1_loss: 0.0850 - val_midLayer1_loss: 1.5011 - val_rightLayer1_loss: 0.9226 - val_leftLayer2_loss: 0.0749 - val_midLayer2_loss: 1.3822 - val_rightLayer2_loss: 0.9644\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Emphysema: 0.48883327616137046\n",
      "\n",
      "auprc 0Emphysema: 0.020413442506064448\n",
      "\n",
      "auroc 1Emphysema: 0.5372185893830769\n",
      "\n",
      "auprc 1Emphysema: 0.028585946961821873\n",
      "\n",
      "auroc 2Emphysema: 0.7042400268977058\n",
      "\n",
      "auprc 2Emphysema: 0.04353344746242461\n",
      "\n",
      "auroc 3Emphysema: 0.5220347734574413\n",
      "\n",
      "auprc 3Emphysema: 0.022426682278625147\n",
      "\n",
      "auroc 4Emphysema: 0.6403890256356214\n",
      "\n",
      "auprc 4Emphysema: 0.03708744331643454\n",
      "\n",
      "auroc 5Emphysema: 0.5388394324526701\n",
      "\n",
      "auprc 5Emphysema: 0.02326233735013626\n",
      "\n",
      "mean auroc: 0.5719258539979809\n",
      "\n",
      "mean auprc: 0.02921821664591781\n",
      "\n",
      "max auroc: 0.7042400268977058\n",
      "\n",
      "max auprc: 0.04353344746242461\n",
      "\n",
      "81.66059017181396\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1795/1799 [============================>.] - ETA: 0s - loss: 6.2696 - leftLayer1_loss: 0.1247 - midLayer1_loss: 1.3161 - rightLayer1_loss: 1.7529 - leftLayer2_loss: 0.1215 - midLayer2_loss: 1.3952 - rightLayer2_loss: 1.5593\n",
      "Epoch 00001: val_loss improved from inf to 5.99952, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 6.2684 - leftLayer1_loss: 0.1247 - midLayer1_loss: 1.3160 - rightLayer1_loss: 1.7526 - leftLayer2_loss: 0.1214 - midLayer2_loss: 1.3951 - rightLayer2_loss: 1.5586 - val_loss: 5.9995 - val_leftLayer1_loss: 0.1214 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 1.6189 - val_leftLayer2_loss: 0.1158 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.4952\n",
      "Epoch 2/11\n",
      "1782/1799 [============================>.] - ETA: 0s - loss: 5.6273 - leftLayer1_loss: 0.1194 - midLayer1_loss: 1.3137 - rightLayer1_loss: 1.5026 - leftLayer2_loss: 0.1106 - midLayer2_loss: 1.3982 - rightLayer2_loss: 1.1827\n",
      "Epoch 00002: val_loss improved from 5.99952 to 5.57381, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.6277 - leftLayer1_loss: 0.1194 - midLayer1_loss: 1.3141 - rightLayer1_loss: 1.5020 - leftLayer2_loss: 0.1106 - midLayer2_loss: 1.3990 - rightLayer2_loss: 1.1825 - val_loss: 5.5738 - val_leftLayer1_loss: 0.1164 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 1.4020 - val_leftLayer2_loss: 0.1092 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.2979\n",
      "Epoch 3/11\n",
      "1791/1799 [============================>.] - ETA: 0s - loss: 5.2711 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.3150 - rightLayer1_loss: 1.3180 - leftLayer2_loss: 0.1007 - midLayer2_loss: 1.3972 - rightLayer2_loss: 1.0255\n",
      "Epoch 00003: val_loss improved from 5.57381 to 5.30402, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.2706 - leftLayer1_loss: 0.1147 - midLayer1_loss: 1.3149 - rightLayer1_loss: 1.3179 - leftLayer2_loss: 0.1007 - midLayer2_loss: 1.3971 - rightLayer2_loss: 1.0254 - val_loss: 5.3040 - val_leftLayer1_loss: 0.1118 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 1.2498 - val_leftLayer2_loss: 0.1034 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.1908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1776/1799 [============================>.] - ETA: 0s - loss: 5.0579 - leftLayer1_loss: 0.1101 - midLayer1_loss: 1.3148 - rightLayer1_loss: 1.1921 - leftLayer2_loss: 0.0927 - midLayer2_loss: 1.3962 - rightLayer2_loss: 0.9520\n",
      "Epoch 00004: val_loss improved from 5.30402 to 5.12616, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 5.0598 - leftLayer1_loss: 0.1101 - midLayer1_loss: 1.3150 - rightLayer1_loss: 1.1922 - leftLayer2_loss: 0.0927 - midLayer2_loss: 1.3970 - rightLayer2_loss: 0.9528 - val_loss: 5.1262 - val_leftLayer1_loss: 0.1074 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 1.1467 - val_leftLayer2_loss: 0.0983 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.1256\n",
      "Epoch 5/11\n",
      "1782/1799 [============================>.] - ETA: 0s - loss: 4.9215 - leftLayer1_loss: 0.1059 - midLayer1_loss: 1.3149 - rightLayer1_loss: 1.1062 - leftLayer2_loss: 0.0855 - midLayer2_loss: 1.3954 - rightLayer2_loss: 0.9136\n",
      "Epoch 00005: val_loss improved from 5.12616 to 5.00323, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.9235 - leftLayer1_loss: 0.1059 - midLayer1_loss: 1.3154 - rightLayer1_loss: 1.1066 - leftLayer2_loss: 0.0854 - midLayer2_loss: 1.3958 - rightLayer2_loss: 0.9144 - val_loss: 5.0032 - val_leftLayer1_loss: 0.1033 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 1.0762 - val_leftLayer2_loss: 0.0937 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.0818\n",
      "Epoch 6/11\n",
      "1777/1799 [============================>.] - ETA: 0s - loss: 4.8316 - leftLayer1_loss: 0.1018 - midLayer1_loss: 1.3141 - rightLayer1_loss: 1.0472 - leftLayer2_loss: 0.0794 - midLayer2_loss: 1.3996 - rightLayer2_loss: 0.8895\n",
      "Epoch 00006: val_loss improved from 5.00323 to 4.91423, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.8343 - leftLayer1_loss: 0.1018 - midLayer1_loss: 1.3144 - rightLayer1_loss: 1.0479 - leftLayer2_loss: 0.0794 - midLayer2_loss: 1.4002 - rightLayer2_loss: 0.8907 - val_loss: 4.9142 - val_leftLayer1_loss: 0.0994 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 1.0268 - val_leftLayer2_loss: 0.0897 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.0501\n",
      "Epoch 7/11\n",
      "1796/1799 [============================>.] - ETA: 0s - loss: 4.7654 - leftLayer1_loss: 0.0980 - midLayer1_loss: 1.3146 - rightLayer1_loss: 1.0058 - leftLayer2_loss: 0.0744 - midLayer2_loss: 1.3978 - rightLayer2_loss: 0.8748\n",
      "Epoch 00007: val_loss improved from 4.91423 to 4.84686, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7648 - leftLayer1_loss: 0.0980 - midLayer1_loss: 1.3146 - rightLayer1_loss: 1.0056 - leftLayer2_loss: 0.0744 - midLayer2_loss: 1.3978 - rightLayer2_loss: 0.8745 - val_loss: 4.8469 - val_leftLayer1_loss: 0.0958 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 0.9909 - val_leftLayer2_loss: 0.0861 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.0258\n",
      "Epoch 8/11\n",
      "1792/1799 [============================>.] - ETA: 0s - loss: 4.7081 - leftLayer1_loss: 0.0945 - midLayer1_loss: 1.3151 - rightLayer1_loss: 0.9745 - leftLayer2_loss: 0.0699 - midLayer2_loss: 1.3901 - rightLayer2_loss: 0.8638\n",
      "Epoch 00008: val_loss improved from 4.84686 to 4.79410, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.7077 - leftLayer1_loss: 0.0945 - midLayer1_loss: 1.3151 - rightLayer1_loss: 0.9746 - leftLayer2_loss: 0.0699 - midLayer2_loss: 1.3899 - rightLayer2_loss: 0.8637 - val_loss: 4.7941 - val_leftLayer1_loss: 0.0924 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 0.9640 - val_leftLayer2_loss: 0.0829 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 1.0065\n",
      "Epoch 9/11\n",
      "1784/1799 [============================>.] - ETA: 0s - loss: 4.6749 - leftLayer1_loss: 0.0913 - midLayer1_loss: 1.3140 - rightLayer1_loss: 0.9511 - leftLayer2_loss: 0.0660 - midLayer2_loss: 1.3942 - rightLayer2_loss: 0.8583\n",
      "Epoch 00009: val_loss improved from 4.79410 to 4.75156, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.6760 - leftLayer1_loss: 0.0913 - midLayer1_loss: 1.3140 - rightLayer1_loss: 0.9515 - leftLayer2_loss: 0.0660 - midLayer2_loss: 1.3941 - rightLayer2_loss: 0.8591 - val_loss: 4.7516 - val_leftLayer1_loss: 0.0893 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 0.9432 - val_leftLayer2_loss: 0.0801 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 0.9908\n",
      "Epoch 10/11\n",
      "1790/1799 [============================>.] - ETA: 0s - loss: 4.6505 - leftLayer1_loss: 0.0882 - midLayer1_loss: 1.3154 - rightLayer1_loss: 0.9331 - leftLayer2_loss: 0.0628 - midLayer2_loss: 1.3985 - rightLayer2_loss: 0.8525\n",
      "Epoch 00010: val_loss improved from 4.75156 to 4.71625, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 4.6511 - leftLayer1_loss: 0.0882 - midLayer1_loss: 1.3154 - rightLayer1_loss: 0.9333 - leftLayer2_loss: 0.0628 - midLayer2_loss: 1.3986 - rightLayer2_loss: 0.8527 - val_loss: 4.7162 - val_leftLayer1_loss: 0.0863 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 0.9266 - val_leftLayer2_loss: 0.0776 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 0.9775\n",
      "Epoch 11/11\n",
      "1785/1799 [============================>.] - ETA: 0s - loss: 4.6278 - leftLayer1_loss: 0.0853 - midLayer1_loss: 1.3153 - rightLayer1_loss: 0.9180 - leftLayer2_loss: 0.0600 - midLayer2_loss: 1.4035 - rightLayer2_loss: 0.8457\n",
      "Epoch 00011: val_loss improved from 4.71625 to 4.68670, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.6285 - leftLayer1_loss: 0.0853 - midLayer1_loss: 1.3153 - rightLayer1_loss: 0.9185 - leftLayer2_loss: 0.0600 - midLayer2_loss: 1.4034 - rightLayer2_loss: 0.8461 - val_loss: 4.6867 - val_leftLayer1_loss: 0.0836 - val_midLayer1_loss: 1.3007 - val_rightLayer1_loss: 0.9132 - val_leftLayer2_loss: 0.0753 - val_midLayer2_loss: 1.3475 - val_rightLayer2_loss: 0.9664\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Emphysema: 0.8607676760833729\n",
      "\n",
      "auprc 0Emphysema: 0.14769244196181308\n",
      "\n",
      "auroc 1Emphysema: 0.5294749696128329\n",
      "\n",
      "auprc 1Emphysema: 0.02376282197398355\n",
      "\n",
      "auroc 2Emphysema: 0.7325769339267747\n",
      "\n",
      "auprc 2Emphysema: 0.04369765228698485\n",
      "\n",
      "auroc 3Emphysema: 0.5922861670016335\n",
      "\n",
      "auprc 3Emphysema: 0.04145728958409027\n",
      "\n",
      "auroc 4Emphysema: 0.5545577793477665\n",
      "\n",
      "auprc 4Emphysema: 0.027589720456744647\n",
      "\n",
      "auroc 5Emphysema: 0.5649339977468153\n",
      "\n",
      "auprc 5Emphysema: 0.025088642623686108\n",
      "\n",
      "mean auroc: 0.6390995872865327\n",
      "\n",
      "mean auprc: 0.051548094814550416\n",
      "\n",
      "max auroc: 0.8607676760833729\n",
      "\n",
      "max auprc: 0.14769244196181308\n",
      "\n",
      "78.41809797286987\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1783/1799 [============================>.] - ETA: 0s - loss: 6.4861 - leftLayer1_loss: 0.1270 - midLayer1_loss: 1.4380 - rightLayer1_loss: 1.7517 - leftLayer2_loss: 0.1227 - midLayer2_loss: 1.4450 - rightLayer2_loss: 1.6017\n",
      "Epoch 00001: val_loss improved from inf to 6.15807, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 6.4836 - leftLayer1_loss: 0.1270 - midLayer1_loss: 1.4382 - rightLayer1_loss: 1.7509 - leftLayer2_loss: 0.1226 - midLayer2_loss: 1.4455 - rightLayer2_loss: 1.5994 - val_loss: 6.1581 - val_leftLayer1_loss: 0.1252 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.6385 - val_leftLayer2_loss: 0.1168 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.4885\n",
      "Epoch 2/11\n",
      "1790/1799 [============================>.] - ETA: 0s - loss: 5.8449 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4387 - rightLayer1_loss: 1.5453 - leftLayer2_loss: 0.1102 - midLayer2_loss: 1.4476 - rightLayer2_loss: 1.1802\n",
      "Epoch 00002: val_loss improved from 6.15807 to 5.74415, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.8443 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4388 - rightLayer1_loss: 1.5449 - leftLayer2_loss: 0.1102 - midLayer2_loss: 1.4475 - rightLayer2_loss: 1.1801 - val_loss: 5.7441 - val_leftLayer1_loss: 0.1210 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.4531 - val_leftLayer2_loss: 0.1092 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.2718\n",
      "Epoch 3/11\n",
      "1786/1799 [============================>.] - ETA: 0s - loss: 5.4954 - leftLayer1_loss: 0.1188 - midLayer1_loss: 1.4392 - rightLayer1_loss: 1.3813 - leftLayer2_loss: 0.0999 - midLayer2_loss: 1.4409 - rightLayer2_loss: 1.0154\n",
      "Epoch 00003: val_loss improved from 5.74415 to 5.48176, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.4962 - leftLayer1_loss: 0.1188 - midLayer1_loss: 1.4394 - rightLayer1_loss: 1.3810 - leftLayer2_loss: 0.0999 - midLayer2_loss: 1.4415 - rightLayer2_loss: 1.0157 - val_loss: 5.4818 - val_leftLayer1_loss: 0.1171 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.3107 - val_leftLayer2_loss: 0.1026 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.1624\n",
      "Epoch 4/11\n",
      "1781/1799 [============================>.] - ETA: 0s - loss: 5.2982 - leftLayer1_loss: 0.1148 - midLayer1_loss: 1.4380 - rightLayer1_loss: 1.2573 - leftLayer2_loss: 0.0907 - midLayer2_loss: 1.4501 - rightLayer2_loss: 0.9473\n",
      "Epoch 00004: val_loss improved from 5.48176 to 5.30252, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.2999 - leftLayer1_loss: 0.1148 - midLayer1_loss: 1.4381 - rightLayer1_loss: 1.2573 - leftLayer2_loss: 0.0907 - midLayer2_loss: 1.4509 - rightLayer2_loss: 0.9481 - val_loss: 5.3025 - val_leftLayer1_loss: 0.1133 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.2056 - val_leftLayer2_loss: 0.0968 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.0978\n",
      "Epoch 5/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 5.1538 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.4388 - rightLayer1_loss: 1.1672 - leftLayer2_loss: 0.0834 - midLayer2_loss: 1.4426 - rightLayer2_loss: 0.9104\n",
      "Epoch 00005: val_loss improved from 5.30252 to 5.17478, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.1536 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.4388 - rightLayer1_loss: 1.1672 - leftLayer2_loss: 0.0834 - midLayer2_loss: 1.4424 - rightLayer2_loss: 0.9104 - val_loss: 5.1748 - val_leftLayer1_loss: 0.1097 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.1286 - val_leftLayer2_loss: 0.0917 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.0556\n",
      "Epoch 6/11\n",
      "1777/1799 [============================>.] - ETA: 0s - loss: 5.0526 - leftLayer1_loss: 0.1078 - midLayer1_loss: 1.4380 - rightLayer1_loss: 1.1009 - leftLayer2_loss: 0.0772 - midLayer2_loss: 1.4401 - rightLayer2_loss: 0.8885\n",
      "Epoch 00006: val_loss improved from 5.17478 to 5.08000, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.0550 - leftLayer1_loss: 0.1077 - midLayer1_loss: 1.4381 - rightLayer1_loss: 1.1014 - leftLayer2_loss: 0.0772 - midLayer2_loss: 1.4407 - rightLayer2_loss: 0.8898 - val_loss: 5.0800 - val_leftLayer1_loss: 0.1064 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.0718 - val_leftLayer2_loss: 0.0873 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.0254\n",
      "Epoch 7/11\n",
      "1778/1799 [============================>.] - ETA: 0s - loss: 4.9790 - leftLayer1_loss: 0.1044 - midLayer1_loss: 1.4385 - rightLayer1_loss: 1.0508 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.4400 - rightLayer2_loss: 0.8732\n",
      "Epoch 00007: val_loss improved from 5.08000 to 5.00751, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9808 - leftLayer1_loss: 0.1044 - midLayer1_loss: 1.4385 - rightLayer1_loss: 1.0514 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.4404 - rightLayer2_loss: 0.8741 - val_loss: 5.0075 - val_leftLayer1_loss: 0.1031 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 1.0291 - val_leftLayer2_loss: 0.0835 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 1.0028\n",
      "Epoch 8/11\n",
      "1789/1799 [============================>.] - ETA: 0s - loss: 4.9335 - leftLayer1_loss: 0.1013 - midLayer1_loss: 1.4387 - rightLayer1_loss: 1.0137 - leftLayer2_loss: 0.0674 - midLayer2_loss: 1.4489 - rightLayer2_loss: 0.8636\n",
      "Epoch 00008: val_loss improved from 5.00751 to 4.95036, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9330 - leftLayer1_loss: 0.1013 - midLayer1_loss: 1.4386 - rightLayer1_loss: 1.0137 - leftLayer2_loss: 0.0674 - midLayer2_loss: 1.4485 - rightLayer2_loss: 0.8635 - val_loss: 4.9504 - val_leftLayer1_loss: 0.1001 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 0.9963 - val_leftLayer2_loss: 0.0801 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 0.9848\n",
      "Epoch 9/11\n",
      "1793/1799 [============================>.] - ETA: 0s - loss: 4.8822 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.4377 - rightLayer1_loss: 0.9849 - leftLayer2_loss: 0.0636 - midLayer2_loss: 1.4416 - rightLayer2_loss: 0.8560\n",
      "Epoch 00009: val_loss improved from 4.95036 to 4.90449, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8817 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.4376 - rightLayer1_loss: 0.9848 - leftLayer2_loss: 0.0636 - midLayer2_loss: 1.4415 - rightLayer2_loss: 0.8558 - val_loss: 4.9045 - val_leftLayer1_loss: 0.0971 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 0.9706 - val_leftLayer2_loss: 0.0771 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 0.9705\n",
      "Epoch 10/11\n",
      "1779/1799 [============================>.] - ETA: 0s - loss: 4.8568 - leftLayer1_loss: 0.0955 - midLayer1_loss: 1.4393 - rightLayer1_loss: 0.9616 - leftLayer2_loss: 0.0606 - midLayer2_loss: 1.4507 - rightLayer2_loss: 0.8489\n",
      "Epoch 00010: val_loss improved from 4.90449 to 4.86641, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8587 - leftLayer1_loss: 0.0955 - midLayer1_loss: 1.4395 - rightLayer1_loss: 0.9625 - leftLayer2_loss: 0.0606 - midLayer2_loss: 1.4507 - rightLayer2_loss: 0.8499 - val_loss: 4.8664 - val_leftLayer1_loss: 0.0944 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 0.9501 - val_leftLayer2_loss: 0.0745 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 0.9584\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1778/1799 [============================>.] - ETA: 0s - loss: 4.8201 - leftLayer1_loss: 0.0928 - midLayer1_loss: 1.4384 - rightLayer1_loss: 0.9428 - leftLayer2_loss: 0.0576 - midLayer2_loss: 1.4444 - rightLayer2_loss: 0.8442\n",
      "Epoch 00011: val_loss improved from 4.86641 to 4.83469, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1799/1799 [==============================] - 4s 3ms/step - loss: 4.8231 - leftLayer1_loss: 0.0928 - midLayer1_loss: 1.4384 - rightLayer1_loss: 0.9436 - leftLayer2_loss: 0.0576 - midLayer2_loss: 1.4454 - rightLayer2_loss: 0.8452 - val_loss: 4.8347 - val_leftLayer1_loss: 0.0918 - val_midLayer1_loss: 1.4442 - val_rightLayer1_loss: 0.9334 - val_leftLayer2_loss: 0.0722 - val_midLayer2_loss: 1.3449 - val_rightLayer2_loss: 0.9482\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Emphysema: 0.5014360199137654\n",
      "\n",
      "auprc 0Emphysema: 0.02723226693165653\n",
      "\n",
      "auroc 1Emphysema: 0.5524422823047578\n",
      "\n",
      "auprc 1Emphysema: 0.0243295412096405\n",
      "\n",
      "auroc 2Emphysema: 0.745687997364713\n",
      "\n",
      "auprc 2Emphysema: 0.04997561088376121\n",
      "\n",
      "auroc 3Emphysema: 0.7908589110658754\n",
      "\n",
      "auprc 3Emphysema: 0.10397263390599129\n",
      "\n",
      "auroc 4Emphysema: 0.42198912549837286\n",
      "\n",
      "auprc 4Emphysema: 0.018487532259084113\n",
      "\n",
      "auroc 5Emphysema: 0.6932137686575056\n",
      "\n",
      "auprc 5Emphysema: 0.041769588002369795\n",
      "\n",
      "mean auroc: 0.617604684134165\n",
      "\n",
      "mean auprc: 0.04429452886541724\n",
      "\n",
      "max auroc: 0.7908589110658754\n",
      "\n",
      "max auprc: 0.10397263390599129\n",
      "\n",
      "78.56999850273132\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1799 steps, validate for 208 steps\n",
      "Epoch 1/11\n",
      "1788/1799 [============================>.] - ETA: 0s - loss: 6.4043 - leftLayer1_loss: 0.1222 - midLayer1_loss: 1.3313 - rightLayer1_loss: 1.7470 - leftLayer2_loss: 0.1202 - midLayer2_loss: 1.4618 - rightLayer2_loss: 1.6218\n",
      "Epoch 00001: val_loss improved from inf to 6.03513, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 6.4019 - leftLayer1_loss: 0.1222 - midLayer1_loss: 1.3315 - rightLayer1_loss: 1.7461 - leftLayer2_loss: 0.1202 - midLayer2_loss: 1.4620 - rightLayer2_loss: 1.6200 - val_loss: 6.0351 - val_leftLayer1_loss: 0.1193 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 1.6005 - val_leftLayer2_loss: 0.1178 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.5057\n",
      "Epoch 2/11\n",
      "1784/1799 [============================>.] - ETA: 0s - loss: 5.6972 - leftLayer1_loss: 0.1168 - midLayer1_loss: 1.3307 - rightLayer1_loss: 1.4838 - leftLayer2_loss: 0.1082 - midLayer2_loss: 1.4638 - rightLayer2_loss: 1.1938\n",
      "Epoch 00002: val_loss improved from 6.03513 to 5.58336, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.6960 - leftLayer1_loss: 0.1168 - midLayer1_loss: 1.3311 - rightLayer1_loss: 1.4831 - leftLayer2_loss: 0.1082 - midLayer2_loss: 1.4637 - rightLayer2_loss: 1.1931 - val_loss: 5.5834 - val_leftLayer1_loss: 0.1142 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 1.3774 - val_leftLayer2_loss: 0.1108 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.2892\n",
      "Epoch 3/11\n",
      "1790/1799 [============================>.] - ETA: 0s - loss: 5.3234 - leftLayer1_loss: 0.1117 - midLayer1_loss: 1.3319 - rightLayer1_loss: 1.2947 - leftLayer2_loss: 0.0982 - midLayer2_loss: 1.4635 - rightLayer2_loss: 1.0233\n",
      "Epoch 00003: val_loss improved from 5.58336 to 5.30772, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.3238 - leftLayer1_loss: 0.1118 - midLayer1_loss: 1.3321 - rightLayer1_loss: 1.2945 - leftLayer2_loss: 0.0982 - midLayer2_loss: 1.4641 - rightLayer2_loss: 1.0231 - val_loss: 5.3077 - val_leftLayer1_loss: 0.1094 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 1.2252 - val_leftLayer2_loss: 0.1045 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.1767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1786/1799 [============================>.] - ETA: 0s - loss: 5.1040 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.3311 - rightLayer1_loss: 1.1699 - leftLayer2_loss: 0.0900 - midLayer2_loss: 1.4537 - rightLayer2_loss: 0.9522\n",
      "Epoch 00004: val_loss improved from 5.30772 to 5.13092, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 5.1052 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.3316 - rightLayer1_loss: 1.1699 - leftLayer2_loss: 0.0900 - midLayer2_loss: 1.4540 - rightLayer2_loss: 0.9526 - val_loss: 5.1309 - val_leftLayer1_loss: 0.1050 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 1.1247 - val_leftLayer2_loss: 0.0991 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.1103\n",
      "Epoch 5/11\n",
      "1782/1799 [============================>.] - ETA: 0s - loss: 4.9728 - leftLayer1_loss: 0.1028 - midLayer1_loss: 1.3302 - rightLayer1_loss: 1.0870 - leftLayer2_loss: 0.0830 - midLayer2_loss: 1.4579 - rightLayer2_loss: 0.9119\n",
      "Epoch 00005: val_loss improved from 5.13092 to 5.01061, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.9744 - leftLayer1_loss: 0.1028 - midLayer1_loss: 1.3306 - rightLayer1_loss: 1.0874 - leftLayer2_loss: 0.0829 - midLayer2_loss: 1.4577 - rightLayer2_loss: 0.9129 - val_loss: 5.0106 - val_leftLayer1_loss: 0.1008 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 1.0571 - val_leftLayer2_loss: 0.0943 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.0666\n",
      "Epoch 6/11\n",
      "1778/1799 [============================>.] - ETA: 0s - loss: 4.8842 - leftLayer1_loss: 0.0987 - midLayer1_loss: 1.3306 - rightLayer1_loss: 1.0302 - leftLayer2_loss: 0.0770 - midLayer2_loss: 1.4589 - rightLayer2_loss: 0.8887\n",
      "Epoch 00006: val_loss improved from 5.01061 to 4.92450, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8864 - leftLayer1_loss: 0.0987 - midLayer1_loss: 1.3313 - rightLayer1_loss: 1.0307 - leftLayer2_loss: 0.0769 - midLayer2_loss: 1.4590 - rightLayer2_loss: 0.8898 - val_loss: 4.9245 - val_leftLayer1_loss: 0.0970 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 1.0102 - val_leftLayer2_loss: 0.0901 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.0355\n",
      "Epoch 7/11\n",
      "1791/1799 [============================>.] - ETA: 0s - loss: 4.8235 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3304 - rightLayer1_loss: 0.9907 - leftLayer2_loss: 0.0719 - midLayer2_loss: 1.4615 - rightLayer2_loss: 0.8741\n",
      "Epoch 00007: val_loss improved from 4.92450 to 4.85994, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.8240 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3304 - rightLayer1_loss: 0.9907 - leftLayer2_loss: 0.0719 - midLayer2_loss: 1.4621 - rightLayer2_loss: 0.8741 - val_loss: 4.8599 - val_leftLayer1_loss: 0.0934 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 0.9764 - val_leftLayer2_loss: 0.0864 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 1.0120\n",
      "Epoch 8/11\n",
      "1794/1799 [============================>.] - ETA: 0s - loss: 4.7751 - leftLayer1_loss: 0.0914 - midLayer1_loss: 1.3297 - rightLayer1_loss: 0.9622 - leftLayer2_loss: 0.0678 - midLayer2_loss: 1.4607 - rightLayer2_loss: 0.8633\n",
      "Epoch 00008: val_loss improved from 4.85994 to 4.80962, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7757 - leftLayer1_loss: 0.0914 - midLayer1_loss: 1.3297 - rightLayer1_loss: 0.9623 - leftLayer2_loss: 0.0678 - midLayer2_loss: 1.4611 - rightLayer2_loss: 0.8634 - val_loss: 4.8096 - val_leftLayer1_loss: 0.0900 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 0.9512 - val_leftLayer2_loss: 0.0831 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 0.9936\n",
      "Epoch 9/11\n",
      "1793/1799 [============================>.] - ETA: 0s - loss: 4.7402 - leftLayer1_loss: 0.0882 - midLayer1_loss: 1.3317 - rightLayer1_loss: 0.9400 - leftLayer2_loss: 0.0641 - midLayer2_loss: 1.4600 - rightLayer2_loss: 0.8561\n",
      "Epoch 00009: val_loss improved from 4.80962 to 4.76895, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7396 - leftLayer1_loss: 0.0882 - midLayer1_loss: 1.3316 - rightLayer1_loss: 0.9398 - leftLayer2_loss: 0.0641 - midLayer2_loss: 1.4599 - rightLayer2_loss: 0.8559 - val_loss: 4.7689 - val_leftLayer1_loss: 0.0869 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 0.9318 - val_leftLayer2_loss: 0.0802 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 0.9783\n",
      "Epoch 10/11\n",
      "1776/1799 [============================>.] - ETA: 0s - loss: 4.7066 - leftLayer1_loss: 0.0851 - midLayer1_loss: 1.3304 - rightLayer1_loss: 0.9216 - leftLayer2_loss: 0.0607 - midLayer2_loss: 1.4614 - rightLayer2_loss: 0.8475\n",
      "Epoch 00010: val_loss improved from 4.76895 to 4.73550, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.7110 - leftLayer1_loss: 0.0851 - midLayer1_loss: 1.3311 - rightLayer1_loss: 0.9227 - leftLayer2_loss: 0.0608 - midLayer2_loss: 1.4624 - rightLayer2_loss: 0.8489 - val_loss: 4.7355 - val_leftLayer1_loss: 0.0840 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 0.9164 - val_leftLayer2_loss: 0.0776 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 0.9657\n",
      "Epoch 11/11\n",
      "1783/1799 [============================>.] - ETA: 0s - loss: 4.6876 - leftLayer1_loss: 0.0823 - midLayer1_loss: 1.3304 - rightLayer1_loss: 0.9080 - leftLayer2_loss: 0.0581 - midLayer2_loss: 1.4641 - rightLayer2_loss: 0.8446\n",
      "Epoch 00011: val_loss improved from 4.73550 to 4.70745, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1799/1799 [==============================] - 5s 3ms/step - loss: 4.6893 - leftLayer1_loss: 0.0823 - midLayer1_loss: 1.3308 - rightLayer1_loss: 0.9086 - leftLayer2_loss: 0.0581 - midLayer2_loss: 1.4643 - rightLayer2_loss: 0.8453 - val_loss: 4.7074 - val_leftLayer1_loss: 0.0812 - val_midLayer1_loss: 1.3222 - val_rightLayer1_loss: 0.9040 - val_leftLayer2_loss: 0.0752 - val_midLayer2_loss: 1.3696 - val_rightLayer2_loss: 0.9551\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Emphysema: 0.7047082455591365\n",
      "\n",
      "auprc 0Emphysema: 0.06046242204470472\n",
      "\n",
      "auroc 1Emphysema: 0.34753630957309567\n",
      "\n",
      "auprc 1Emphysema: 0.01560786060615249\n",
      "\n",
      "auroc 2Emphysema: 0.7396492311894385\n",
      "\n",
      "auprc 2Emphysema: 0.09095646687034475\n",
      "\n",
      "auroc 3Emphysema: 0.5075740305230177\n",
      "\n",
      "auprc 3Emphysema: 0.02069027398676029\n",
      "\n",
      "auroc 4Emphysema: 0.4242949567876741\n",
      "\n",
      "auprc 4Emphysema: 0.018162259815989554\n",
      "\n",
      "auroc 5Emphysema: 0.666763357180673\n",
      "\n",
      "auprc 5Emphysema: 0.03497153668689589\n",
      "\n",
      "mean auroc: 0.5650876884688393\n",
      "\n",
      "mean auprc: 0.040141803335141286\n",
      "\n",
      "max auroc: 0.7396492311894385\n",
      "\n",
      "max auprc: 0.09095646687034475\n",
      "\n",
      "79.75384426116943\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607676760833729\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
