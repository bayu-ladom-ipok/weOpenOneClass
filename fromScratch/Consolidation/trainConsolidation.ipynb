{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Consolidation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "813: 3263\n",
      "126: 3263\n",
      "896: 3263\n",
      "841: 3263\n",
      "435: 3263\n",
      "289: 3263\n",
      "86: 3263\n",
      "173: 3263\n",
      "3263: 3263\n",
      "109: 3263\n",
      "79: 3263\n",
      "57: 3263\n",
      "171: 3263\n",
      "4: 3263\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3247/3263 [============================>.] - ETA: 0s - loss: 6.3375 - leftLayer1_loss: 0.1230 - midLayer1_loss: 1.3980 - rightLayer1_loss: 1.6950 - leftLayer2_loss: 0.1155 - midLayer2_loss: 1.4869 - rightLayer2_loss: 1.5191\n",
      "Epoch 00001: val_loss improved from inf to 5.92698, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 10s 3ms/step - loss: 6.3346 - leftLayer1_loss: 0.1230 - midLayer1_loss: 1.3979 - rightLayer1_loss: 1.6940 - leftLayer2_loss: 0.1154 - midLayer2_loss: 1.4871 - rightLayer2_loss: 1.5173 - val_loss: 5.9270 - val_leftLayer1_loss: 0.1189 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 1.5063 - val_leftLayer2_loss: 0.1105 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.3960\n",
      "Epoch 2/11\n",
      "3261/3263 [============================>.] - ETA: 0s - loss: 5.5631 - leftLayer1_loss: 0.1156 - midLayer1_loss: 1.3982 - rightLayer1_loss: 1.3806 - leftLayer2_loss: 0.0985 - midLayer2_loss: 1.4823 - rightLayer2_loss: 1.0880\n",
      "Epoch 00002: val_loss improved from 5.92698 to 5.48233, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.5626 - leftLayer1_loss: 0.1156 - midLayer1_loss: 1.3981 - rightLayer1_loss: 1.3805 - leftLayer2_loss: 0.0985 - midLayer2_loss: 1.4821 - rightLayer2_loss: 1.0878 - val_loss: 5.4823 - val_leftLayer1_loss: 0.1118 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 1.2646 - val_leftLayer2_loss: 0.1007 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.2099\n",
      "Epoch 3/11\n",
      "3249/3263 [============================>.] - ETA: 0s - loss: 5.2673 - leftLayer1_loss: 0.1089 - midLayer1_loss: 1.3984 - rightLayer1_loss: 1.2006 - leftLayer2_loss: 0.0855 - midLayer2_loss: 1.4828 - rightLayer2_loss: 0.9911\n",
      "Epoch 00003: val_loss improved from 5.48233 to 5.25844, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.2667 - leftLayer1_loss: 0.1089 - midLayer1_loss: 1.3983 - rightLayer1_loss: 1.2002 - leftLayer2_loss: 0.0855 - midLayer2_loss: 1.4828 - rightLayer2_loss: 0.9910 - val_loss: 5.2584 - val_leftLayer1_loss: 0.1054 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 1.1335 - val_leftLayer2_loss: 0.0928 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.1315\n",
      "Epoch 4/11\n",
      "3251/3263 [============================>.] - ETA: 0s - loss: 5.1254 - leftLayer1_loss: 0.1029 - midLayer1_loss: 1.3977 - rightLayer1_loss: 1.1029 - leftLayer2_loss: 0.0761 - midLayer2_loss: 1.4902 - rightLayer2_loss: 0.9556\n",
      "Epoch 00004: val_loss improved from 5.25844 to 5.13001, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1248 - leftLayer1_loss: 0.1028 - midLayer1_loss: 1.3976 - rightLayer1_loss: 1.1027 - leftLayer2_loss: 0.0761 - midLayer2_loss: 1.4900 - rightLayer2_loss: 0.9555 - val_loss: 5.1300 - val_leftLayer1_loss: 0.0996 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 1.0605 - val_leftLayer2_loss: 0.0865 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.0881\n",
      "Epoch 5/11\n",
      "3262/3263 [============================>.] - ETA: 0s - loss: 5.0356 - leftLayer1_loss: 0.0974 - midLayer1_loss: 1.3985 - rightLayer1_loss: 1.0456 - leftLayer2_loss: 0.0691 - midLayer2_loss: 1.4844 - rightLayer2_loss: 0.9406\n",
      "Epoch 00005: val_loss improved from 5.13001 to 5.04781, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.0356 - leftLayer1_loss: 0.0974 - midLayer1_loss: 1.3984 - rightLayer1_loss: 1.0456 - leftLayer2_loss: 0.0691 - midLayer2_loss: 1.4845 - rightLayer2_loss: 0.9406 - val_loss: 5.0478 - val_leftLayer1_loss: 0.0943 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 1.0168 - val_leftLayer2_loss: 0.0814 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "3253/3263 [============================>.] - ETA: 0s - loss: 4.9825 - leftLayer1_loss: 0.0924 - midLayer1_loss: 1.3982 - rightLayer1_loss: 1.0104 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.4877 - rightLayer2_loss: 0.9305\n",
      "Epoch 00006: val_loss improved from 5.04781 to 4.99100, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9822 - leftLayer1_loss: 0.0924 - midLayer1_loss: 1.3981 - rightLayer1_loss: 1.0102 - leftLayer2_loss: 0.0633 - midLayer2_loss: 1.4877 - rightLayer2_loss: 0.9304 - val_loss: 4.9910 - val_leftLayer1_loss: 0.0896 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 0.9887 - val_leftLayer2_loss: 0.0773 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.0401\n",
      "Epoch 7/11\n",
      "3242/3263 [============================>.] - ETA: 0s - loss: 4.9401 - leftLayer1_loss: 0.0880 - midLayer1_loss: 1.3979 - rightLayer1_loss: 0.9874 - leftLayer2_loss: 0.0593 - midLayer2_loss: 1.4836 - rightLayer2_loss: 0.9238\n",
      "Epoch 00007: val_loss improved from 4.99100 to 4.94928, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9389 - leftLayer1_loss: 0.0880 - midLayer1_loss: 1.3976 - rightLayer1_loss: 0.9870 - leftLayer2_loss: 0.0593 - midLayer2_loss: 1.4835 - rightLayer2_loss: 0.9234 - val_loss: 4.9493 - val_leftLayer1_loss: 0.0853 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 0.9695 - val_leftLayer2_loss: 0.0738 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.0253\n",
      "Epoch 8/11\n",
      "3251/3263 [============================>.] - ETA: 0s - loss: 4.9137 - leftLayer1_loss: 0.0840 - midLayer1_loss: 1.3977 - rightLayer1_loss: 0.9701 - leftLayer2_loss: 0.0560 - midLayer2_loss: 1.4866 - rightLayer2_loss: 0.9193\n",
      "Epoch 00008: val_loss improved from 4.94928 to 4.91715, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9135 - leftLayer1_loss: 0.0840 - midLayer1_loss: 1.3976 - rightLayer1_loss: 0.9701 - leftLayer2_loss: 0.0559 - midLayer2_loss: 1.4867 - rightLayer2_loss: 0.9193 - val_loss: 4.9172 - val_leftLayer1_loss: 0.0815 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 0.9557 - val_leftLayer2_loss: 0.0709 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.0137\n",
      "Epoch 9/11\n",
      "3244/3263 [============================>.] - ETA: 0s - loss: 4.8972 - leftLayer1_loss: 0.0804 - midLayer1_loss: 1.3984 - rightLayer1_loss: 0.9587 - leftLayer2_loss: 0.0534 - midLayer2_loss: 1.4891 - rightLayer2_loss: 0.9173\n",
      "Epoch 00009: val_loss improved from 4.91715 to 4.89155, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8962 - leftLayer1_loss: 0.0804 - midLayer1_loss: 1.3982 - rightLayer1_loss: 0.9583 - leftLayer2_loss: 0.0534 - midLayer2_loss: 1.4889 - rightLayer2_loss: 0.9170 - val_loss: 4.8916 - val_leftLayer1_loss: 0.0781 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 0.9454 - val_leftLayer2_loss: 0.0685 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 1.0043\n",
      "Epoch 10/11\n",
      "3244/3263 [============================>.] - ETA: 0s - loss: 4.8748 - leftLayer1_loss: 0.0771 - midLayer1_loss: 1.3975 - rightLayer1_loss: 0.9483 - leftLayer2_loss: 0.0514 - midLayer2_loss: 1.4863 - rightLayer2_loss: 0.9143\n",
      "Epoch 00010: val_loss improved from 4.89155 to 4.87068, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8737 - leftLayer1_loss: 0.0771 - midLayer1_loss: 1.3973 - rightLayer1_loss: 0.9480 - leftLayer2_loss: 0.0513 - midLayer2_loss: 1.4860 - rightLayer2_loss: 0.9139 - val_loss: 4.8707 - val_leftLayer1_loss: 0.0750 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 0.9375 - val_leftLayer2_loss: 0.0664 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 0.9966\n",
      "Epoch 11/11\n",
      "3249/3263 [============================>.] - ETA: 0s - loss: 4.8637 - leftLayer1_loss: 0.0742 - midLayer1_loss: 1.3980 - rightLayer1_loss: 0.9413 - leftLayer2_loss: 0.0497 - midLayer2_loss: 1.4882 - rightLayer2_loss: 0.9122\n",
      "Epoch 00011: val_loss improved from 4.87068 to 4.85310, saving model to ./experiments/0.009_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8635 - leftLayer1_loss: 0.0742 - midLayer1_loss: 1.3979 - rightLayer1_loss: 0.9414 - leftLayer2_loss: 0.0497 - midLayer2_loss: 1.4879 - rightLayer2_loss: 0.9123 - val_loss: 4.8531 - val_leftLayer1_loss: 0.0721 - val_midLayer1_loss: 1.3933 - val_rightLayer1_loss: 0.9312 - val_leftLayer2_loss: 0.0645 - val_midLayer2_loss: 1.4020 - val_rightLayer2_loss: 0.9900\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Consolidation: 0.5556318559679168\n",
      "\n",
      "auprc 0Consolidation: 0.056546350308689416\n",
      "\n",
      "auroc 1Consolidation: 0.6149670512616159\n",
      "\n",
      "auprc 1Consolidation: 0.06622737161057027\n",
      "\n",
      "auroc 2Consolidation: 0.45099859229023465\n",
      "\n",
      "auprc 2Consolidation: 0.03596471624265024\n",
      "\n",
      "auroc 3Consolidation: 0.27892816320636304\n",
      "\n",
      "auprc 3Consolidation: 0.02673553535962881\n",
      "\n",
      "auroc 4Consolidation: 0.5480904980466641\n",
      "\n",
      "auprc 4Consolidation: 0.046555243887000386\n",
      "\n",
      "auroc 5Consolidation: 0.3696385194777948\n",
      "\n",
      "auprc 5Consolidation: 0.03039476656391535\n",
      "\n",
      "mean auroc: 0.4697091133750982\n",
      "\n",
      "mean auprc: 0.043737330662075746\n",
      "\n",
      "max auroc: 0.6149670512616159\n",
      "\n",
      "max auprc: 0.06622737161057027\n",
      "\n",
      "121.32550597190857\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3255/3263 [============================>.] - ETA: 0s - loss: 6.1063 - leftLayer1_loss: 0.1211 - midLayer1_loss: 1.3499 - rightLayer1_loss: 1.6613 - leftLayer2_loss: 0.1222 - midLayer2_loss: 1.4332 - rightLayer2_loss: 1.4185\n",
      "Epoch 00001: val_loss improved from inf to 5.76616, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 6.1050 - leftLayer1_loss: 0.1211 - midLayer1_loss: 1.3498 - rightLayer1_loss: 1.6607 - leftLayer2_loss: 0.1222 - midLayer2_loss: 1.4333 - rightLayer2_loss: 1.4177 - val_loss: 5.7662 - val_leftLayer1_loss: 0.1171 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 1.4710 - val_leftLayer2_loss: 0.1138 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.3421\n",
      "Epoch 2/11\n",
      "3248/3263 [============================>.] - ETA: 0s - loss: 5.4141 - leftLayer1_loss: 0.1136 - midLayer1_loss: 1.3497 - rightLayer1_loss: 1.3508 - leftLayer2_loss: 0.1035 - midLayer2_loss: 1.4348 - rightLayer2_loss: 1.0618\n",
      "Epoch 00002: val_loss improved from 5.76616 to 5.35779, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.4130 - leftLayer1_loss: 0.1135 - midLayer1_loss: 1.3497 - rightLayer1_loss: 1.3502 - leftLayer2_loss: 0.1034 - midLayer2_loss: 1.4347 - rightLayer2_loss: 1.0614 - val_loss: 5.3578 - val_leftLayer1_loss: 0.1098 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 1.2393 - val_leftLayer2_loss: 0.1031 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.1834\n",
      "Epoch 3/11\n",
      "3247/3263 [============================>.] - ETA: 0s - loss: 5.1475 - leftLayer1_loss: 0.1067 - midLayer1_loss: 1.3507 - rightLayer1_loss: 1.1807 - leftLayer2_loss: 0.0890 - midLayer2_loss: 1.4375 - rightLayer2_loss: 0.9828\n",
      "Epoch 00003: val_loss improved from 5.35779 to 5.15143, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1470 - leftLayer1_loss: 0.1067 - midLayer1_loss: 1.3506 - rightLayer1_loss: 1.1803 - leftLayer2_loss: 0.0890 - midLayer2_loss: 1.4376 - rightLayer2_loss: 0.9827 - val_loss: 5.1514 - val_leftLayer1_loss: 0.1033 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 1.1177 - val_leftLayer2_loss: 0.0946 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.1136\n",
      "Epoch 4/11\n",
      "3253/3263 [============================>.] - ETA: 0s - loss: 5.0037 - leftLayer1_loss: 0.1005 - midLayer1_loss: 1.3500 - rightLayer1_loss: 1.0900 - leftLayer2_loss: 0.0784 - midLayer2_loss: 1.4329 - rightLayer2_loss: 0.9519\n",
      "Epoch 00004: val_loss improved from 5.15143 to 5.03248, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.0033 - leftLayer1_loss: 0.1005 - midLayer1_loss: 1.3500 - rightLayer1_loss: 1.0898 - leftLayer2_loss: 0.0784 - midLayer2_loss: 1.4329 - rightLayer2_loss: 0.9518 - val_loss: 5.0325 - val_leftLayer1_loss: 0.0974 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 1.0507 - val_leftLayer2_loss: 0.0879 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0743\n",
      "Epoch 5/11\n",
      "3254/3263 [============================>.] - ETA: 0s - loss: 4.9208 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3497 - rightLayer1_loss: 1.0376 - leftLayer2_loss: 0.0707 - midLayer2_loss: 1.4304 - rightLayer2_loss: 0.9374\n",
      "Epoch 00005: val_loss improved from 5.03248 to 4.95576, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9203 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.3496 - rightLayer1_loss: 1.0375 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.4303 - rightLayer2_loss: 0.9373 - val_loss: 4.9558 - val_leftLayer1_loss: 0.0922 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 1.0106 - val_leftLayer2_loss: 0.0824 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0483\n",
      "Epoch 6/11\n",
      "3248/3263 [============================>.] - ETA: 0s - loss: 4.8720 - leftLayer1_loss: 0.0901 - midLayer1_loss: 1.3494 - rightLayer1_loss: 1.0051 - leftLayer2_loss: 0.0646 - midLayer2_loss: 1.4354 - rightLayer2_loss: 0.9274\n",
      "Epoch 00006: val_loss improved from 4.95576 to 4.90240, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8720 - leftLayer1_loss: 0.0900 - midLayer1_loss: 1.3494 - rightLayer1_loss: 1.0050 - leftLayer2_loss: 0.0646 - midLayer2_loss: 1.4355 - rightLayer2_loss: 0.9275 - val_loss: 4.9024 - val_leftLayer1_loss: 0.0875 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 0.9848 - val_leftLayer2_loss: 0.0780 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0300\n",
      "Epoch 7/11\n",
      "3245/3263 [============================>.] - ETA: 0s - loss: 4.8349 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.3506 - rightLayer1_loss: 0.9833 - leftLayer2_loss: 0.0601 - midLayer2_loss: 1.4326 - rightLayer2_loss: 0.9225\n",
      "Epoch 00007: val_loss improved from 4.90240 to 4.86286, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8341 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.3504 - rightLayer1_loss: 0.9830 - leftLayer2_loss: 0.0601 - midLayer2_loss: 1.4327 - rightLayer2_loss: 0.9223 - val_loss: 4.8629 - val_leftLayer1_loss: 0.0832 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 0.9670 - val_leftLayer2_loss: 0.0744 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0160\n",
      "Epoch 8/11\n",
      "3253/3263 [============================>.] - ETA: 0s - loss: 4.8040 - leftLayer1_loss: 0.0817 - midLayer1_loss: 1.3488 - rightLayer1_loss: 0.9680 - leftLayer2_loss: 0.0567 - midLayer2_loss: 1.4300 - rightLayer2_loss: 0.9188\n",
      "Epoch 00008: val_loss improved from 4.86286 to 4.83216, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8037 - leftLayer1_loss: 0.0817 - midLayer1_loss: 1.3488 - rightLayer1_loss: 0.9679 - leftLayer2_loss: 0.0567 - midLayer2_loss: 1.4301 - rightLayer2_loss: 0.9186 - val_loss: 4.8322 - val_leftLayer1_loss: 0.0795 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 0.9542 - val_leftLayer2_loss: 0.0714 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0049\n",
      "Epoch 9/11\n",
      "3242/3263 [============================>.] - ETA: 0s - loss: 4.7895 - leftLayer1_loss: 0.0781 - midLayer1_loss: 1.3499 - rightLayer1_loss: 0.9569 - leftLayer2_loss: 0.0540 - midLayer2_loss: 1.4346 - rightLayer2_loss: 0.9159\n",
      "Epoch 00009: val_loss improved from 4.83216 to 4.80755, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.7884 - leftLayer1_loss: 0.0781 - midLayer1_loss: 1.3497 - rightLayer1_loss: 0.9566 - leftLayer2_loss: 0.0540 - midLayer2_loss: 1.4344 - rightLayer2_loss: 0.9156 - val_loss: 4.8076 - val_leftLayer1_loss: 0.0761 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 0.9446 - val_leftLayer2_loss: 0.0688 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 0.9959\n",
      "Epoch 10/11\n",
      "3248/3263 [============================>.] - ETA: 0s - loss: 4.7687 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.3502 - rightLayer1_loss: 0.9480 - leftLayer2_loss: 0.0515 - midLayer2_loss: 1.4307 - rightLayer2_loss: 0.9133\n",
      "Epoch 00010: val_loss improved from 4.80755 to 4.78741, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.7689 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.3502 - rightLayer1_loss: 0.9480 - leftLayer2_loss: 0.0515 - midLayer2_loss: 1.4307 - rightLayer2_loss: 0.9135 - val_loss: 4.7874 - val_leftLayer1_loss: 0.0730 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 0.9371 - val_leftLayer2_loss: 0.0666 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 0.9885\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3241/3263 [============================>.] - ETA: 0s - loss: 4.7579 - leftLayer1_loss: 0.0721 - midLayer1_loss: 1.3509 - rightLayer1_loss: 0.9412 - leftLayer2_loss: 0.0498 - midLayer2_loss: 1.4327 - rightLayer2_loss: 0.9111\n",
      "Epoch 00011: val_loss improved from 4.78741 to 4.77061, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.7567 - leftLayer1_loss: 0.0721 - midLayer1_loss: 1.3506 - rightLayer1_loss: 0.9409 - leftLayer2_loss: 0.0498 - midLayer2_loss: 1.4324 - rightLayer2_loss: 0.9109 - val_loss: 4.7706 - val_leftLayer1_loss: 0.0703 - val_midLayer1_loss: 1.3464 - val_rightLayer1_loss: 0.9311 - val_leftLayer2_loss: 0.0647 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 0.9823\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Consolidation: 0.6339749769030891\n",
      "\n",
      "auprc 0Consolidation: 0.055041709609329074\n",
      "\n",
      "auroc 1Consolidation: 0.4993421248535217\n",
      "\n",
      "auprc 1Consolidation: 0.0395799723976445\n",
      "\n",
      "auroc 2Consolidation: 0.5351717248268972\n",
      "\n",
      "auprc 2Consolidation: 0.043443787591666186\n",
      "\n",
      "auroc 3Consolidation: 0.4260137874982995\n",
      "\n",
      "auprc 3Consolidation: 0.033870729578634455\n",
      "\n",
      "auroc 4Consolidation: 0.4508266913293214\n",
      "\n",
      "auprc 4Consolidation: 0.0366910763465656\n",
      "\n",
      "auroc 5Consolidation: 0.4482993628230332\n",
      "\n",
      "auprc 5Consolidation: 0.03585022907392379\n",
      "\n",
      "mean auroc: 0.4989381113723604\n",
      "\n",
      "mean auprc: 0.040746250766293936\n",
      "\n",
      "max auroc: 0.6339749769030891\n",
      "\n",
      "max auprc: 0.055041709609329074\n",
      "\n",
      "119.77635836601257\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3262/3263 [============================>.] - ETA: 0s - loss: 6.1774 - leftLayer1_loss: 0.1218 - midLayer1_loss: 1.3586 - rightLayer1_loss: 1.6888 - leftLayer2_loss: 0.1190 - midLayer2_loss: 1.4196 - rightLayer2_loss: 1.4697\n",
      "Epoch 00001: val_loss improved from inf to 5.87683, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 6.1774 - leftLayer1_loss: 0.1218 - midLayer1_loss: 1.3586 - rightLayer1_loss: 1.6888 - leftLayer2_loss: 0.1190 - midLayer2_loss: 1.4196 - rightLayer2_loss: 1.4696 - val_loss: 5.8768 - val_leftLayer1_loss: 0.1183 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 1.5152 - val_leftLayer2_loss: 0.1137 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.3924\n",
      "Epoch 2/11\n",
      "3259/3263 [============================>.] - ETA: 0s - loss: 5.4810 - leftLayer1_loss: 0.1151 - midLayer1_loss: 1.3585 - rightLayer1_loss: 1.3956 - leftLayer2_loss: 0.1023 - midLayer2_loss: 1.4194 - rightLayer2_loss: 1.0902\n",
      "Epoch 00002: val_loss improved from 5.87683 to 5.45904, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.4806 - leftLayer1_loss: 0.1151 - midLayer1_loss: 1.3584 - rightLayer1_loss: 1.3953 - leftLayer2_loss: 0.1023 - midLayer2_loss: 1.4195 - rightLayer2_loss: 1.0900 - val_loss: 5.4590 - val_leftLayer1_loss: 0.1119 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 1.2846 - val_leftLayer2_loss: 0.1043 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.2211\n",
      "Epoch 3/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 5.1941 - leftLayer1_loss: 0.1090 - midLayer1_loss: 1.3588 - rightLayer1_loss: 1.2205 - leftLayer2_loss: 0.0895 - midLayer2_loss: 1.4203 - rightLayer2_loss: 0.9961\n",
      "Epoch 00003: val_loss improved from 5.45904 to 5.23806, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1929 - leftLayer1_loss: 0.1089 - midLayer1_loss: 1.3586 - rightLayer1_loss: 1.2200 - leftLayer2_loss: 0.0895 - midLayer2_loss: 1.4200 - rightLayer2_loss: 0.9959 - val_loss: 5.2381 - val_leftLayer1_loss: 0.1060 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 1.1539 - val_leftLayer2_loss: 0.0967 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.1443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 5.0413 - leftLayer1_loss: 0.1034 - midLayer1_loss: 1.3591 - rightLayer1_loss: 1.1205 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.4194 - rightLayer2_loss: 0.9595\n",
      "Epoch 00004: val_loss improved from 5.23806 to 5.10745, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.0406 - leftLayer1_loss: 0.1034 - midLayer1_loss: 1.3590 - rightLayer1_loss: 1.1201 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.4195 - rightLayer2_loss: 0.9592 - val_loss: 5.1075 - val_leftLayer1_loss: 0.1006 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 1.0785 - val_leftLayer2_loss: 0.0905 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.1007\n",
      "Epoch 5/11\n",
      "3261/3263 [============================>.] - ETA: 0s - loss: 4.9484 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.3577 - rightLayer1_loss: 1.0608 - leftLayer2_loss: 0.0719 - midLayer2_loss: 1.4176 - rightLayer2_loss: 0.9421\n",
      "Epoch 00005: val_loss improved from 5.10745 to 5.02270, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9481 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.3577 - rightLayer1_loss: 1.0607 - leftLayer2_loss: 0.0719 - midLayer2_loss: 1.4176 - rightLayer2_loss: 0.9419 - val_loss: 5.0227 - val_leftLayer1_loss: 0.0957 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 1.0322 - val_leftLayer2_loss: 0.0854 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.0722\n",
      "Epoch 6/11\n",
      "3254/3263 [============================>.] - ETA: 0s - loss: 4.8912 - leftLayer1_loss: 0.0937 - midLayer1_loss: 1.3576 - rightLayer1_loss: 1.0231 - leftLayer2_loss: 0.0661 - midLayer2_loss: 1.4196 - rightLayer2_loss: 0.9311\n",
      "Epoch 00006: val_loss improved from 5.02270 to 4.96347, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8908 - leftLayer1_loss: 0.0937 - midLayer1_loss: 1.3575 - rightLayer1_loss: 1.0229 - leftLayer2_loss: 0.0661 - midLayer2_loss: 1.4195 - rightLayer2_loss: 0.9310 - val_loss: 4.9635 - val_leftLayer1_loss: 0.0912 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 1.0020 - val_leftLayer2_loss: 0.0812 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.0519\n",
      "Epoch 7/11\n",
      "3241/3263 [============================>.] - ETA: 0s - loss: 4.8525 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.3583 - rightLayer1_loss: 0.9984 - leftLayer2_loss: 0.0620 - midLayer2_loss: 1.4191 - rightLayer2_loss: 0.9253\n",
      "Epoch 00007: val_loss improved from 4.96347 to 4.91962, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8514 - leftLayer1_loss: 0.0894 - midLayer1_loss: 1.3580 - rightLayer1_loss: 0.9979 - leftLayer2_loss: 0.0619 - midLayer2_loss: 1.4191 - rightLayer2_loss: 0.9250 - val_loss: 4.9196 - val_leftLayer1_loss: 0.0872 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 0.9810 - val_leftLayer2_loss: 0.0777 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.0365\n",
      "Epoch 8/11\n",
      "3249/3263 [============================>.] - ETA: 0s - loss: 4.8217 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.3588 - rightLayer1_loss: 0.9800 - leftLayer2_loss: 0.0584 - midLayer2_loss: 1.4186 - rightLayer2_loss: 0.9203\n",
      "Epoch 00008: val_loss improved from 4.91962 to 4.88564, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8221 - leftLayer1_loss: 0.0856 - midLayer1_loss: 1.3588 - rightLayer1_loss: 0.9799 - leftLayer2_loss: 0.0584 - midLayer2_loss: 1.4190 - rightLayer2_loss: 0.9205 - val_loss: 4.8856 - val_leftLayer1_loss: 0.0835 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 0.9659 - val_leftLayer2_loss: 0.0747 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.0243\n",
      "Epoch 9/11\n",
      "3253/3263 [============================>.] - ETA: 0s - loss: 4.8007 - leftLayer1_loss: 0.0822 - midLayer1_loss: 1.3580 - rightLayer1_loss: 0.9665 - leftLayer2_loss: 0.0556 - midLayer2_loss: 1.4209 - rightLayer2_loss: 0.9175\n",
      "Epoch 00009: val_loss improved from 4.88564 to 4.85846, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 4.8004 - leftLayer1_loss: 0.0822 - midLayer1_loss: 1.3579 - rightLayer1_loss: 0.9664 - leftLayer2_loss: 0.0556 - midLayer2_loss: 1.4209 - rightLayer2_loss: 0.9174 - val_loss: 4.8585 - val_leftLayer1_loss: 0.0802 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 0.9545 - val_leftLayer2_loss: 0.0722 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.0144\n",
      "Epoch 10/11\n",
      "3262/3263 [============================>.] - ETA: 0s - loss: 4.7814 - leftLayer1_loss: 0.0790 - midLayer1_loss: 1.3572 - rightLayer1_loss: 0.9562 - leftLayer2_loss: 0.0533 - midLayer2_loss: 1.4218 - rightLayer2_loss: 0.9138\n",
      "Epoch 00010: val_loss improved from 4.85846 to 4.83622, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 4.7814 - leftLayer1_loss: 0.0790 - midLayer1_loss: 1.3572 - rightLayer1_loss: 0.9562 - leftLayer2_loss: 0.0533 - midLayer2_loss: 1.4219 - rightLayer2_loss: 0.9138 - val_loss: 4.8362 - val_leftLayer1_loss: 0.0772 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 0.9457 - val_leftLayer2_loss: 0.0700 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 1.0062\n",
      "Epoch 11/11\n",
      "3253/3263 [============================>.] - ETA: 0s - loss: 4.7662 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3583 - rightLayer1_loss: 0.9482 - leftLayer2_loss: 0.0512 - midLayer2_loss: 1.4198 - rightLayer2_loss: 0.9125\n",
      "Epoch 00011: val_loss improved from 4.83622 to 4.81749, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.7659 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3582 - rightLayer1_loss: 0.9481 - leftLayer2_loss: 0.0512 - midLayer2_loss: 1.4199 - rightLayer2_loss: 0.9124 - val_loss: 4.8175 - val_leftLayer1_loss: 0.0744 - val_midLayer1_loss: 1.3531 - val_rightLayer1_loss: 0.9387 - val_leftLayer2_loss: 0.0680 - val_midLayer2_loss: 1.3841 - val_rightLayer2_loss: 0.9992\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Consolidation: 0.47871882646868036\n",
      "\n",
      "auprc 0Consolidation: 0.038862968929985454\n",
      "\n",
      "auroc 1Consolidation: 0.5249767279282183\n",
      "\n",
      "auprc 1Consolidation: 0.04241305968318407\n",
      "\n",
      "auroc 2Consolidation: 0.5203709693773984\n",
      "\n",
      "auprc 2Consolidation: 0.043598264350870386\n",
      "\n",
      "auroc 3Consolidation: 0.2891864126522221\n",
      "\n",
      "auprc 3Consolidation: 0.027164062615250593\n",
      "\n",
      "auroc 4Consolidation: 0.353138605987817\n",
      "\n",
      "auprc 4Consolidation: 0.029883134804121508\n",
      "\n",
      "auroc 5Consolidation: 0.3470640746356702\n",
      "\n",
      "auprc 5Consolidation: 0.029339722832761102\n",
      "\n",
      "mean auroc: 0.41890926950833435\n",
      "\n",
      "mean auprc: 0.035210202202695516\n",
      "\n",
      "max auroc: 0.5249767279282183\n",
      "\n",
      "max auprc: 0.043598264350870386\n",
      "\n",
      "120.02750396728516\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 6.2772 - leftLayer1_loss: 0.1219 - midLayer1_loss: 1.4234 - rightLayer1_loss: 1.7123 - leftLayer2_loss: 0.1182 - midLayer2_loss: 1.4635 - rightLayer2_loss: 1.4379\n",
      "Epoch 00001: val_loss improved from inf to 5.93537, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 6.2747 - leftLayer1_loss: 0.1219 - midLayer1_loss: 1.4233 - rightLayer1_loss: 1.7113 - leftLayer2_loss: 0.1182 - midLayer2_loss: 1.4636 - rightLayer2_loss: 1.4364 - val_loss: 5.9354 - val_leftLayer1_loss: 0.1183 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 1.5421 - val_leftLayer2_loss: 0.1146 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.3518\n",
      "Epoch 2/11\n",
      "3245/3263 [============================>.] - ETA: 0s - loss: 5.5916 - leftLayer1_loss: 0.1154 - midLayer1_loss: 1.4239 - rightLayer1_loss: 1.4178 - leftLayer2_loss: 0.1003 - midLayer2_loss: 1.4642 - rightLayer2_loss: 1.0700\n",
      "Epoch 00002: val_loss improved from 5.93537 to 5.52060, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.5899 - leftLayer1_loss: 0.1154 - midLayer1_loss: 1.4237 - rightLayer1_loss: 1.4171 - leftLayer2_loss: 0.1002 - midLayer2_loss: 1.4642 - rightLayer2_loss: 1.0693 - val_loss: 5.5206 - val_leftLayer1_loss: 0.1121 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 1.3076 - val_leftLayer2_loss: 0.1039 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.1885\n",
      "Epoch 3/11\n",
      "3255/3263 [============================>.] - ETA: 0s - loss: 5.3058 - leftLayer1_loss: 0.1094 - midLayer1_loss: 1.4239 - rightLayer1_loss: 1.2377 - leftLayer2_loss: 0.0868 - midLayer2_loss: 1.4606 - rightLayer2_loss: 0.9873\n",
      "Epoch 00003: val_loss improved from 5.52060 to 5.29941, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.3050 - leftLayer1_loss: 0.1094 - midLayer1_loss: 1.4238 - rightLayer1_loss: 1.2375 - leftLayer2_loss: 0.0868 - midLayer2_loss: 1.4603 - rightLayer2_loss: 0.9872 - val_loss: 5.2994 - val_leftLayer1_loss: 0.1063 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 1.1714 - val_leftLayer2_loss: 0.0955 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.1176\n",
      "Epoch 4/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 5.1558 - leftLayer1_loss: 0.1039 - midLayer1_loss: 1.4238 - rightLayer1_loss: 1.1332 - leftLayer2_loss: 0.0767 - midLayer2_loss: 1.4604 - rightLayer2_loss: 0.9577\n",
      "Epoch 00004: val_loss improved from 5.29941 to 5.16775, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.1552 - leftLayer1_loss: 0.1039 - midLayer1_loss: 1.4237 - rightLayer1_loss: 1.1328 - leftLayer2_loss: 0.0767 - midLayer2_loss: 1.4605 - rightLayer2_loss: 0.9576 - val_loss: 5.1677 - val_leftLayer1_loss: 0.1011 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 1.0918 - val_leftLayer2_loss: 0.0888 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.0776\n",
      "Epoch 5/11\n",
      "3255/3263 [============================>.] - ETA: 0s - loss: 5.0672 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.4236 - rightLayer1_loss: 1.0712 - leftLayer2_loss: 0.0694 - midLayer2_loss: 1.4621 - rightLayer2_loss: 0.9420\n",
      "Epoch 00005: val_loss improved from 5.16775 to 5.08233, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.0667 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.4235 - rightLayer1_loss: 1.0710 - leftLayer2_loss: 0.0693 - midLayer2_loss: 1.4621 - rightLayer2_loss: 0.9418 - val_loss: 5.0823 - val_leftLayer1_loss: 0.0962 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 1.0427 - val_leftLayer2_loss: 0.0834 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.0515\n",
      "Epoch 6/11\n",
      "3258/3263 [============================>.] - ETA: 0s - loss: 5.0035 - leftLayer1_loss: 0.0944 - midLayer1_loss: 1.4240 - rightLayer1_loss: 1.0318 - leftLayer2_loss: 0.0635 - midLayer2_loss: 1.4581 - rightLayer2_loss: 0.9317\n",
      "Epoch 00006: val_loss improved from 5.08233 to 5.02295, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.0030 - leftLayer1_loss: 0.0944 - midLayer1_loss: 1.4239 - rightLayer1_loss: 1.0316 - leftLayer2_loss: 0.0635 - midLayer2_loss: 1.4581 - rightLayer2_loss: 0.9315 - val_loss: 5.0229 - val_leftLayer1_loss: 0.0919 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 1.0105 - val_leftLayer2_loss: 0.0790 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.0330\n",
      "Epoch 7/11\n",
      "3241/3263 [============================>.] - ETA: 0s - loss: 4.9655 - leftLayer1_loss: 0.0902 - midLayer1_loss: 1.4239 - rightLayer1_loss: 1.0052 - leftLayer2_loss: 0.0594 - midLayer2_loss: 1.4605 - rightLayer2_loss: 0.9264\n",
      "Epoch 00007: val_loss improved from 5.02295 to 4.97909, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.9642 - leftLayer1_loss: 0.0902 - midLayer1_loss: 1.4236 - rightLayer1_loss: 1.0048 - leftLayer2_loss: 0.0594 - midLayer2_loss: 1.4602 - rightLayer2_loss: 0.9260 - val_loss: 4.9791 - val_leftLayer1_loss: 0.0879 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 0.9882 - val_leftLayer2_loss: 0.0753 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.0191\n",
      "Epoch 8/11\n",
      "3256/3263 [============================>.] - ETA: 0s - loss: 4.9334 - leftLayer1_loss: 0.0864 - midLayer1_loss: 1.4234 - rightLayer1_loss: 0.9863 - leftLayer2_loss: 0.0561 - midLayer2_loss: 1.4589 - rightLayer2_loss: 0.9223\n",
      "Epoch 00008: val_loss improved from 4.97909 to 4.94530, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.9327 - leftLayer1_loss: 0.0864 - midLayer1_loss: 1.4233 - rightLayer1_loss: 0.9861 - leftLayer2_loss: 0.0560 - midLayer2_loss: 1.4588 - rightLayer2_loss: 0.9220 - val_loss: 4.9453 - val_leftLayer1_loss: 0.0842 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 0.9721 - val_leftLayer2_loss: 0.0723 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 1.0081\n",
      "Epoch 9/11\n",
      "3258/3263 [============================>.] - ETA: 0s - loss: 4.9131 - leftLayer1_loss: 0.0830 - midLayer1_loss: 1.4241 - rightLayer1_loss: 0.9723 - leftLayer2_loss: 0.0533 - midLayer2_loss: 1.4624 - rightLayer2_loss: 0.9181\n",
      "Epoch 00009: val_loss improved from 4.94530 to 4.91852, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.9124 - leftLayer1_loss: 0.0829 - midLayer1_loss: 1.4240 - rightLayer1_loss: 0.9721 - leftLayer2_loss: 0.0532 - midLayer2_loss: 1.4622 - rightLayer2_loss: 0.9179 - val_loss: 4.9185 - val_leftLayer1_loss: 0.0809 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 0.9601 - val_leftLayer2_loss: 0.0697 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 0.9993\n",
      "Epoch 10/11\n",
      "3247/3263 [============================>.] - ETA: 0s - loss: 4.8916 - leftLayer1_loss: 0.0799 - midLayer1_loss: 1.4238 - rightLayer1_loss: 0.9615 - leftLayer2_loss: 0.0514 - midLayer2_loss: 1.4587 - rightLayer2_loss: 0.9163\n",
      "Epoch 00010: val_loss improved from 4.91852 to 4.89644, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.8917 - leftLayer1_loss: 0.0799 - midLayer1_loss: 1.4238 - rightLayer1_loss: 0.9614 - leftLayer2_loss: 0.0514 - midLayer2_loss: 1.4589 - rightLayer2_loss: 0.9164 - val_loss: 4.8964 - val_leftLayer1_loss: 0.0779 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 0.9507 - val_leftLayer2_loss: 0.0675 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 0.9918\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261/3263 [============================>.] - ETA: 0s - loss: 4.8775 - leftLayer1_loss: 0.0770 - midLayer1_loss: 1.4237 - rightLayer1_loss: 0.9527 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.4604 - rightLayer2_loss: 0.9141\n",
      "Epoch 00011: val_loss improved from 4.89644 to 4.87799, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.8770 - leftLayer1_loss: 0.0770 - midLayer1_loss: 1.4237 - rightLayer1_loss: 0.9526 - leftLayer2_loss: 0.0496 - midLayer2_loss: 1.4603 - rightLayer2_loss: 0.9140 - val_loss: 4.8780 - val_leftLayer1_loss: 0.0751 - val_midLayer1_loss: 1.4213 - val_rightLayer1_loss: 0.9432 - val_leftLayer2_loss: 0.0656 - val_midLayer2_loss: 1.3873 - val_rightLayer2_loss: 0.9855\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Consolidation: 0.718296850237236\n",
      "\n",
      "auprc 0Consolidation: 0.09577556858142627\n",
      "\n",
      "auroc 1Consolidation: 0.46003830574257226\n",
      "\n",
      "auprc 1Consolidation: 0.03780286927934735\n",
      "\n",
      "auroc 2Consolidation: 0.6355550498595501\n",
      "\n",
      "auprc 2Consolidation: 0.07385868954836547\n",
      "\n",
      "auroc 3Consolidation: 0.4178723331996272\n",
      "\n",
      "auprc 3Consolidation: 0.03314810996911039\n",
      "\n",
      "auroc 4Consolidation: 0.5354802269618166\n",
      "\n",
      "auprc 4Consolidation: 0.043573470729683046\n",
      "\n",
      "auroc 5Consolidation: 0.4095485412697569\n",
      "\n",
      "auprc 5Consolidation: 0.03252563955530309\n",
      "\n",
      "mean auroc: 0.5294652178784266\n",
      "\n",
      "mean auprc: 0.052780724610539266\n",
      "\n",
      "max auroc: 0.718296850237236\n",
      "\n",
      "max auprc: 0.09577556858142627\n",
      "\n",
      "114.98639011383057\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3254/3263 [============================>.] - ETA: 0s - loss: 6.3646 - leftLayer1_loss: 0.1196 - midLayer1_loss: 1.3555 - rightLayer1_loss: 1.6851 - leftLayer2_loss: 0.1173 - midLayer2_loss: 1.6075 - rightLayer2_loss: 1.4796\n",
      "Epoch 00001: val_loss improved from inf to 5.90902, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 6.3627 - leftLayer1_loss: 0.1196 - midLayer1_loss: 1.3554 - rightLayer1_loss: 1.6846 - leftLayer2_loss: 0.1173 - midLayer2_loss: 1.6071 - rightLayer2_loss: 1.4787 - val_loss: 5.9090 - val_leftLayer1_loss: 0.1158 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 1.4991 - val_leftLayer2_loss: 0.1138 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.3649\n",
      "Epoch 2/11\n",
      "3252/3263 [============================>.] - ETA: 0s - loss: 5.6263 - leftLayer1_loss: 0.1126 - midLayer1_loss: 1.3555 - rightLayer1_loss: 1.3757 - leftLayer2_loss: 0.0994 - midLayer2_loss: 1.6064 - rightLayer2_loss: 1.0767\n",
      "Epoch 00002: val_loss improved from 5.90902 to 5.47665, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.6254 - leftLayer1_loss: 0.1126 - midLayer1_loss: 1.3553 - rightLayer1_loss: 1.3752 - leftLayer2_loss: 0.0993 - midLayer2_loss: 1.6066 - rightLayer2_loss: 1.0763 - val_loss: 5.4766 - val_leftLayer1_loss: 0.1091 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 1.2621 - val_leftLayer2_loss: 0.1030 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.1872\n",
      "Epoch 3/11\n",
      "3253/3263 [============================>.] - ETA: 0s - loss: 5.3526 - leftLayer1_loss: 0.1062 - midLayer1_loss: 1.3562 - rightLayer1_loss: 1.1989 - leftLayer2_loss: 0.0859 - midLayer2_loss: 1.6165 - rightLayer2_loss: 0.9890\n",
      "Epoch 00003: val_loss improved from 5.47665 to 5.25888, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.3516 - leftLayer1_loss: 0.1062 - midLayer1_loss: 1.3560 - rightLayer1_loss: 1.1986 - leftLayer2_loss: 0.0858 - midLayer2_loss: 1.6161 - rightLayer2_loss: 0.9888 - val_loss: 5.2589 - val_leftLayer1_loss: 0.1030 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 1.1338 - val_leftLayer2_loss: 0.0944 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.1124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3254/3263 [============================>.] - ETA: 0s - loss: 5.2018 - leftLayer1_loss: 0.1005 - midLayer1_loss: 1.3557 - rightLayer1_loss: 1.1030 - leftLayer2_loss: 0.0758 - midLayer2_loss: 1.6092 - rightLayer2_loss: 0.9577\n",
      "Epoch 00004: val_loss improved from 5.25888 to 5.13296, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.2012 - leftLayer1_loss: 0.1005 - midLayer1_loss: 1.3556 - rightLayer1_loss: 1.1027 - leftLayer2_loss: 0.0758 - midLayer2_loss: 1.6090 - rightLayer2_loss: 0.9577 - val_loss: 5.1330 - val_leftLayer1_loss: 0.0974 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 1.0619 - val_leftLayer2_loss: 0.0876 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.0707\n",
      "Epoch 5/11\n",
      "3250/3263 [============================>.] - ETA: 0s - loss: 5.1170 - leftLayer1_loss: 0.0953 - midLayer1_loss: 1.3549 - rightLayer1_loss: 1.0471 - leftLayer2_loss: 0.0684 - midLayer2_loss: 1.6107 - rightLayer2_loss: 0.9407\n",
      "Epoch 00005: val_loss improved from 5.13296 to 5.05257, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.1163 - leftLayer1_loss: 0.0952 - midLayer1_loss: 1.3547 - rightLayer1_loss: 1.0469 - leftLayer2_loss: 0.0684 - midLayer2_loss: 1.6105 - rightLayer2_loss: 0.9406 - val_loss: 5.0526 - val_leftLayer1_loss: 0.0924 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 1.0186 - val_leftLayer2_loss: 0.0821 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.0441\n",
      "Epoch 6/11\n",
      "3251/3263 [============================>.] - ETA: 0s - loss: 5.0606 - leftLayer1_loss: 0.0906 - midLayer1_loss: 1.3561 - rightLayer1_loss: 1.0120 - leftLayer2_loss: 0.0629 - midLayer2_loss: 1.6090 - rightLayer2_loss: 0.9300\n",
      "Epoch 00006: val_loss improved from 5.05257 to 4.99694, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.0601 - leftLayer1_loss: 0.0906 - midLayer1_loss: 1.3560 - rightLayer1_loss: 1.0119 - leftLayer2_loss: 0.0629 - midLayer2_loss: 1.6088 - rightLayer2_loss: 0.9300 - val_loss: 4.9969 - val_leftLayer1_loss: 0.0880 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 0.9905 - val_leftLayer2_loss: 0.0777 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.0254\n",
      "Epoch 7/11\n",
      "3252/3263 [============================>.] - ETA: 0s - loss: 5.0217 - leftLayer1_loss: 0.0863 - midLayer1_loss: 1.3557 - rightLayer1_loss: 0.9892 - leftLayer2_loss: 0.0589 - midLayer2_loss: 1.6069 - rightLayer2_loss: 0.9247\n",
      "Epoch 00007: val_loss improved from 4.99694 to 4.95580, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 5.0213 - leftLayer1_loss: 0.0863 - midLayer1_loss: 1.3556 - rightLayer1_loss: 0.9891 - leftLayer2_loss: 0.0589 - midLayer2_loss: 1.6069 - rightLayer2_loss: 0.9246 - val_loss: 4.9558 - val_leftLayer1_loss: 0.0839 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 0.9713 - val_leftLayer2_loss: 0.0741 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.0112\n",
      "Epoch 8/11\n",
      "3258/3263 [============================>.] - ETA: 0s - loss: 4.9998 - leftLayer1_loss: 0.0825 - midLayer1_loss: 1.3560 - rightLayer1_loss: 0.9725 - leftLayer2_loss: 0.0554 - midLayer2_loss: 1.6135 - rightLayer2_loss: 0.9198\n",
      "Epoch 00008: val_loss improved from 4.95580 to 4.92432, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.9994 - leftLayer1_loss: 0.0825 - midLayer1_loss: 1.3560 - rightLayer1_loss: 0.9723 - leftLayer2_loss: 0.0554 - midLayer2_loss: 1.6135 - rightLayer2_loss: 0.9196 - val_loss: 4.9243 - val_leftLayer1_loss: 0.0803 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 0.9574 - val_leftLayer2_loss: 0.0710 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 1.0003\n",
      "Epoch 9/11\n",
      "3249/3263 [============================>.] - ETA: 0s - loss: 4.9719 - leftLayer1_loss: 0.0792 - midLayer1_loss: 1.3558 - rightLayer1_loss: 0.9600 - leftLayer2_loss: 0.0529 - midLayer2_loss: 1.6073 - rightLayer2_loss: 0.9168\n",
      "Epoch 00009: val_loss improved from 4.92432 to 4.89907, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.9720 - leftLayer1_loss: 0.0792 - midLayer1_loss: 1.3557 - rightLayer1_loss: 0.9600 - leftLayer2_loss: 0.0529 - midLayer2_loss: 1.6075 - rightLayer2_loss: 0.9169 - val_loss: 4.8991 - val_leftLayer1_loss: 0.0770 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 0.9469 - val_leftLayer2_loss: 0.0685 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 0.9914\n",
      "Epoch 10/11\n",
      "3244/3263 [============================>.] - ETA: 0s - loss: 4.9546 - leftLayer1_loss: 0.0760 - midLayer1_loss: 1.3559 - rightLayer1_loss: 0.9507 - leftLayer2_loss: 0.0508 - midLayer2_loss: 1.6079 - rightLayer2_loss: 0.9133\n",
      "Epoch 00010: val_loss improved from 4.89907 to 4.87840, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 2ms/step - loss: 4.9540 - leftLayer1_loss: 0.0760 - midLayer1_loss: 1.3556 - rightLayer1_loss: 0.9504 - leftLayer2_loss: 0.0508 - midLayer2_loss: 1.6081 - rightLayer2_loss: 0.9130 - val_loss: 4.8784 - val_leftLayer1_loss: 0.0740 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 0.9388 - val_leftLayer2_loss: 0.0663 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 0.9840\n",
      "Epoch 11/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 4.9416 - leftLayer1_loss: 0.0732 - midLayer1_loss: 1.3556 - rightLayer1_loss: 0.9430 - leftLayer2_loss: 0.0492 - midLayer2_loss: 1.6074 - rightLayer2_loss: 0.9132\n",
      "Epoch 00011: val_loss improved from 4.87840 to 4.86111, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9408 - leftLayer1_loss: 0.0732 - midLayer1_loss: 1.3553 - rightLayer1_loss: 0.9429 - leftLayer2_loss: 0.0491 - midLayer2_loss: 1.6071 - rightLayer2_loss: 0.9131 - val_loss: 4.8611 - val_leftLayer1_loss: 0.0713 - val_midLayer1_loss: 1.3438 - val_rightLayer1_loss: 0.9324 - val_leftLayer2_loss: 0.0644 - val_midLayer2_loss: 1.4716 - val_rightLayer2_loss: 0.9777\n",
      "22433/22433 [==============================] - 29s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Consolidation: 0.4930178919074303\n",
      "\n",
      "auprc 0Consolidation: 0.03873866366060199\n",
      "\n",
      "auroc 1Consolidation: 0.5567393350853316\n",
      "\n",
      "auprc 1Consolidation: 0.0449836525970006\n",
      "\n",
      "auroc 2Consolidation: 0.6119239468888796\n",
      "\n",
      "auprc 2Consolidation: 0.05990125216315268\n",
      "\n",
      "auroc 3Consolidation: 0.3668656737768368\n",
      "\n",
      "auprc 3Consolidation: 0.030544431517063774\n",
      "\n",
      "auroc 4Consolidation: 0.3405593043231851\n",
      "\n",
      "auprc 4Consolidation: 0.029291629992653157\n",
      "\n",
      "auroc 5Consolidation: 0.4501311322614654\n",
      "\n",
      "auprc 5Consolidation: 0.035468960322924244\n",
      "\n",
      "mean auroc: 0.46987288070718813\n",
      "\n",
      "mean auprc: 0.03982143170889941\n",
      "\n",
      "max auroc: 0.6119239468888796\n",
      "\n",
      "max auprc: 0.05990125216315268\n",
      "\n",
      "117.331960439682\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3248/3263 [============================>.] - ETA: 0s - loss: 6.5622 - leftLayer1_loss: 0.1256 - midLayer1_loss: 1.4954 - rightLayer1_loss: 1.6633 - leftLayer2_loss: 0.1160 - midLayer2_loss: 1.6737 - rightLayer2_loss: 1.4881\n",
      "Epoch 00001: val_loss improved from inf to 6.11253, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 6.5596 - leftLayer1_loss: 0.1256 - midLayer1_loss: 1.4953 - rightLayer1_loss: 1.6624 - leftLayer2_loss: 0.1160 - midLayer2_loss: 1.6737 - rightLayer2_loss: 1.4866 - val_loss: 6.1125 - val_leftLayer1_loss: 0.1214 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 1.4833 - val_leftLayer2_loss: 0.1137 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.4032\n",
      "Epoch 2/11\n",
      "3247/3263 [============================>.] - ETA: 0s - loss: 5.8430 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4961 - rightLayer1_loss: 1.3613 - leftLayer2_loss: 0.0999 - midLayer2_loss: 1.6737 - rightLayer2_loss: 1.0940\n",
      "Epoch 00002: val_loss improved from 6.11253 to 5.69196, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.8418 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4960 - rightLayer1_loss: 1.3607 - leftLayer2_loss: 0.0999 - midLayer2_loss: 1.6736 - rightLayer2_loss: 1.0936 - val_loss: 5.6920 - val_leftLayer1_loss: 0.1141 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 1.2539 - val_leftLayer2_loss: 0.1045 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.2286\n",
      "Epoch 3/11\n",
      "3256/3263 [============================>.] - ETA: 0s - loss: 5.5567 - leftLayer1_loss: 0.1110 - midLayer1_loss: 1.4962 - rightLayer1_loss: 1.1910 - leftLayer2_loss: 0.0872 - midLayer2_loss: 1.6737 - rightLayer2_loss: 0.9976\n",
      "Epoch 00003: val_loss improved from 5.69196 to 5.47580, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.5560 - leftLayer1_loss: 0.1110 - midLayer1_loss: 1.4960 - rightLayer1_loss: 1.1908 - leftLayer2_loss: 0.0872 - midLayer2_loss: 1.6736 - rightLayer2_loss: 0.9973 - val_loss: 5.4758 - val_leftLayer1_loss: 0.1075 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 1.1298 - val_leftLayer2_loss: 0.0970 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.1506\n",
      "Epoch 4/11\n",
      "3248/3263 [============================>.] - ETA: 0s - loss: 5.4110 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4955 - rightLayer1_loss: 1.0982 - leftLayer2_loss: 0.0779 - midLayer2_loss: 1.6724 - rightLayer2_loss: 0.9624\n",
      "Epoch 00004: val_loss improved from 5.47580 to 5.34956, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.4108 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4954 - rightLayer1_loss: 1.0980 - leftLayer2_loss: 0.0778 - midLayer2_loss: 1.6725 - rightLayer2_loss: 0.9623 - val_loss: 5.3496 - val_leftLayer1_loss: 0.1014 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 1.0601 - val_leftLayer2_loss: 0.0910 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.1062\n",
      "Epoch 5/11\n",
      "3258/3263 [============================>.] - ETA: 0s - loss: 5.3270 - leftLayer1_loss: 0.0991 - midLayer1_loss: 1.4957 - rightLayer1_loss: 1.0442 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.6746 - rightLayer2_loss: 0.9429\n",
      "Epoch 00005: val_loss improved from 5.34956 to 5.26809, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.3264 - leftLayer1_loss: 0.0990 - midLayer1_loss: 1.4955 - rightLayer1_loss: 1.0440 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.6746 - rightLayer2_loss: 0.9426 - val_loss: 5.2681 - val_leftLayer1_loss: 0.0960 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 1.0179 - val_leftLayer2_loss: 0.0859 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0773\n",
      "Epoch 6/11\n",
      "3249/3263 [============================>.] - ETA: 0s - loss: 5.2762 - leftLayer1_loss: 0.0939 - midLayer1_loss: 1.4954 - rightLayer1_loss: 1.0098 - leftLayer2_loss: 0.0651 - midLayer2_loss: 1.6776 - rightLayer2_loss: 0.9343\n",
      "Epoch 00006: val_loss improved from 5.26809 to 5.21101, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.2760 - leftLayer1_loss: 0.0938 - midLayer1_loss: 1.4954 - rightLayer1_loss: 1.0098 - leftLayer2_loss: 0.0651 - midLayer2_loss: 1.6775 - rightLayer2_loss: 0.9343 - val_loss: 5.2110 - val_leftLayer1_loss: 0.0911 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 0.9905 - val_leftLayer2_loss: 0.0818 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0567\n",
      "Epoch 7/11\n",
      "3252/3263 [============================>.] - ETA: 0s - loss: 5.2385 - leftLayer1_loss: 0.0893 - midLayer1_loss: 1.4957 - rightLayer1_loss: 0.9870 - leftLayer2_loss: 0.0610 - midLayer2_loss: 1.6789 - rightLayer2_loss: 0.9266\n",
      "Epoch 00007: val_loss improved from 5.21101 to 5.16859, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.2381 - leftLayer1_loss: 0.0893 - midLayer1_loss: 1.4956 - rightLayer1_loss: 0.9869 - leftLayer2_loss: 0.0610 - midLayer2_loss: 1.6788 - rightLayer2_loss: 0.9266 - val_loss: 5.1686 - val_leftLayer1_loss: 0.0867 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 0.9716 - val_leftLayer2_loss: 0.0783 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0411\n",
      "Epoch 8/11\n",
      "3257/3263 [============================>.] - ETA: 0s - loss: 5.2062 - leftLayer1_loss: 0.0851 - midLayer1_loss: 1.4958 - rightLayer1_loss: 0.9707 - leftLayer2_loss: 0.0574 - midLayer2_loss: 1.6743 - rightLayer2_loss: 0.9228\n",
      "Epoch 00008: val_loss improved from 5.16859 to 5.13568, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.2051 - leftLayer1_loss: 0.0851 - midLayer1_loss: 1.4956 - rightLayer1_loss: 0.9704 - leftLayer2_loss: 0.0574 - midLayer2_loss: 1.6742 - rightLayer2_loss: 0.9224 - val_loss: 5.1357 - val_leftLayer1_loss: 0.0827 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 0.9580 - val_leftLayer2_loss: 0.0753 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0288\n",
      "Epoch 9/11\n",
      "3261/3263 [============================>.] - ETA: 0s - loss: 5.1866 - leftLayer1_loss: 0.0814 - midLayer1_loss: 1.4965 - rightLayer1_loss: 0.9588 - leftLayer2_loss: 0.0548 - midLayer2_loss: 1.6765 - rightLayer2_loss: 0.9186\n",
      "Epoch 00009: val_loss improved from 5.13568 to 5.10924, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1861 - leftLayer1_loss: 0.0814 - midLayer1_loss: 1.4964 - rightLayer1_loss: 0.9587 - leftLayer2_loss: 0.0548 - midLayer2_loss: 1.6765 - rightLayer2_loss: 0.9184 - val_loss: 5.1092 - val_leftLayer1_loss: 0.0792 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 0.9477 - val_leftLayer2_loss: 0.0728 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0187\n",
      "Epoch 10/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 5.1649 - leftLayer1_loss: 0.0781 - midLayer1_loss: 1.4955 - rightLayer1_loss: 0.9492 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.6746 - rightLayer2_loss: 0.9151\n",
      "Epoch 00010: val_loss improved from 5.10924 to 5.08749, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1641 - leftLayer1_loss: 0.0780 - midLayer1_loss: 1.4954 - rightLayer1_loss: 0.9491 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.6741 - rightLayer2_loss: 0.9150 - val_loss: 5.0875 - val_leftLayer1_loss: 0.0760 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 0.9397 - val_leftLayer2_loss: 0.0706 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0104\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3251/3263 [============================>.] - ETA: 0s - loss: 5.1529 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.4961 - rightLayer1_loss: 0.9421 - leftLayer2_loss: 0.0503 - midLayer2_loss: 1.6768 - rightLayer2_loss: 0.9125\n",
      "Epoch 00011: val_loss improved from 5.08749 to 5.06923, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1531 - leftLayer1_loss: 0.0750 - midLayer1_loss: 1.4961 - rightLayer1_loss: 0.9421 - leftLayer2_loss: 0.0503 - midLayer2_loss: 1.6769 - rightLayer2_loss: 0.9126 - val_loss: 5.0692 - val_leftLayer1_loss: 0.0731 - val_midLayer1_loss: 1.4878 - val_rightLayer1_loss: 0.9333 - val_leftLayer2_loss: 0.0687 - val_midLayer2_loss: 1.5031 - val_rightLayer2_loss: 1.0033\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Consolidation: 0.5915281630506645\n",
      "\n",
      "auprc 0Consolidation: 0.05283388820723718\n",
      "\n",
      "auroc 1Consolidation: 0.5365463243166341\n",
      "\n",
      "auprc 1Consolidation: 0.044960769724129754\n",
      "\n",
      "auroc 2Consolidation: 0.5367575634963129\n",
      "\n",
      "auprc 2Consolidation: 0.04832880427102941\n",
      "\n",
      "auroc 3Consolidation: 0.36154898092361565\n",
      "\n",
      "auprc 3Consolidation: 0.030030912011885506\n",
      "\n",
      "auroc 4Consolidation: 0.5551708178826823\n",
      "\n",
      "auprc 4Consolidation: 0.047335095961546246\n",
      "\n",
      "auroc 5Consolidation: 0.39620473526084277\n",
      "\n",
      "auprc 5Consolidation: 0.03217400580151656\n",
      "\n",
      "mean auroc: 0.49629276415512535\n",
      "\n",
      "mean auprc: 0.042610579329557446\n",
      "\n",
      "max auroc: 0.5915281630506645\n",
      "\n",
      "max auprc: 0.05283388820723718\n",
      "\n",
      "120.84535312652588\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3263 steps, validate for 447 steps\n",
      "Epoch 1/11\n",
      "3246/3263 [============================>.] - ETA: 0s - loss: 6.1389 - leftLayer1_loss: 0.1183 - midLayer1_loss: 1.4113 - rightLayer1_loss: 1.6346 - leftLayer2_loss: 0.1188 - midLayer2_loss: 1.3979 - rightLayer2_loss: 1.4580\n",
      "Epoch 00001: val_loss improved from inf to 5.81118, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 9s 3ms/step - loss: 6.1358 - leftLayer1_loss: 0.1183 - midLayer1_loss: 1.4111 - rightLayer1_loss: 1.6336 - leftLayer2_loss: 0.1188 - midLayer2_loss: 1.3976 - rightLayer2_loss: 1.4564 - val_loss: 5.8112 - val_leftLayer1_loss: 0.1144 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 1.4541 - val_leftLayer2_loss: 0.1135 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.3827\n",
      "Epoch 2/11\n",
      "3255/3263 [============================>.] - ETA: 0s - loss: 5.4451 - leftLayer1_loss: 0.1112 - midLayer1_loss: 1.4109 - rightLayer1_loss: 1.3382 - leftLayer2_loss: 0.1015 - midLayer2_loss: 1.3987 - rightLayer2_loss: 1.0845\n",
      "Epoch 00002: val_loss improved from 5.81118 to 5.40752, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.4440 - leftLayer1_loss: 0.1112 - midLayer1_loss: 1.4108 - rightLayer1_loss: 1.3379 - leftLayer2_loss: 0.1015 - midLayer2_loss: 1.3984 - rightLayer2_loss: 1.0841 - val_loss: 5.4075 - val_leftLayer1_loss: 0.1076 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 1.2330 - val_leftLayer2_loss: 0.1039 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.2165\n",
      "Epoch 3/11\n",
      "3256/3263 [============================>.] - ETA: 0s - loss: 5.1712 - leftLayer1_loss: 0.1048 - midLayer1_loss: 1.4113 - rightLayer1_loss: 1.1755 - leftLayer2_loss: 0.0889 - midLayer2_loss: 1.3975 - rightLayer2_loss: 0.9932\n",
      "Epoch 00003: val_loss improved from 5.40752 to 5.20087, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.1706 - leftLayer1_loss: 0.1048 - midLayer1_loss: 1.4112 - rightLayer1_loss: 1.1753 - leftLayer2_loss: 0.0889 - midLayer2_loss: 1.3976 - rightLayer2_loss: 0.9929 - val_loss: 5.2009 - val_leftLayer1_loss: 0.1014 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 1.1151 - val_leftLayer2_loss: 0.0962 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.1416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3252/3263 [============================>.] - ETA: 0s - loss: 5.0289 - leftLayer1_loss: 0.0990 - midLayer1_loss: 1.4107 - rightLayer1_loss: 1.0867 - leftLayer2_loss: 0.0786 - midLayer2_loss: 1.3949 - rightLayer2_loss: 0.9591\n",
      "Epoch 00004: val_loss improved from 5.20087 to 5.08078, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 5.0284 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.4106 - rightLayer1_loss: 1.0865 - leftLayer2_loss: 0.0786 - midLayer2_loss: 1.3948 - rightLayer2_loss: 0.9589 - val_loss: 5.0808 - val_leftLayer1_loss: 0.0959 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 1.0493 - val_leftLayer2_loss: 0.0899 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0991\n",
      "Epoch 5/11\n",
      "3244/3263 [============================>.] - ETA: 0s - loss: 4.9527 - leftLayer1_loss: 0.0938 - midLayer1_loss: 1.4118 - rightLayer1_loss: 1.0358 - leftLayer2_loss: 0.0712 - midLayer2_loss: 1.3974 - rightLayer2_loss: 0.9427\n",
      "Epoch 00005: val_loss improved from 5.08078 to 5.00334, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.9518 - leftLayer1_loss: 0.0937 - midLayer1_loss: 1.4115 - rightLayer1_loss: 1.0354 - leftLayer2_loss: 0.0712 - midLayer2_loss: 1.3975 - rightLayer2_loss: 0.9424 - val_loss: 5.0033 - val_leftLayer1_loss: 0.0909 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 1.0095 - val_leftLayer2_loss: 0.0848 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0715\n",
      "Epoch 6/11\n",
      "3240/3263 [============================>.] - ETA: 0s - loss: 4.9011 - leftLayer1_loss: 0.0890 - midLayer1_loss: 1.4106 - rightLayer1_loss: 1.0038 - leftLayer2_loss: 0.0655 - midLayer2_loss: 1.3985 - rightLayer2_loss: 0.9336\n",
      "Epoch 00006: val_loss improved from 5.00334 to 4.94898, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8989 - leftLayer1_loss: 0.0890 - midLayer1_loss: 1.4103 - rightLayer1_loss: 1.0032 - leftLayer2_loss: 0.0655 - midLayer2_loss: 1.3979 - rightLayer2_loss: 0.9330 - val_loss: 4.9490 - val_leftLayer1_loss: 0.0865 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 0.9837 - val_leftLayer2_loss: 0.0806 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0516\n",
      "Epoch 7/11\n",
      "3249/3263 [============================>.] - ETA: 0s - loss: 4.8613 - leftLayer1_loss: 0.0849 - midLayer1_loss: 1.4104 - rightLayer1_loss: 0.9816 - leftLayer2_loss: 0.0612 - midLayer2_loss: 1.3970 - rightLayer2_loss: 0.9262\n",
      "Epoch 00007: val_loss improved from 4.94898 to 4.90849, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8614 - leftLayer1_loss: 0.0849 - midLayer1_loss: 1.4104 - rightLayer1_loss: 0.9816 - leftLayer2_loss: 0.0612 - midLayer2_loss: 1.3970 - rightLayer2_loss: 0.9263 - val_loss: 4.9085 - val_leftLayer1_loss: 0.0824 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 0.9659 - val_leftLayer2_loss: 0.0771 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0365\n",
      "Epoch 8/11\n",
      "3252/3263 [============================>.] - ETA: 0s - loss: 4.8336 - leftLayer1_loss: 0.0811 - midLayer1_loss: 1.4114 - rightLayer1_loss: 0.9660 - leftLayer2_loss: 0.0575 - midLayer2_loss: 1.3969 - rightLayer2_loss: 0.9206\n",
      "Epoch 00008: val_loss improved from 4.90849 to 4.87707, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8331 - leftLayer1_loss: 0.0811 - midLayer1_loss: 1.4113 - rightLayer1_loss: 0.9659 - leftLayer2_loss: 0.0575 - midLayer2_loss: 1.3967 - rightLayer2_loss: 0.9206 - val_loss: 4.8771 - val_leftLayer1_loss: 0.0789 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 0.9531 - val_leftLayer2_loss: 0.0741 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0245\n",
      "Epoch 9/11\n",
      "3252/3263 [============================>.] - ETA: 0s - loss: 4.8130 - leftLayer1_loss: 0.0777 - midLayer1_loss: 1.4109 - rightLayer1_loss: 0.9544 - leftLayer2_loss: 0.0548 - midLayer2_loss: 1.3975 - rightLayer2_loss: 0.9178\n",
      "Epoch 00009: val_loss improved from 4.87707 to 4.85186, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8127 - leftLayer1_loss: 0.0777 - midLayer1_loss: 1.4109 - rightLayer1_loss: 0.9543 - leftLayer2_loss: 0.0548 - midLayer2_loss: 1.3974 - rightLayer2_loss: 0.9177 - val_loss: 4.8519 - val_leftLayer1_loss: 0.0756 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 0.9434 - val_leftLayer2_loss: 0.0716 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0147\n",
      "Epoch 10/11\n",
      "3242/3263 [============================>.] - ETA: 0s - loss: 4.8038 - leftLayer1_loss: 0.0747 - midLayer1_loss: 1.4114 - rightLayer1_loss: 0.9461 - leftLayer2_loss: 0.0525 - midLayer2_loss: 1.4031 - rightLayer2_loss: 0.9161\n",
      "Epoch 00010: val_loss improved from 4.85186 to 4.83105, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.8028 - leftLayer1_loss: 0.0746 - midLayer1_loss: 1.4111 - rightLayer1_loss: 0.9457 - leftLayer2_loss: 0.0525 - midLayer2_loss: 1.4030 - rightLayer2_loss: 0.9159 - val_loss: 4.8310 - val_leftLayer1_loss: 0.0727 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 0.9359 - val_leftLayer2_loss: 0.0694 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 1.0065\n",
      "Epoch 11/11\n",
      "3256/3263 [============================>.] - ETA: 0s - loss: 4.7857 - leftLayer1_loss: 0.0719 - midLayer1_loss: 1.4116 - rightLayer1_loss: 0.9389 - leftLayer2_loss: 0.0505 - midLayer2_loss: 1.4001 - rightLayer2_loss: 0.9126\n",
      "Epoch 00011: val_loss improved from 4.83105 to 4.81373, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3263/3263 [==============================] - 8s 3ms/step - loss: 4.7848 - leftLayer1_loss: 0.0719 - midLayer1_loss: 1.4116 - rightLayer1_loss: 0.9386 - leftLayer2_loss: 0.0505 - midLayer2_loss: 1.3999 - rightLayer2_loss: 0.9123 - val_loss: 4.8137 - val_leftLayer1_loss: 0.0701 - val_midLayer1_loss: 1.4071 - val_rightLayer1_loss: 0.9299 - val_leftLayer2_loss: 0.0675 - val_midLayer2_loss: 1.3395 - val_rightLayer2_loss: 0.9997\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Consolidation: 0.4670625497627251\n",
      "\n",
      "auprc 0Consolidation: 0.041912493667183505\n",
      "\n",
      "auroc 1Consolidation: 0.521545496194824\n",
      "\n",
      "auprc 1Consolidation: 0.04831606054259241\n",
      "\n",
      "auroc 2Consolidation: 0.47083532092298896\n",
      "\n",
      "auprc 2Consolidation: 0.037980262670399646\n",
      "\n",
      "auroc 3Consolidation: 0.38290437888626083\n",
      "\n",
      "auprc 3Consolidation: 0.031112502758060042\n",
      "\n",
      "auroc 4Consolidation: 0.3567603008719315\n",
      "\n",
      "auprc 4Consolidation: 0.030166171231396043\n",
      "\n",
      "auroc 5Consolidation: 0.47595121126681617\n",
      "\n",
      "auprc 5Consolidation: 0.03814536709249903\n",
      "\n",
      "mean auroc: 0.44584320965092444\n",
      "\n",
      "mean auprc: 0.03793880966035511\n",
      "\n",
      "max auroc: 0.521545496194824\n",
      "\n",
      "max auprc: 0.04831606054259241\n",
      "\n",
      "120.74156069755554\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718296850237236\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
