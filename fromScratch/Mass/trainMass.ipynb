{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Mass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "503: 3988\n",
      "75: 3988\n",
      "865: 3988\n",
      "822: 3988\n",
      "3988: 3988\n",
      "605: 3988\n",
      "42: 3988\n",
      "291: 3988\n",
      "435: 3988\n",
      "90: 3988\n",
      "141: 3988\n",
      "83: 3988\n",
      "306: 3988\n",
      "16: 3988\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 6.1839 - leftLayer1_loss: 0.1223 - midLayer1_loss: 1.3947 - rightLayer1_loss: 1.6247 - leftLayer2_loss: 0.1198 - midLayer2_loss: 1.5370 - rightLayer2_loss: 1.3854\n",
      "Epoch 00001: val_loss improved from inf to 5.67138, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 13s 3ms/step - loss: 6.1831 - leftLayer1_loss: 0.1223 - midLayer1_loss: 1.3947 - rightLayer1_loss: 1.6244 - leftLayer2_loss: 0.1198 - midLayer2_loss: 1.5369 - rightLayer2_loss: 1.3849 - val_loss: 5.6714 - val_leftLayer1_loss: 0.1172 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 1.4037 - val_leftLayer2_loss: 0.1115 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 1.2573\n",
      "Epoch 2/11\n",
      "3977/3988 [============================>.] - ETA: 0s - loss: 5.3795 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.3946 - rightLayer1_loss: 1.2642 - leftLayer2_loss: 0.0976 - midLayer2_loss: 1.5397 - rightLayer2_loss: 0.9702\n",
      "Epoch 00002: val_loss improved from 5.67138 to 5.21588, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 5.3784 - leftLayer1_loss: 0.1131 - midLayer1_loss: 1.3945 - rightLayer1_loss: 1.2638 - leftLayer2_loss: 0.0976 - midLayer2_loss: 1.5394 - rightLayer2_loss: 0.9700 - val_loss: 5.2159 - val_leftLayer1_loss: 0.1085 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 1.1438 - val_leftLayer2_loss: 0.0987 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 1.0832\n",
      "Epoch 3/11\n",
      "3971/3988 [============================>.] - ETA: 0s - loss: 5.0859 - leftLayer1_loss: 0.1050 - midLayer1_loss: 1.3937 - rightLayer1_loss: 1.0826 - leftLayer2_loss: 0.0814 - midLayer2_loss: 1.5354 - rightLayer2_loss: 0.8879\n",
      "Epoch 00003: val_loss improved from 5.21588 to 4.99630, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 5.0849 - leftLayer1_loss: 0.1049 - midLayer1_loss: 1.3935 - rightLayer1_loss: 1.0821 - leftLayer2_loss: 0.0814 - midLayer2_loss: 1.5353 - rightLayer2_loss: 0.8876 - val_loss: 4.9963 - val_leftLayer1_loss: 0.1008 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 1.0151 - val_leftLayer2_loss: 0.0890 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 1.0097\n",
      "Epoch 4/11\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 4.9548 - leftLayer1_loss: 0.0977 - midLayer1_loss: 1.3951 - rightLayer1_loss: 0.9901 - leftLayer2_loss: 0.0704 - midLayer2_loss: 1.5430 - rightLayer2_loss: 0.8585\n",
      "Epoch 00004: val_loss improved from 4.99630 to 4.87047, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 4.9548 - leftLayer1_loss: 0.0977 - midLayer1_loss: 1.3951 - rightLayer1_loss: 0.9901 - leftLayer2_loss: 0.0704 - midLayer2_loss: 1.5431 - rightLayer2_loss: 0.8585 - val_loss: 4.8705 - val_leftLayer1_loss: 0.0939 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.9457 - val_leftLayer2_loss: 0.0816 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.9675\n",
      "Epoch 5/11\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 4.8653 - leftLayer1_loss: 0.0914 - midLayer1_loss: 1.3947 - rightLayer1_loss: 0.9386 - leftLayer2_loss: 0.0624 - midLayer2_loss: 1.5363 - rightLayer2_loss: 0.8418\n",
      "Epoch 00005: val_loss improved from 4.87047 to 4.78935, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 4.8652 - leftLayer1_loss: 0.0914 - midLayer1_loss: 1.3948 - rightLayer1_loss: 0.9386 - leftLayer2_loss: 0.0624 - midLayer2_loss: 1.5363 - rightLayer2_loss: 0.8418 - val_loss: 4.7894 - val_leftLayer1_loss: 0.0879 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.9039 - val_leftLayer2_loss: 0.0758 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "3976/3988 [============================>.] - ETA: 0s - loss: 4.8180 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.3948 - rightLayer1_loss: 0.9063 - leftLayer2_loss: 0.0567 - midLayer2_loss: 1.5425 - rightLayer2_loss: 0.8319\n",
      "Epoch 00006: val_loss improved from 4.78935 to 4.73237, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.8179 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.3948 - rightLayer1_loss: 0.9062 - leftLayer2_loss: 0.0567 - midLayer2_loss: 1.5426 - rightLayer2_loss: 0.8319 - val_loss: 4.7324 - val_leftLayer1_loss: 0.0826 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.8766 - val_leftLayer2_loss: 0.0713 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.9201\n",
      "Epoch 7/11\n",
      "3967/3988 [============================>.] - ETA: 0s - loss: 4.7833 - leftLayer1_loss: 0.0808 - midLayer1_loss: 1.3951 - rightLayer1_loss: 0.8850 - leftLayer2_loss: 0.0526 - midLayer2_loss: 1.5443 - rightLayer2_loss: 0.8255\n",
      "Epoch 00007: val_loss improved from 4.73237 to 4.68991, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7821 - leftLayer1_loss: 0.0808 - midLayer1_loss: 1.3948 - rightLayer1_loss: 0.8847 - leftLayer2_loss: 0.0525 - midLayer2_loss: 1.5441 - rightLayer2_loss: 0.8252 - val_loss: 4.6899 - val_leftLayer1_loss: 0.0780 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.8575 - val_leftLayer2_loss: 0.0677 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.9051\n",
      "Epoch 8/11\n",
      "3969/3988 [============================>.] - ETA: 0s - loss: 4.7479 - leftLayer1_loss: 0.0765 - midLayer1_loss: 1.3954 - rightLayer1_loss: 0.8698 - leftLayer2_loss: 0.0494 - midLayer2_loss: 1.5365 - rightLayer2_loss: 0.8204\n",
      "Epoch 00008: val_loss improved from 4.68991 to 4.65690, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7470 - leftLayer1_loss: 0.0765 - midLayer1_loss: 1.3952 - rightLayer1_loss: 0.8694 - leftLayer2_loss: 0.0494 - midLayer2_loss: 1.5364 - rightLayer2_loss: 0.8201 - val_loss: 4.6569 - val_leftLayer1_loss: 0.0739 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.8434 - val_leftLayer2_loss: 0.0647 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.8933\n",
      "Epoch 9/11\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 4.7307 - leftLayer1_loss: 0.0726 - midLayer1_loss: 1.3945 - rightLayer1_loss: 0.8578 - leftLayer2_loss: 0.0472 - midLayer2_loss: 1.5413 - rightLayer2_loss: 0.8174\n",
      "Epoch 00009: val_loss improved from 4.65690 to 4.63021, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7304 - leftLayer1_loss: 0.0726 - midLayer1_loss: 1.3944 - rightLayer1_loss: 0.8577 - leftLayer2_loss: 0.0471 - midLayer2_loss: 1.5413 - rightLayer2_loss: 0.8173 - val_loss: 4.6302 - val_leftLayer1_loss: 0.0702 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.8326 - val_leftLayer2_loss: 0.0622 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.8835\n",
      "Epoch 10/11\n",
      "3964/3988 [============================>.] - ETA: 0s - loss: 4.7174 - leftLayer1_loss: 0.0693 - midLayer1_loss: 1.3946 - rightLayer1_loss: 0.8493 - leftLayer2_loss: 0.0451 - midLayer2_loss: 1.5447 - rightLayer2_loss: 0.8146\n",
      "Epoch 00010: val_loss improved from 4.63021 to 4.60824, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7160 - leftLayer1_loss: 0.0692 - midLayer1_loss: 1.3942 - rightLayer1_loss: 0.8488 - leftLayer2_loss: 0.0451 - midLayer2_loss: 1.5445 - rightLayer2_loss: 0.8141 - val_loss: 4.6082 - val_leftLayer1_loss: 0.0670 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.8241 - val_leftLayer2_loss: 0.0601 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.8754\n",
      "Epoch 11/11\n",
      "3974/3988 [============================>.] - ETA: 0s - loss: 4.6968 - leftLayer1_loss: 0.0663 - midLayer1_loss: 1.3947 - rightLayer1_loss: 0.8416 - leftLayer2_loss: 0.0436 - midLayer2_loss: 1.5388 - rightLayer2_loss: 0.8119\n",
      "Epoch 00011: val_loss improved from 4.60824 to 4.58976, saving model to ./experiments/0.009_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6967 - leftLayer1_loss: 0.0662 - midLayer1_loss: 1.3946 - rightLayer1_loss: 0.8417 - leftLayer2_loss: 0.0436 - midLayer2_loss: 1.5385 - rightLayer2_loss: 0.8121 - val_loss: 4.5898 - val_leftLayer1_loss: 0.0642 - val_midLayer1_loss: 1.3795 - val_rightLayer1_loss: 0.8172 - val_leftLayer2_loss: 0.0582 - val_midLayer2_loss: 1.4023 - val_rightLayer2_loss: 0.8684\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Mass: 0.31980495506134776\n",
      "\n",
      "auprc 0Mass: 0.03349822137293965\n",
      "\n",
      "auroc 1Mass: 0.5104306154668523\n",
      "\n",
      "auprc 1Mass: 0.04988539679475257\n",
      "\n",
      "auroc 2Mass: 0.4858771842588334\n",
      "\n",
      "auprc 2Mass: 0.046466471276237806\n",
      "\n",
      "auroc 3Mass: 0.46984560496252004\n",
      "\n",
      "auprc 3Mass: 0.04510822803588759\n",
      "\n",
      "auroc 4Mass: 0.6877349178921721\n",
      "\n",
      "auprc 4Mass: 0.10070864218363115\n",
      "\n",
      "auroc 5Mass: 0.4704215821554807\n",
      "\n",
      "auprc 5Mass: 0.04534845224571051\n",
      "\n",
      "mean auroc: 0.49068580996620104\n",
      "\n",
      "mean auprc: 0.05350256865152655\n",
      "\n",
      "max auroc: 0.6877349178921721\n",
      "\n",
      "max auprc: 0.10070864218363115\n",
      "\n",
      "145.3833613395691\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 6.0210 - leftLayer1_loss: 0.1158 - midLayer1_loss: 1.3835 - rightLayer1_loss: 1.6077 - leftLayer2_loss: 0.1146 - midLayer2_loss: 1.4336 - rightLayer2_loss: 1.3658\n",
      "Epoch 00001: val_loss improved from inf to 5.58991, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 6.0207 - leftLayer1_loss: 0.1158 - midLayer1_loss: 1.3835 - rightLayer1_loss: 1.6076 - leftLayer2_loss: 0.1146 - midLayer2_loss: 1.4336 - rightLayer2_loss: 1.3657 - val_loss: 5.5899 - val_leftLayer1_loss: 0.1111 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 1.3845 - val_leftLayer2_loss: 0.1103 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 1.2718\n",
      "Epoch 2/11\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 5.2198 - leftLayer1_loss: 0.1068 - midLayer1_loss: 1.3836 - rightLayer1_loss: 1.2399 - leftLayer2_loss: 0.0936 - midLayer2_loss: 1.4287 - rightLayer2_loss: 0.9672\n",
      "Epoch 00002: val_loss improved from 5.58991 to 5.13620, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 5.2193 - leftLayer1_loss: 0.1068 - midLayer1_loss: 1.3834 - rightLayer1_loss: 1.2397 - leftLayer2_loss: 0.0936 - midLayer2_loss: 1.4288 - rightLayer2_loss: 0.9671 - val_loss: 5.1362 - val_leftLayer1_loss: 0.1027 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 1.1270 - val_leftLayer2_loss: 0.0981 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 1.0961\n",
      "Epoch 3/11\n",
      "3973/3988 [============================>.] - ETA: 0s - loss: 4.9449 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.3836 - rightLayer1_loss: 1.0636 - leftLayer2_loss: 0.0787 - midLayer2_loss: 1.4336 - rightLayer2_loss: 0.8864\n",
      "Epoch 00003: val_loss improved from 5.13620 to 4.91999, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.9447 - leftLayer1_loss: 0.0989 - midLayer1_loss: 1.3837 - rightLayer1_loss: 1.0633 - leftLayer2_loss: 0.0787 - midLayer2_loss: 1.4337 - rightLayer2_loss: 0.8864 - val_loss: 4.9200 - val_leftLayer1_loss: 0.0953 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 1.0032 - val_leftLayer2_loss: 0.0889 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 1.0203\n",
      "Epoch 4/11\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 4.8081 - leftLayer1_loss: 0.0920 - midLayer1_loss: 1.3835 - rightLayer1_loss: 0.9769 - leftLayer2_loss: 0.0683 - midLayer2_loss: 1.4314 - rightLayer2_loss: 0.8560\n",
      "Epoch 00004: val_loss improved from 4.91999 to 4.79740, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.8078 - leftLayer1_loss: 0.0920 - midLayer1_loss: 1.3834 - rightLayer1_loss: 0.9768 - leftLayer2_loss: 0.0683 - midLayer2_loss: 1.4314 - rightLayer2_loss: 0.8559 - val_loss: 4.7974 - val_leftLayer1_loss: 0.0889 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.9374 - val_leftLayer2_loss: 0.0818 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.9771\n",
      "Epoch 5/11\n",
      "3972/3988 [============================>.] - ETA: 0s - loss: 4.7307 - leftLayer1_loss: 0.0860 - midLayer1_loss: 1.3836 - rightLayer1_loss: 0.9288 - leftLayer2_loss: 0.0609 - midLayer2_loss: 1.4309 - rightLayer2_loss: 0.8405\n",
      "Epoch 00005: val_loss improved from 4.79740 to 4.71815, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7305 - leftLayer1_loss: 0.0860 - midLayer1_loss: 1.3836 - rightLayer1_loss: 0.9286 - leftLayer2_loss: 0.0609 - midLayer2_loss: 1.4310 - rightLayer2_loss: 0.8404 - val_loss: 4.7181 - val_leftLayer1_loss: 0.0832 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8980 - val_leftLayer2_loss: 0.0763 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.9484\n",
      "Epoch 6/11\n",
      "3974/3988 [============================>.] - ETA: 0s - loss: 4.6809 - leftLayer1_loss: 0.0807 - midLayer1_loss: 1.3842 - rightLayer1_loss: 0.8991 - leftLayer2_loss: 0.0557 - midLayer2_loss: 1.4297 - rightLayer2_loss: 0.8315\n",
      "Epoch 00006: val_loss improved from 4.71815 to 4.66222, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6811 - leftLayer1_loss: 0.0807 - midLayer1_loss: 1.3843 - rightLayer1_loss: 0.8991 - leftLayer2_loss: 0.0557 - midLayer2_loss: 1.4298 - rightLayer2_loss: 0.8316 - val_loss: 4.6622 - val_leftLayer1_loss: 0.0782 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8722 - val_leftLayer2_loss: 0.0719 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.9277\n",
      "Epoch 7/11\n",
      "3971/3988 [============================>.] - ETA: 0s - loss: 4.6494 - leftLayer1_loss: 0.0762 - midLayer1_loss: 1.3840 - rightLayer1_loss: 0.8797 - leftLayer2_loss: 0.0517 - midLayer2_loss: 1.4339 - rightLayer2_loss: 0.8239\n",
      "Epoch 00007: val_loss improved from 4.66222 to 4.62052, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6490 - leftLayer1_loss: 0.0761 - midLayer1_loss: 1.3840 - rightLayer1_loss: 0.8794 - leftLayer2_loss: 0.0517 - midLayer2_loss: 1.4340 - rightLayer2_loss: 0.8237 - val_loss: 4.6205 - val_leftLayer1_loss: 0.0739 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8541 - val_leftLayer2_loss: 0.0683 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.9120\n",
      "Epoch 8/11\n",
      "3980/3988 [============================>.] - ETA: 0s - loss: 4.6248 - leftLayer1_loss: 0.0721 - midLayer1_loss: 1.3833 - rightLayer1_loss: 0.8652 - leftLayer2_loss: 0.0488 - midLayer2_loss: 1.4348 - rightLayer2_loss: 0.8207\n",
      "Epoch 00008: val_loss improved from 4.62052 to 4.58789, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6244 - leftLayer1_loss: 0.0721 - midLayer1_loss: 1.3832 - rightLayer1_loss: 0.8650 - leftLayer2_loss: 0.0488 - midLayer2_loss: 1.4350 - rightLayer2_loss: 0.8204 - val_loss: 4.5879 - val_leftLayer1_loss: 0.0701 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8408 - val_leftLayer2_loss: 0.0653 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.8994\n",
      "Epoch 9/11\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 4.6067 - leftLayer1_loss: 0.0685 - midLayer1_loss: 1.3838 - rightLayer1_loss: 0.8547 - leftLayer2_loss: 0.0465 - midLayer2_loss: 1.4366 - rightLayer2_loss: 0.8167\n",
      "Epoch 00009: val_loss improved from 4.58789 to 4.56164, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 4.6065 - leftLayer1_loss: 0.0685 - midLayer1_loss: 1.3837 - rightLayer1_loss: 0.8546 - leftLayer2_loss: 0.0465 - midLayer2_loss: 1.4367 - rightLayer2_loss: 0.8166 - val_loss: 4.5616 - val_leftLayer1_loss: 0.0668 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8307 - val_leftLayer2_loss: 0.0629 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.8892\n",
      "Epoch 10/11\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 4.5889 - leftLayer1_loss: 0.0655 - midLayer1_loss: 1.3840 - rightLayer1_loss: 0.8467 - leftLayer2_loss: 0.0446 - midLayer2_loss: 1.4343 - rightLayer2_loss: 0.8138\n",
      "Epoch 00010: val_loss improved from 4.56164 to 4.53993, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5885 - leftLayer1_loss: 0.0655 - midLayer1_loss: 1.3839 - rightLayer1_loss: 0.8465 - leftLayer2_loss: 0.0446 - midLayer2_loss: 1.4343 - rightLayer2_loss: 0.8136 - val_loss: 4.5399 - val_leftLayer1_loss: 0.0638 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8226 - val_leftLayer2_loss: 0.0608 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.8806\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3988 [============================>.] - ETA: 0s - loss: 4.5714 - leftLayer1_loss: 0.0627 - midLayer1_loss: 1.3830 - rightLayer1_loss: 0.8397 - leftLayer2_loss: 0.0431 - midLayer2_loss: 1.4318 - rightLayer2_loss: 0.8110\n",
      "Epoch 00011: val_loss improved from 4.53993 to 4.52176, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5711 - leftLayer1_loss: 0.0627 - midLayer1_loss: 1.3829 - rightLayer1_loss: 0.8396 - leftLayer2_loss: 0.0431 - midLayer2_loss: 1.4317 - rightLayer2_loss: 0.8109 - val_loss: 4.5218 - val_leftLayer1_loss: 0.0612 - val_midLayer1_loss: 1.3695 - val_rightLayer1_loss: 0.8161 - val_leftLayer2_loss: 0.0589 - val_midLayer2_loss: 1.3427 - val_rightLayer2_loss: 0.8734\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Mass: 0.6600254217271858\n",
      "\n",
      "auprc 0Mass: 0.08628308259280595\n",
      "\n",
      "auroc 1Mass: 0.2864176704830335\n",
      "\n",
      "auprc 1Mass: 0.03226412456465011\n",
      "\n",
      "auroc 2Mass: 0.654224005403412\n",
      "\n",
      "auprc 2Mass: 0.09631971045701654\n",
      "\n",
      "auroc 3Mass: 0.45817697002846736\n",
      "\n",
      "auprc 3Mass: 0.04474688578495345\n",
      "\n",
      "auroc 4Mass: 0.48694187188443994\n",
      "\n",
      "auprc 4Mass: 0.04924851978818534\n",
      "\n",
      "auroc 5Mass: 0.4163903012070659\n",
      "\n",
      "auprc 5Mass: 0.03970315552597039\n",
      "\n",
      "mean auroc: 0.4936960401222674\n",
      "\n",
      "mean auprc: 0.05809424645226363\n",
      "\n",
      "max auroc: 0.6600254217271858\n",
      "\n",
      "max auprc: 0.09631971045701654\n",
      "\n",
      "142.01694893836975\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 6.0221 - leftLayer1_loss: 0.1239 - midLayer1_loss: 1.4383 - rightLayer1_loss: 1.6190 - leftLayer2_loss: 0.1161 - midLayer2_loss: 1.3751 - rightLayer2_loss: 1.3498\n",
      "Epoch 00001: val_loss improved from inf to 5.66591, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 6.0219 - leftLayer1_loss: 0.1239 - midLayer1_loss: 1.4383 - rightLayer1_loss: 1.6189 - leftLayer2_loss: 0.1161 - midLayer2_loss: 1.3750 - rightLayer2_loss: 1.3497 - val_loss: 5.6659 - val_leftLayer1_loss: 0.1194 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 1.4150 - val_leftLayer2_loss: 0.1081 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 1.2732\n",
      "Epoch 2/11\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 5.2744 - leftLayer1_loss: 0.1152 - midLayer1_loss: 1.4387 - rightLayer1_loss: 1.2824 - leftLayer2_loss: 0.0949 - midLayer2_loss: 1.3764 - rightLayer2_loss: 0.9669\n",
      "Epoch 00002: val_loss improved from 5.66591 to 5.22394, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 5.2742 - leftLayer1_loss: 0.1152 - midLayer1_loss: 1.4386 - rightLayer1_loss: 1.2823 - leftLayer2_loss: 0.0949 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.9668 - val_loss: 5.2239 - val_leftLayer1_loss: 0.1112 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 1.1655 - val_leftLayer2_loss: 0.0961 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 1.1010\n",
      "Epoch 3/11\n",
      "3975/3988 [============================>.] - ETA: 0s - loss: 4.9990 - leftLayer1_loss: 0.1074 - midLayer1_loss: 1.4386 - rightLayer1_loss: 1.1041 - leftLayer2_loss: 0.0798 - midLayer2_loss: 1.3813 - rightLayer2_loss: 0.8876\n",
      "Epoch 00003: val_loss improved from 5.22394 to 5.00208, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.9987 - leftLayer1_loss: 0.1074 - midLayer1_loss: 1.4386 - rightLayer1_loss: 1.1039 - leftLayer2_loss: 0.0798 - midLayer2_loss: 1.3814 - rightLayer2_loss: 0.8876 - val_loss: 5.0021 - val_leftLayer1_loss: 0.1038 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 1.0353 - val_leftLayer2_loss: 0.0871 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 1.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 4.8568 - leftLayer1_loss: 0.1004 - midLayer1_loss: 1.4384 - rightLayer1_loss: 1.0097 - leftLayer2_loss: 0.0695 - midLayer2_loss: 1.3797 - rightLayer2_loss: 0.8590\n",
      "Epoch 00004: val_loss improved from 5.00208 to 4.87248, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.8563 - leftLayer1_loss: 0.1004 - midLayer1_loss: 1.4383 - rightLayer1_loss: 1.0095 - leftLayer2_loss: 0.0695 - midLayer2_loss: 1.3797 - rightLayer2_loss: 0.8588 - val_loss: 4.8725 - val_leftLayer1_loss: 0.0972 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.9630 - val_leftLayer2_loss: 0.0801 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.9821\n",
      "Epoch 5/11\n",
      "3971/3988 [============================>.] - ETA: 0s - loss: 4.7681 - leftLayer1_loss: 0.0943 - midLayer1_loss: 1.4387 - rightLayer1_loss: 0.9552 - leftLayer2_loss: 0.0619 - midLayer2_loss: 1.3754 - rightLayer2_loss: 0.8426\n",
      "Epoch 00005: val_loss improved from 4.87248 to 4.78809, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7674 - leftLayer1_loss: 0.0943 - midLayer1_loss: 1.4386 - rightLayer1_loss: 0.9549 - leftLayer2_loss: 0.0618 - midLayer2_loss: 1.3754 - rightLayer2_loss: 0.8424 - val_loss: 4.7881 - val_leftLayer1_loss: 0.0913 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.9187 - val_leftLayer2_loss: 0.0747 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.9533\n",
      "Epoch 6/11\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 4.7133 - leftLayer1_loss: 0.0888 - midLayer1_loss: 1.4378 - rightLayer1_loss: 0.9211 - leftLayer2_loss: 0.0564 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.8327\n",
      "Epoch 00006: val_loss improved from 4.78809 to 4.72838, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7129 - leftLayer1_loss: 0.0887 - midLayer1_loss: 1.4377 - rightLayer1_loss: 0.9209 - leftLayer2_loss: 0.0564 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.8325 - val_loss: 4.7284 - val_leftLayer1_loss: 0.0860 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.8894 - val_leftLayer2_loss: 0.0704 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.9324\n",
      "Epoch 7/11\n",
      "3976/3988 [============================>.] - ETA: 0s - loss: 4.6748 - leftLayer1_loss: 0.0839 - midLayer1_loss: 1.4387 - rightLayer1_loss: 0.8975 - leftLayer2_loss: 0.0524 - midLayer2_loss: 1.3759 - rightLayer2_loss: 0.8264\n",
      "Epoch 00007: val_loss improved from 4.72838 to 4.68359, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6748 - leftLayer1_loss: 0.0839 - midLayer1_loss: 1.4387 - rightLayer1_loss: 0.8974 - leftLayer2_loss: 0.0523 - midLayer2_loss: 1.3759 - rightLayer2_loss: 0.8264 - val_loss: 4.6836 - val_leftLayer1_loss: 0.0814 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.8688 - val_leftLayer2_loss: 0.0669 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.9164\n",
      "Epoch 8/11\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 4.6514 - leftLayer1_loss: 0.0795 - midLayer1_loss: 1.4382 - rightLayer1_loss: 0.8814 - leftLayer2_loss: 0.0493 - midLayer2_loss: 1.3815 - rightLayer2_loss: 0.8213\n",
      "Epoch 00008: val_loss improved from 4.68359 to 4.64867, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6510 - leftLayer1_loss: 0.0795 - midLayer1_loss: 1.4382 - rightLayer1_loss: 0.8813 - leftLayer2_loss: 0.0493 - midLayer2_loss: 1.3815 - rightLayer2_loss: 0.8212 - val_loss: 4.6487 - val_leftLayer1_loss: 0.0772 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.8536 - val_leftLayer2_loss: 0.0640 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.9037\n",
      "Epoch 9/11\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 4.6223 - leftLayer1_loss: 0.0756 - midLayer1_loss: 1.4390 - rightLayer1_loss: 0.8686 - leftLayer2_loss: 0.0470 - midLayer2_loss: 1.3750 - rightLayer2_loss: 0.8171\n",
      "Epoch 00009: val_loss improved from 4.64867 to 4.62066, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6220 - leftLayer1_loss: 0.0756 - midLayer1_loss: 1.4390 - rightLayer1_loss: 0.8685 - leftLayer2_loss: 0.0470 - midLayer2_loss: 1.3749 - rightLayer2_loss: 0.8170 - val_loss: 4.6207 - val_leftLayer1_loss: 0.0735 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.8419 - val_leftLayer2_loss: 0.0616 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.8935\n",
      "Epoch 10/11\n",
      "3965/3988 [============================>.] - ETA: 0s - loss: 4.6048 - leftLayer1_loss: 0.0723 - midLayer1_loss: 1.4389 - rightLayer1_loss: 0.8593 - leftLayer2_loss: 0.0450 - midLayer2_loss: 1.3740 - rightLayer2_loss: 0.8153\n",
      "Epoch 00010: val_loss improved from 4.62066 to 4.59739, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.6038 - leftLayer1_loss: 0.0722 - midLayer1_loss: 1.4387 - rightLayer1_loss: 0.8590 - leftLayer2_loss: 0.0449 - midLayer2_loss: 1.3738 - rightLayer2_loss: 0.8151 - val_loss: 4.5974 - val_leftLayer1_loss: 0.0702 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.8327 - val_leftLayer2_loss: 0.0596 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.8848\n",
      "Epoch 11/11\n",
      "3967/3988 [============================>.] - ETA: 0s - loss: 4.5921 - leftLayer1_loss: 0.0692 - midLayer1_loss: 1.4394 - rightLayer1_loss: 0.8519 - leftLayer2_loss: 0.0434 - midLayer2_loss: 1.3762 - rightLayer2_loss: 0.8121\n",
      "Epoch 00011: val_loss improved from 4.59739 to 4.57795, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5912 - leftLayer1_loss: 0.0692 - midLayer1_loss: 1.4392 - rightLayer1_loss: 0.8516 - leftLayer2_loss: 0.0434 - midLayer2_loss: 1.3759 - rightLayer2_loss: 0.8119 - val_loss: 4.5779 - val_leftLayer1_loss: 0.0673 - val_midLayer1_loss: 1.4300 - val_rightLayer1_loss: 0.8252 - val_leftLayer2_loss: 0.0578 - val_midLayer2_loss: 1.3201 - val_rightLayer2_loss: 0.8775\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Mass: 0.5738819412503263\n",
      "\n",
      "auprc 0Mass: 0.057748973117102725\n",
      "\n",
      "auroc 1Mass: 0.7565029689759623\n",
      "\n",
      "auprc 1Mass: 0.13576781767917623\n",
      "\n",
      "auroc 2Mass: 0.5501138072921199\n",
      "\n",
      "auprc 2Mass: 0.05511743073402329\n",
      "\n",
      "auroc 3Mass: 0.5476616569082041\n",
      "\n",
      "auprc 3Mass: 0.05630934996030312\n",
      "\n",
      "auroc 4Mass: 0.4898775737685898\n",
      "\n",
      "auprc 4Mass: 0.04888521930419361\n",
      "\n",
      "auroc 5Mass: 0.6012467419995111\n",
      "\n",
      "auprc 5Mass: 0.07033732378692564\n",
      "\n",
      "mean auroc: 0.5865474483657857\n",
      "\n",
      "mean auprc: 0.07069435243028743\n",
      "\n",
      "max auroc: 0.7565029689759623\n",
      "\n",
      "max auprc: 0.13576781767917623\n",
      "\n",
      "142.0092213153839\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3966/3988 [============================>.] - ETA: 0s - loss: 5.8635 - leftLayer1_loss: 0.1248 - midLayer1_loss: 1.3463 - rightLayer1_loss: 1.5826 - leftLayer2_loss: 0.1174 - midLayer2_loss: 1.3669 - rightLayer2_loss: 1.3255\n",
      "Epoch 00001: val_loss improved from inf to 5.51092, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 5.8597 - leftLayer1_loss: 0.1248 - midLayer1_loss: 1.3461 - rightLayer1_loss: 1.5812 - leftLayer2_loss: 0.1173 - midLayer2_loss: 1.3666 - rightLayer2_loss: 1.3238 - val_loss: 5.5109 - val_leftLayer1_loss: 0.1196 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 1.3579 - val_leftLayer2_loss: 0.1124 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 1.2697\n",
      "Epoch 2/11\n",
      "3972/3988 [============================>.] - ETA: 0s - loss: 5.1143 - leftLayer1_loss: 0.1149 - midLayer1_loss: 1.3464 - rightLayer1_loss: 1.2270 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.3654 - rightLayer2_loss: 0.9642\n",
      "Epoch 00002: val_loss improved from 5.51092 to 5.07837, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 5.1131 - leftLayer1_loss: 0.1148 - midLayer1_loss: 1.3463 - rightLayer1_loss: 1.2265 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.3654 - rightLayer2_loss: 0.9638 - val_loss: 5.0784 - val_leftLayer1_loss: 0.1102 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 1.1121 - val_leftLayer2_loss: 0.1004 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 1.1043\n",
      "Epoch 3/11\n",
      "3971/3988 [============================>.] - ETA: 0s - loss: 4.8451 - leftLayer1_loss: 0.1060 - midLayer1_loss: 1.3465 - rightLayer1_loss: 1.0578 - leftLayer2_loss: 0.0810 - midLayer2_loss: 1.3658 - rightLayer2_loss: 0.8880\n",
      "Epoch 00003: val_loss improved from 5.07837 to 4.86900, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.8441 - leftLayer1_loss: 0.1060 - midLayer1_loss: 1.3464 - rightLayer1_loss: 1.0574 - leftLayer2_loss: 0.0810 - midLayer2_loss: 1.3656 - rightLayer2_loss: 0.8877 - val_loss: 4.8690 - val_leftLayer1_loss: 0.1019 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.9942 - val_leftLayer2_loss: 0.0913 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 1.0303\n",
      "Epoch 4/11\n",
      "3968/3988 [============================>.] - ETA: 0s - loss: 4.7116 - leftLayer1_loss: 0.0983 - midLayer1_loss: 1.3461 - rightLayer1_loss: 0.9737 - leftLayer2_loss: 0.0702 - midLayer2_loss: 1.3671 - rightLayer2_loss: 0.8563\n",
      "Epoch 00004: val_loss improved from 4.86900 to 4.74881, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7103 - leftLayer1_loss: 0.0982 - midLayer1_loss: 1.3459 - rightLayer1_loss: 0.9733 - leftLayer2_loss: 0.0702 - midLayer2_loss: 1.3667 - rightLayer2_loss: 0.8560 - val_loss: 4.7488 - val_leftLayer1_loss: 0.0946 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.9311 - val_leftLayer2_loss: 0.0842 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.9875\n",
      "Epoch 5/11\n",
      "3972/3988 [============================>.] - ETA: 0s - loss: 4.6380 - leftLayer1_loss: 0.0915 - midLayer1_loss: 1.3461 - rightLayer1_loss: 0.9263 - leftLayer2_loss: 0.0627 - midLayer2_loss: 1.3692 - rightLayer2_loss: 0.8422\n",
      "Epoch 00005: val_loss improved from 4.74881 to 4.66982, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 4.6376 - leftLayer1_loss: 0.0915 - midLayer1_loss: 1.3459 - rightLayer1_loss: 0.9261 - leftLayer2_loss: 0.0627 - midLayer2_loss: 1.3692 - rightLayer2_loss: 0.8422 - val_loss: 4.6698 - val_leftLayer1_loss: 0.0882 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8933 - val_leftLayer2_loss: 0.0786 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.9583\n",
      "Epoch 6/11\n",
      "3970/3988 [============================>.] - ETA: 0s - loss: 4.5850 - leftLayer1_loss: 0.0855 - midLayer1_loss: 1.3463 - rightLayer1_loss: 0.8973 - leftLayer2_loss: 0.0572 - midLayer2_loss: 1.3672 - rightLayer2_loss: 0.8316\n",
      "Epoch 00006: val_loss improved from 4.66982 to 4.61405, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5840 - leftLayer1_loss: 0.0855 - midLayer1_loss: 1.3461 - rightLayer1_loss: 0.8970 - leftLayer2_loss: 0.0571 - midLayer2_loss: 1.3671 - rightLayer2_loss: 0.8312 - val_loss: 4.6141 - val_leftLayer1_loss: 0.0826 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8685 - val_leftLayer2_loss: 0.0742 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.9374\n",
      "Epoch 7/11\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 4.5468 - leftLayer1_loss: 0.0803 - midLayer1_loss: 1.3452 - rightLayer1_loss: 0.8773 - leftLayer2_loss: 0.0530 - midLayer2_loss: 1.3668 - rightLayer2_loss: 0.8243\n",
      "Epoch 00007: val_loss improved from 4.61405 to 4.57207, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5465 - leftLayer1_loss: 0.0803 - midLayer1_loss: 1.3451 - rightLayer1_loss: 0.8772 - leftLayer2_loss: 0.0530 - midLayer2_loss: 1.3668 - rightLayer2_loss: 0.8241 - val_loss: 4.5721 - val_leftLayer1_loss: 0.0777 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8510 - val_leftLayer2_loss: 0.0706 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.9214\n",
      "Epoch 8/11\n",
      "3977/3988 [============================>.] - ETA: 0s - loss: 4.5260 - leftLayer1_loss: 0.0758 - midLayer1_loss: 1.3455 - rightLayer1_loss: 0.8637 - leftLayer2_loss: 0.0499 - midLayer2_loss: 1.3718 - rightLayer2_loss: 0.8192\n",
      "Epoch 00008: val_loss improved from 4.57207 to 4.53929, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5258 - leftLayer1_loss: 0.0758 - midLayer1_loss: 1.3455 - rightLayer1_loss: 0.8637 - leftLayer2_loss: 0.0499 - midLayer2_loss: 1.3716 - rightLayer2_loss: 0.8192 - val_loss: 4.5393 - val_leftLayer1_loss: 0.0735 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8382 - val_leftLayer2_loss: 0.0675 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.9088\n",
      "Epoch 9/11\n",
      "3981/3988 [============================>.] - ETA: 0s - loss: 4.5061 - leftLayer1_loss: 0.0719 - midLayer1_loss: 1.3461 - rightLayer1_loss: 0.8528 - leftLayer2_loss: 0.0475 - midLayer2_loss: 1.3712 - rightLayer2_loss: 0.8166\n",
      "Epoch 00009: val_loss improved from 4.53929 to 4.51262, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5057 - leftLayer1_loss: 0.0719 - midLayer1_loss: 1.3461 - rightLayer1_loss: 0.8528 - leftLayer2_loss: 0.0475 - midLayer2_loss: 1.3709 - rightLayer2_loss: 0.8166 - val_loss: 4.5126 - val_leftLayer1_loss: 0.0697 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8283 - val_leftLayer2_loss: 0.0650 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.8982\n",
      "Epoch 10/11\n",
      "3968/3988 [============================>.] - ETA: 0s - loss: 4.4879 - leftLayer1_loss: 0.0684 - midLayer1_loss: 1.3470 - rightLayer1_loss: 0.8450 - leftLayer2_loss: 0.0456 - midLayer2_loss: 1.3682 - rightLayer2_loss: 0.8138\n",
      "Epoch 00010: val_loss improved from 4.51262 to 4.49056, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.4868 - leftLayer1_loss: 0.0683 - midLayer1_loss: 1.3467 - rightLayer1_loss: 0.8447 - leftLayer2_loss: 0.0455 - midLayer2_loss: 1.3679 - rightLayer2_loss: 0.8136 - val_loss: 4.4906 - val_leftLayer1_loss: 0.0664 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8205 - val_leftLayer2_loss: 0.0629 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.8894\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3988 [============================>.] - ETA: 0s - loss: 4.4714 - leftLayer1_loss: 0.0654 - midLayer1_loss: 1.3469 - rightLayer1_loss: 0.8383 - leftLayer2_loss: 0.0438 - midLayer2_loss: 1.3663 - rightLayer2_loss: 0.8106\n",
      "Epoch 00011: val_loss improved from 4.49056 to 4.47206, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.4714 - leftLayer1_loss: 0.0654 - midLayer1_loss: 1.3469 - rightLayer1_loss: 0.8383 - leftLayer2_loss: 0.0438 - midLayer2_loss: 1.3664 - rightLayer2_loss: 0.8106 - val_loss: 4.4721 - val_leftLayer1_loss: 0.0635 - val_midLayer1_loss: 1.3391 - val_rightLayer1_loss: 0.8142 - val_leftLayer2_loss: 0.0610 - val_midLayer2_loss: 1.3122 - val_rightLayer2_loss: 0.8820\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Mass: 0.40516365625349626\n",
      "\n",
      "auprc 0Mass: 0.03927204058192476\n",
      "\n",
      "auroc 1Mass: 0.3977325352527048\n",
      "\n",
      "auprc 1Mass: 0.04116284354985536\n",
      "\n",
      "auroc 2Mass: 0.506572894264676\n",
      "\n",
      "auprc 2Mass: 0.0497551898141976\n",
      "\n",
      "auroc 3Mass: 0.49927721077864656\n",
      "\n",
      "auprc 3Mass: 0.051365763619218824\n",
      "\n",
      "auroc 4Mass: 0.4215225480568021\n",
      "\n",
      "auprc 4Mass: 0.04177850513173886\n",
      "\n",
      "auroc 5Mass: 0.4336061559116393\n",
      "\n",
      "auprc 5Mass: 0.04226904943632876\n",
      "\n",
      "mean auroc: 0.4439791667529942\n",
      "\n",
      "mean auprc: 0.044267232022210695\n",
      "\n",
      "max auroc: 0.506572894264676\n",
      "\n",
      "max auprc: 0.051365763619218824\n",
      "\n",
      "142.06468510627747\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 5.9833 - leftLayer1_loss: 0.1259 - midLayer1_loss: 1.3854 - rightLayer1_loss: 1.6130 - leftLayer2_loss: 0.1239 - midLayer2_loss: 1.3831 - rightLayer2_loss: 1.3520\n",
      "Epoch 00001: val_loss improved from inf to 5.61543, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 5.9817 - leftLayer1_loss: 0.1259 - midLayer1_loss: 1.3853 - rightLayer1_loss: 1.6125 - leftLayer2_loss: 0.1239 - midLayer2_loss: 1.3831 - rightLayer2_loss: 1.3511 - val_loss: 5.6154 - val_leftLayer1_loss: 0.1206 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 1.3885 - val_leftLayer2_loss: 0.1146 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 1.2856\n",
      "Epoch 2/11\n",
      "3975/3988 [============================>.] - ETA: 0s - loss: 5.2032 - leftLayer1_loss: 0.1160 - midLayer1_loss: 1.3848 - rightLayer1_loss: 1.2473 - leftLayer2_loss: 0.1013 - midLayer2_loss: 1.3819 - rightLayer2_loss: 0.9719\n",
      "Epoch 00002: val_loss improved from 5.61543 to 5.16292, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 5.2029 - leftLayer1_loss: 0.1160 - midLayer1_loss: 1.3848 - rightLayer1_loss: 1.2469 - leftLayer2_loss: 0.1013 - midLayer2_loss: 1.3822 - rightLayer2_loss: 0.9718 - val_loss: 5.1629 - val_leftLayer1_loss: 0.1112 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 1.1304 - val_leftLayer2_loss: 0.1021 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 1.1130\n",
      "Epoch 3/11\n",
      "3974/3988 [============================>.] - ETA: 0s - loss: 4.9220 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.3843 - rightLayer1_loss: 1.0688 - leftLayer2_loss: 0.0851 - midLayer2_loss: 1.3843 - rightLayer2_loss: 0.8923\n",
      "Epoch 00003: val_loss improved from 5.16292 to 4.94322, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.9218 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.3843 - rightLayer1_loss: 1.0687 - leftLayer2_loss: 0.0851 - midLayer2_loss: 1.3843 - rightLayer2_loss: 0.8923 - val_loss: 4.9432 - val_leftLayer1_loss: 0.1029 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 1.0053 - val_leftLayer2_loss: 0.0925 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 1.0364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3975/3988 [============================>.] - ETA: 0s - loss: 4.7853 - leftLayer1_loss: 0.0993 - midLayer1_loss: 1.3847 - rightLayer1_loss: 0.9801 - leftLayer2_loss: 0.0736 - midLayer2_loss: 1.3873 - rightLayer2_loss: 0.8603\n",
      "Epoch 00004: val_loss improved from 4.94322 to 4.81732, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 4.7851 - leftLayer1_loss: 0.0993 - midLayer1_loss: 1.3847 - rightLayer1_loss: 0.9800 - leftLayer2_loss: 0.0736 - midLayer2_loss: 1.3872 - rightLayer2_loss: 0.8603 - val_loss: 4.8173 - val_leftLayer1_loss: 0.0956 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.9384 - val_leftLayer2_loss: 0.0851 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.9921\n",
      "Epoch 5/11\n",
      "3976/3988 [============================>.] - ETA: 0s - loss: 4.7029 - leftLayer1_loss: 0.0926 - midLayer1_loss: 1.3845 - rightLayer1_loss: 0.9309 - leftLayer2_loss: 0.0654 - midLayer2_loss: 1.3851 - rightLayer2_loss: 0.8445\n",
      "Epoch 00005: val_loss improved from 4.81732 to 4.73540, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.7030 - leftLayer1_loss: 0.0926 - midLayer1_loss: 1.3844 - rightLayer1_loss: 0.9308 - leftLayer2_loss: 0.0653 - midLayer2_loss: 1.3852 - rightLayer2_loss: 0.8445 - val_loss: 4.7354 - val_leftLayer1_loss: 0.0892 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8984 - val_leftLayer2_loss: 0.0792 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.9624\n",
      "Epoch 6/11\n",
      "3965/3988 [============================>.] - ETA: 0s - loss: 4.6507 - leftLayer1_loss: 0.0866 - midLayer1_loss: 1.3854 - rightLayer1_loss: 0.9002 - leftLayer2_loss: 0.0591 - midLayer2_loss: 1.3864 - rightLayer2_loss: 0.8330\n",
      "Epoch 00006: val_loss improved from 4.73540 to 4.67750, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6500 - leftLayer1_loss: 0.0865 - midLayer1_loss: 1.3853 - rightLayer1_loss: 0.8999 - leftLayer2_loss: 0.0591 - midLayer2_loss: 1.3865 - rightLayer2_loss: 0.8327 - val_loss: 4.6775 - val_leftLayer1_loss: 0.0836 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8722 - val_leftLayer2_loss: 0.0746 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.9410\n",
      "Epoch 7/11\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 4.6063 - leftLayer1_loss: 0.0814 - midLayer1_loss: 1.3847 - rightLayer1_loss: 0.8800 - leftLayer2_loss: 0.0544 - midLayer2_loss: 1.3786 - rightLayer2_loss: 0.8273\n",
      "Epoch 00007: val_loss improved from 4.67750 to 4.63393, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6061 - leftLayer1_loss: 0.0814 - midLayer1_loss: 1.3846 - rightLayer1_loss: 0.8799 - leftLayer2_loss: 0.0544 - midLayer2_loss: 1.3786 - rightLayer2_loss: 0.8271 - val_loss: 4.6339 - val_leftLayer1_loss: 0.0787 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8538 - val_leftLayer2_loss: 0.0708 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.9245\n",
      "Epoch 8/11\n",
      "3980/3988 [============================>.] - ETA: 0s - loss: 4.5843 - leftLayer1_loss: 0.0768 - midLayer1_loss: 1.3852 - rightLayer1_loss: 0.8653 - leftLayer2_loss: 0.0512 - midLayer2_loss: 1.3834 - rightLayer2_loss: 0.8224\n",
      "Epoch 00008: val_loss improved from 4.63393 to 4.59988, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5839 - leftLayer1_loss: 0.0768 - midLayer1_loss: 1.3851 - rightLayer1_loss: 0.8652 - leftLayer2_loss: 0.0512 - midLayer2_loss: 1.3834 - rightLayer2_loss: 0.8222 - val_loss: 4.5999 - val_leftLayer1_loss: 0.0744 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8403 - val_leftLayer2_loss: 0.0677 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.9114\n",
      "Epoch 9/11\n",
      "3974/3988 [============================>.] - ETA: 0s - loss: 4.5600 - leftLayer1_loss: 0.0728 - midLayer1_loss: 1.3848 - rightLayer1_loss: 0.8538 - leftLayer2_loss: 0.0485 - midLayer2_loss: 1.3823 - rightLayer2_loss: 0.8178\n",
      "Epoch 00009: val_loss improved from 4.59988 to 4.57252, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5601 - leftLayer1_loss: 0.0727 - midLayer1_loss: 1.3848 - rightLayer1_loss: 0.8539 - leftLayer2_loss: 0.0485 - midLayer2_loss: 1.3823 - rightLayer2_loss: 0.8179 - val_loss: 4.5725 - val_leftLayer1_loss: 0.0706 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8299 - val_leftLayer2_loss: 0.0650 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.9008\n",
      "Epoch 10/11\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 4.5471 - leftLayer1_loss: 0.0693 - midLayer1_loss: 1.3851 - rightLayer1_loss: 0.8453 - leftLayer2_loss: 0.0464 - midLayer2_loss: 1.3855 - rightLayer2_loss: 0.8155\n",
      "Epoch 00010: val_loss improved from 4.57252 to 4.54977, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5466 - leftLayer1_loss: 0.0693 - midLayer1_loss: 1.3850 - rightLayer1_loss: 0.8452 - leftLayer2_loss: 0.0464 - midLayer2_loss: 1.3854 - rightLayer2_loss: 0.8153 - val_loss: 4.5498 - val_leftLayer1_loss: 0.0672 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8218 - val_leftLayer2_loss: 0.0628 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.8918\n",
      "Epoch 11/11\n",
      "3970/3988 [============================>.] - ETA: 0s - loss: 4.5325 - leftLayer1_loss: 0.0662 - midLayer1_loss: 1.3846 - rightLayer1_loss: 0.8388 - leftLayer2_loss: 0.0448 - midLayer2_loss: 1.3851 - rightLayer2_loss: 0.8131\n",
      "Epoch 00011: val_loss improved from 4.54977 to 4.53056, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5316 - leftLayer1_loss: 0.0662 - midLayer1_loss: 1.3845 - rightLayer1_loss: 0.8385 - leftLayer2_loss: 0.0447 - midLayer2_loss: 1.3849 - rightLayer2_loss: 0.8128 - val_loss: 4.5306 - val_leftLayer1_loss: 0.0643 - val_midLayer1_loss: 1.3760 - val_rightLayer1_loss: 0.8151 - val_leftLayer2_loss: 0.0609 - val_midLayer2_loss: 1.3302 - val_rightLayer2_loss: 0.8841\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Mass: 0.6250018232371576\n",
      "\n",
      "auprc 0Mass: 0.0914676264052221\n",
      "\n",
      "auroc 1Mass: 0.3219956780991924\n",
      "\n",
      "auprc 1Mass: 0.03357079449604304\n",
      "\n",
      "auroc 2Mass: 0.569430797790568\n",
      "\n",
      "auprc 2Mass: 0.061728250266398825\n",
      "\n",
      "auroc 3Mass: 0.6092778116181644\n",
      "\n",
      "auprc 3Mass: 0.06933555305602945\n",
      "\n",
      "auroc 4Mass: 0.5889597396085842\n",
      "\n",
      "auprc 4Mass: 0.06411119647724933\n",
      "\n",
      "auroc 5Mass: 0.5538236598170962\n",
      "\n",
      "auprc 5Mass: 0.06134205971599774\n",
      "\n",
      "mean auroc: 0.5447482516951272\n",
      "\n",
      "mean auprc: 0.06359258006949009\n",
      "\n",
      "max auroc: 0.6250018232371576\n",
      "\n",
      "max auprc: 0.0914676264052221\n",
      "\n",
      "138.37840580940247\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 5.9679 - leftLayer1_loss: 0.1149 - midLayer1_loss: 1.3251 - rightLayer1_loss: 1.6129 - leftLayer2_loss: 0.1224 - midLayer2_loss: 1.4316 - rightLayer2_loss: 1.3609\n",
      "Epoch 00001: val_loss improved from inf to 5.54907, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 5.9669 - leftLayer1_loss: 0.1149 - midLayer1_loss: 1.3251 - rightLayer1_loss: 1.6125 - leftLayer2_loss: 0.1224 - midLayer2_loss: 1.4316 - rightLayer2_loss: 1.3604 - val_loss: 5.5491 - val_leftLayer1_loss: 0.1102 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 1.3831 - val_leftLayer2_loss: 0.1145 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 1.2680\n",
      "Epoch 2/11\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 5.1734 - leftLayer1_loss: 0.1061 - midLayer1_loss: 1.3257 - rightLayer1_loss: 1.2457 - leftLayer2_loss: 0.0993 - midLayer2_loss: 1.4279 - rightLayer2_loss: 0.9686\n",
      "Epoch 00002: val_loss improved from 5.54907 to 5.09359, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 5.1730 - leftLayer1_loss: 0.1061 - midLayer1_loss: 1.3257 - rightLayer1_loss: 1.2456 - leftLayer2_loss: 0.0993 - midLayer2_loss: 1.4278 - rightLayer2_loss: 0.9685 - val_loss: 5.0936 - val_leftLayer1_loss: 0.1020 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 1.1252 - val_leftLayer2_loss: 0.1014 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 1.0919\n",
      "Epoch 3/11\n",
      "3976/3988 [============================>.] - ETA: 0s - loss: 4.8930 - leftLayer1_loss: 0.0984 - midLayer1_loss: 1.3251 - rightLayer1_loss: 1.0677 - leftLayer2_loss: 0.0836 - midLayer2_loss: 1.4294 - rightLayer2_loss: 0.8887\n",
      "Epoch 00003: val_loss improved from 5.09359 to 4.87599, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.8925 - leftLayer1_loss: 0.0984 - midLayer1_loss: 1.3250 - rightLayer1_loss: 1.0675 - leftLayer2_loss: 0.0836 - midLayer2_loss: 1.4292 - rightLayer2_loss: 0.8887 - val_loss: 4.8760 - val_leftLayer1_loss: 0.0947 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 1.0013 - val_leftLayer2_loss: 0.0913 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 1.0154\n",
      "Epoch 4/11\n",
      "3975/3988 [============================>.] - ETA: 0s - loss: 4.7588 - leftLayer1_loss: 0.0917 - midLayer1_loss: 1.3253 - rightLayer1_loss: 0.9797 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.4327 - rightLayer2_loss: 0.8572\n",
      "Epoch 00004: val_loss improved from 4.87599 to 4.75287, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.7585 - leftLayer1_loss: 0.0917 - midLayer1_loss: 1.3252 - rightLayer1_loss: 0.9796 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.4327 - rightLayer2_loss: 0.8572 - val_loss: 4.7529 - val_leftLayer1_loss: 0.0884 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.9355 - val_leftLayer2_loss: 0.0836 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.9722\n",
      "Epoch 5/11\n",
      "3970/3988 [============================>.] - ETA: 0s - loss: 4.6780 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.3252 - rightLayer1_loss: 0.9300 - leftLayer2_loss: 0.0640 - midLayer2_loss: 1.4309 - rightLayer2_loss: 0.8423\n",
      "Epoch 00005: val_loss improved from 4.75287 to 4.67360, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6769 - leftLayer1_loss: 0.0857 - midLayer1_loss: 1.3249 - rightLayer1_loss: 0.9296 - leftLayer2_loss: 0.0639 - midLayer2_loss: 1.4309 - rightLayer2_loss: 0.8420 - val_loss: 4.6736 - val_leftLayer1_loss: 0.0828 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8963 - val_leftLayer2_loss: 0.0777 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.9438\n",
      "Epoch 6/11\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 4.6299 - leftLayer1_loss: 0.0806 - midLayer1_loss: 1.3251 - rightLayer1_loss: 0.9005 - leftLayer2_loss: 0.0581 - midLayer2_loss: 1.4334 - rightLayer2_loss: 0.8323\n",
      "Epoch 00006: val_loss improved from 4.67360 to 4.61779, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6292 - leftLayer1_loss: 0.0806 - midLayer1_loss: 1.3249 - rightLayer1_loss: 0.9003 - leftLayer2_loss: 0.0581 - midLayer2_loss: 1.4332 - rightLayer2_loss: 0.8321 - val_loss: 4.6178 - val_leftLayer1_loss: 0.0779 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8707 - val_leftLayer2_loss: 0.0729 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.9232\n",
      "Epoch 7/11\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 4.5905 - leftLayer1_loss: 0.0760 - midLayer1_loss: 1.3257 - rightLayer1_loss: 0.8799 - leftLayer2_loss: 0.0537 - midLayer2_loss: 1.4309 - rightLayer2_loss: 0.8242\n",
      "Epoch 00007: val_loss improved from 4.61779 to 4.57642, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5900 - leftLayer1_loss: 0.0760 - midLayer1_loss: 1.3257 - rightLayer1_loss: 0.8799 - leftLayer2_loss: 0.0537 - midLayer2_loss: 1.4307 - rightLayer2_loss: 0.8241 - val_loss: 4.5764 - val_leftLayer1_loss: 0.0737 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8528 - val_leftLayer2_loss: 0.0691 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.9078\n",
      "Epoch 8/11\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 4.5649 - leftLayer1_loss: 0.0721 - midLayer1_loss: 1.3251 - rightLayer1_loss: 0.8659 - leftLayer2_loss: 0.0504 - midLayer2_loss: 1.4305 - rightLayer2_loss: 0.8209\n",
      "Epoch 00008: val_loss improved from 4.57642 to 4.54404, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5641 - leftLayer1_loss: 0.0721 - midLayer1_loss: 1.3249 - rightLayer1_loss: 0.8657 - leftLayer2_loss: 0.0504 - midLayer2_loss: 1.4303 - rightLayer2_loss: 0.8207 - val_loss: 4.5440 - val_leftLayer1_loss: 0.0699 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8396 - val_leftLayer2_loss: 0.0660 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.8955\n",
      "Epoch 9/11\n",
      "3970/3988 [============================>.] - ETA: 0s - loss: 4.5461 - leftLayer1_loss: 0.0687 - midLayer1_loss: 1.3254 - rightLayer1_loss: 0.8549 - leftLayer2_loss: 0.0479 - midLayer2_loss: 1.4317 - rightLayer2_loss: 0.8175\n",
      "Epoch 00009: val_loss improved from 4.54404 to 4.51794, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5449 - leftLayer1_loss: 0.0687 - midLayer1_loss: 1.3252 - rightLayer1_loss: 0.8546 - leftLayer2_loss: 0.0479 - midLayer2_loss: 1.4315 - rightLayer2_loss: 0.8171 - val_loss: 4.5179 - val_leftLayer1_loss: 0.0666 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8295 - val_leftLayer2_loss: 0.0633 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.8854\n",
      "Epoch 10/11\n",
      "3968/3988 [============================>.] - ETA: 0s - loss: 4.5320 - leftLayer1_loss: 0.0656 - midLayer1_loss: 1.3256 - rightLayer1_loss: 0.8467 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.4341 - rightLayer2_loss: 0.8141\n",
      "Epoch 00010: val_loss improved from 4.51794 to 4.49644, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5306 - leftLayer1_loss: 0.0656 - midLayer1_loss: 1.3253 - rightLayer1_loss: 0.8465 - leftLayer2_loss: 0.0459 - midLayer2_loss: 1.4335 - rightLayer2_loss: 0.8138 - val_loss: 4.4964 - val_leftLayer1_loss: 0.0637 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8216 - val_leftLayer2_loss: 0.0611 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.8769\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3975/3988 [============================>.] - ETA: 0s - loss: 4.5104 - leftLayer1_loss: 0.0629 - midLayer1_loss: 1.3257 - rightLayer1_loss: 0.8392 - leftLayer2_loss: 0.0444 - midLayer2_loss: 1.4266 - rightLayer2_loss: 0.8117\n",
      "Epoch 00011: val_loss improved from 4.49644 to 4.47836, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5103 - leftLayer1_loss: 0.0629 - midLayer1_loss: 1.3255 - rightLayer1_loss: 0.8392 - leftLayer2_loss: 0.0444 - midLayer2_loss: 1.4265 - rightLayer2_loss: 0.8118 - val_loss: 4.4784 - val_leftLayer1_loss: 0.0611 - val_midLayer1_loss: 1.3171 - val_rightLayer1_loss: 0.8152 - val_leftLayer2_loss: 0.0592 - val_midLayer2_loss: 1.3561 - val_rightLayer2_loss: 0.8698\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Mass: 0.5602425526977693\n",
      "\n",
      "auprc 0Mass: 0.061913283631836624\n",
      "\n",
      "auroc 1Mass: 0.3366392766720949\n",
      "\n",
      "auprc 1Mass: 0.03428581279795849\n",
      "\n",
      "auroc 2Mass: 0.5251588288187495\n",
      "\n",
      "auprc 2Mass: 0.05346923996304259\n",
      "\n",
      "auroc 3Mass: 0.6018118833625465\n",
      "\n",
      "auprc 3Mass: 0.06359309577401091\n",
      "\n",
      "auroc 4Mass: 0.29376100675840866\n",
      "\n",
      "auprc 4Mass: 0.03255300158767239\n",
      "\n",
      "auroc 5Mass: 0.44407358833791216\n",
      "\n",
      "auprc 5Mass: 0.041959142267033823\n",
      "\n",
      "mean auroc: 0.46028118944124685\n",
      "\n",
      "mean auprc: 0.04796226267025914\n",
      "\n",
      "max auroc: 0.6018118833625465\n",
      "\n",
      "max auprc: 0.06359309577401091\n",
      "\n",
      "134.1915144920349\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 3988 steps, validate for 625 steps\n",
      "Epoch 1/11\n",
      "3969/3988 [============================>.] - ETA: 0s - loss: 5.9976 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.4204 - rightLayer1_loss: 1.5981 - leftLayer2_loss: 0.1124 - midLayer2_loss: 1.4063 - rightLayer2_loss: 1.3376\n",
      "Epoch 00001: val_loss improved from inf to 5.57472, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 11s 3ms/step - loss: 5.9943 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.4205 - rightLayer1_loss: 1.5968 - leftLayer2_loss: 0.1124 - midLayer2_loss: 1.4060 - rightLayer2_loss: 1.3360 - val_loss: 5.5747 - val_leftLayer1_loss: 0.1170 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 1.3546 - val_leftLayer2_loss: 0.1093 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 1.2764\n",
      "Epoch 2/11\n",
      "3970/3988 [============================>.] - ETA: 0s - loss: 5.2029 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.4205 - rightLayer1_loss: 1.2101 - leftLayer2_loss: 0.0922 - midLayer2_loss: 1.4052 - rightLayer2_loss: 0.9628\n",
      "Epoch 00002: val_loss improved from 5.57472 to 5.12246, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 5.2012 - leftLayer1_loss: 0.1120 - midLayer1_loss: 1.4205 - rightLayer1_loss: 1.2094 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.4048 - rightLayer2_loss: 0.9623 - val_loss: 5.1225 - val_leftLayer1_loss: 0.1070 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 1.0966 - val_leftLayer2_loss: 0.0976 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 1.1039\n",
      "Epoch 3/11\n",
      "3971/3988 [============================>.] - ETA: 0s - loss: 4.9359 - leftLayer1_loss: 0.1027 - midLayer1_loss: 1.4209 - rightLayer1_loss: 1.0380 - leftLayer2_loss: 0.0780 - midLayer2_loss: 1.4121 - rightLayer2_loss: 0.8840\n",
      "Epoch 00003: val_loss improved from 5.12246 to 4.91255, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.9349 - leftLayer1_loss: 0.1027 - midLayer1_loss: 1.4210 - rightLayer1_loss: 1.0376 - leftLayer2_loss: 0.0780 - midLayer2_loss: 1.4119 - rightLayer2_loss: 0.8838 - val_loss: 4.9126 - val_leftLayer1_loss: 0.0983 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.9800 - val_leftLayer2_loss: 0.0886 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 1.0282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "3980/3988 [============================>.] - ETA: 0s - loss: 4.8040 - leftLayer1_loss: 0.0945 - midLayer1_loss: 1.4202 - rightLayer1_loss: 0.9570 - leftLayer2_loss: 0.0681 - midLayer2_loss: 1.4088 - rightLayer2_loss: 0.8553\n",
      "Epoch 00004: val_loss improved from 4.91255 to 4.79372, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.8033 - leftLayer1_loss: 0.0945 - midLayer1_loss: 1.4202 - rightLayer1_loss: 0.9568 - leftLayer2_loss: 0.0681 - midLayer2_loss: 1.4086 - rightLayer2_loss: 0.8552 - val_loss: 4.7937 - val_leftLayer1_loss: 0.0908 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.9194 - val_leftLayer2_loss: 0.0817 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.9843\n",
      "Epoch 5/11\n",
      "3976/3988 [============================>.] - ETA: 0s - loss: 4.7286 - leftLayer1_loss: 0.0876 - midLayer1_loss: 1.4204 - rightLayer1_loss: 0.9130 - leftLayer2_loss: 0.0609 - midLayer2_loss: 1.4070 - rightLayer2_loss: 0.8397\n",
      "Epoch 00005: val_loss improved from 4.79372 to 4.71678, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.7284 - leftLayer1_loss: 0.0875 - midLayer1_loss: 1.4205 - rightLayer1_loss: 0.9129 - leftLayer2_loss: 0.0609 - midLayer2_loss: 1.4068 - rightLayer2_loss: 0.8397 - val_loss: 4.7168 - val_leftLayer1_loss: 0.0844 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8836 - val_leftLayer2_loss: 0.0763 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.9551\n",
      "Epoch 6/11\n",
      "3969/3988 [============================>.] - ETA: 0s - loss: 4.6835 - leftLayer1_loss: 0.0815 - midLayer1_loss: 1.4208 - rightLayer1_loss: 0.8864 - leftLayer2_loss: 0.0559 - midLayer2_loss: 1.4087 - rightLayer2_loss: 0.8301\n",
      "Epoch 00006: val_loss improved from 4.71678 to 4.66246, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6822 - leftLayer1_loss: 0.0815 - midLayer1_loss: 1.4208 - rightLayer1_loss: 0.8861 - leftLayer2_loss: 0.0558 - midLayer2_loss: 1.4082 - rightLayer2_loss: 0.8298 - val_loss: 4.6625 - val_leftLayer1_loss: 0.0788 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8602 - val_leftLayer2_loss: 0.0720 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.9340\n",
      "Epoch 7/11\n",
      "3965/3988 [============================>.] - ETA: 0s - loss: 4.6479 - leftLayer1_loss: 0.0764 - midLayer1_loss: 1.4214 - rightLayer1_loss: 0.8684 - leftLayer2_loss: 0.0518 - midLayer2_loss: 1.4059 - rightLayer2_loss: 0.8240\n",
      "Epoch 00007: val_loss improved from 4.66246 to 4.62165, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6467 - leftLayer1_loss: 0.0764 - midLayer1_loss: 1.4214 - rightLayer1_loss: 0.8680 - leftLayer2_loss: 0.0518 - midLayer2_loss: 1.4053 - rightLayer2_loss: 0.8238 - val_loss: 4.6216 - val_leftLayer1_loss: 0.0740 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8439 - val_leftLayer2_loss: 0.0685 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.9179\n",
      "Epoch 8/11\n",
      "3981/3988 [============================>.] - ETA: 0s - loss: 4.6213 - leftLayer1_loss: 0.0719 - midLayer1_loss: 1.4209 - rightLayer1_loss: 0.8554 - leftLayer2_loss: 0.0491 - midLayer2_loss: 1.4048 - rightLayer2_loss: 0.8193\n",
      "Epoch 00008: val_loss improved from 4.62165 to 4.58967, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6210 - leftLayer1_loss: 0.0719 - midLayer1_loss: 1.4209 - rightLayer1_loss: 0.8553 - leftLayer2_loss: 0.0491 - midLayer2_loss: 1.4046 - rightLayer2_loss: 0.8193 - val_loss: 4.5897 - val_leftLayer1_loss: 0.0698 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8318 - val_leftLayer2_loss: 0.0656 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.9050\n",
      "Epoch 9/11\n",
      "3981/3988 [============================>.] - ETA: 0s - loss: 4.6058 - leftLayer1_loss: 0.0681 - midLayer1_loss: 1.4211 - rightLayer1_loss: 0.8457 - leftLayer2_loss: 0.0465 - midLayer2_loss: 1.4092 - rightLayer2_loss: 0.8153\n",
      "Epoch 00009: val_loss improved from 4.58967 to 4.56398, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.6055 - leftLayer1_loss: 0.0681 - midLayer1_loss: 1.4211 - rightLayer1_loss: 0.8456 - leftLayer2_loss: 0.0465 - midLayer2_loss: 1.4090 - rightLayer2_loss: 0.8152 - val_loss: 4.5640 - val_leftLayer1_loss: 0.0662 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8226 - val_leftLayer2_loss: 0.0631 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.8946\n",
      "Epoch 10/11\n",
      "3981/3988 [============================>.] - ETA: 0s - loss: 4.5918 - leftLayer1_loss: 0.0647 - midLayer1_loss: 1.4213 - rightLayer1_loss: 0.8383 - leftLayer2_loss: 0.0447 - midLayer2_loss: 1.4097 - rightLayer2_loss: 0.8131\n",
      "Epoch 00010: val_loss improved from 4.56398 to 4.54258, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 2ms/step - loss: 4.5917 - leftLayer1_loss: 0.0647 - midLayer1_loss: 1.4213 - rightLayer1_loss: 0.8382 - leftLayer2_loss: 0.0447 - midLayer2_loss: 1.4096 - rightLayer2_loss: 0.8131 - val_loss: 4.5426 - val_leftLayer1_loss: 0.0630 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8153 - val_leftLayer2_loss: 0.0611 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.8858\n",
      "Epoch 11/11\n",
      "3980/3988 [============================>.] - ETA: 0s - loss: 4.5703 - leftLayer1_loss: 0.0619 - midLayer1_loss: 1.4201 - rightLayer1_loss: 0.8322 - leftLayer2_loss: 0.0433 - midLayer2_loss: 1.4024 - rightLayer2_loss: 0.8104\n",
      "Epoch 00011: val_loss improved from 4.54258 to 4.52461, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "3988/3988 [==============================] - 10s 3ms/step - loss: 4.5695 - leftLayer1_loss: 0.0618 - midLayer1_loss: 1.4201 - rightLayer1_loss: 0.8320 - leftLayer2_loss: 0.0433 - midLayer2_loss: 1.4021 - rightLayer2_loss: 0.8102 - val_loss: 4.5246 - val_leftLayer1_loss: 0.0603 - val_midLayer1_loss: 1.4049 - val_rightLayer1_loss: 0.8093 - val_leftLayer2_loss: 0.0593 - val_midLayer2_loss: 1.3126 - val_rightLayer2_loss: 0.8783\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Mass: 0.5545358825503772\n",
      "\n",
      "auprc 0Mass: 0.05796188410237112\n",
      "\n",
      "auroc 1Mass: 0.6067314744601768\n",
      "\n",
      "auprc 1Mass: 0.06662572262500577\n",
      "\n",
      "auroc 2Mass: 0.6118056470627236\n",
      "\n",
      "auprc 2Mass: 0.09476099584284217\n",
      "\n",
      "auroc 3Mass: 0.42899073464026294\n",
      "\n",
      "auprc 3Mass: 0.04295453028924374\n",
      "\n",
      "auroc 4Mass: 0.49644178693816327\n",
      "\n",
      "auprc 4Mass: 0.04871846275293326\n",
      "\n",
      "auroc 5Mass: 0.45292047371016336\n",
      "\n",
      "auprc 5Mass: 0.043168841137139216\n",
      "\n",
      "mean auroc: 0.5252376665603112\n",
      "\n",
      "mean auprc: 0.05903173945825588\n",
      "\n",
      "max auroc: 0.6118056470627236\n",
      "\n",
      "max auprc: 0.09476099584284217\n",
      "\n",
      "136.32161235809326\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565029689759623\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
