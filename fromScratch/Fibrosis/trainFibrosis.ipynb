{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Fibrosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "161: 1158\n",
      "43: 1158\n",
      "126: 1158\n",
      "234: 1158\n",
      "83: 1158\n",
      "114: 1158\n",
      "10: 1158\n",
      "62: 1158\n",
      "57: 1158\n",
      "7: 1158\n",
      "25: 1158\n",
      "1158: 1158\n",
      "113: 1158\n",
      "4: 1158\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1138/1158 [============================>.] - ETA: 0s - loss: 6.4965 - leftLayer1_loss: 0.1307 - midLayer1_loss: 1.3739 - rightLayer1_loss: 1.7747 - leftLayer2_loss: 0.1242 - midLayer2_loss: 1.4363 - rightLayer2_loss: 1.6568\n",
      "Epoch 00001: val_loss improved from inf to 6.21840, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 4s 4ms/step - loss: 6.4925 - leftLayer1_loss: 0.1306 - midLayer1_loss: 1.3746 - rightLayer1_loss: 1.7732 - leftLayer2_loss: 0.1241 - midLayer2_loss: 1.4365 - rightLayer2_loss: 1.6534 - val_loss: 6.2184 - val_leftLayer1_loss: 0.1290 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.6863 - val_leftLayer2_loss: 0.1191 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.5927\n",
      "Epoch 2/11\n",
      "1138/1158 [============================>.] - ETA: 0s - loss: 5.9702 - leftLayer1_loss: 0.1274 - midLayer1_loss: 1.3731 - rightLayer1_loss: 1.6148 - leftLayer2_loss: 0.1157 - midLayer2_loss: 1.4380 - rightLayer2_loss: 1.3012\n",
      "Epoch 00002: val_loss improved from 6.21840 to 5.85033, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.9692 - leftLayer1_loss: 0.1274 - midLayer1_loss: 1.3738 - rightLayer1_loss: 1.6134 - leftLayer2_loss: 0.1157 - midLayer2_loss: 1.4393 - rightLayer2_loss: 1.2996 - val_loss: 5.8503 - val_leftLayer1_loss: 0.1258 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.5321 - val_leftLayer2_loss: 0.1141 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.3871\n",
      "Epoch 3/11\n",
      "1148/1158 [============================>.] - ETA: 0s - loss: 5.6113 - leftLayer1_loss: 0.1243 - midLayer1_loss: 1.3716 - rightLayer1_loss: 1.4731 - leftLayer2_loss: 0.1086 - midLayer2_loss: 1.4357 - rightLayer2_loss: 1.0980\n",
      "Epoch 00003: val_loss improved from 5.85033 to 5.57298, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.6111 - leftLayer1_loss: 0.1243 - midLayer1_loss: 1.3720 - rightLayer1_loss: 1.4727 - leftLayer2_loss: 0.1086 - midLayer2_loss: 1.4354 - rightLayer2_loss: 1.0981 - val_loss: 5.5730 - val_leftLayer1_loss: 0.1227 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.3983 - val_leftLayer2_loss: 0.1094 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.2513\n",
      "Epoch 4/11\n",
      "1153/1158 [============================>.] - ETA: 0s - loss: 5.3627 - leftLayer1_loss: 0.1213 - midLayer1_loss: 1.3725 - rightLayer1_loss: 1.3552 - leftLayer2_loss: 0.1018 - midLayer2_loss: 1.4297 - rightLayer2_loss: 0.9822\n",
      "Epoch 00004: val_loss improved from 5.57298 to 5.36179, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.3652 - leftLayer1_loss: 0.1213 - midLayer1_loss: 1.3729 - rightLayer1_loss: 1.3554 - leftLayer2_loss: 0.1018 - midLayer2_loss: 1.4304 - rightLayer2_loss: 0.9834 - val_loss: 5.3618 - val_leftLayer1_loss: 0.1197 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.2862 - val_leftLayer2_loss: 0.1052 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.1595\n",
      "Epoch 5/11\n",
      "1141/1158 [============================>.] - ETA: 0s - loss: 5.1945 - leftLayer1_loss: 0.1183 - midLayer1_loss: 1.3724 - rightLayer1_loss: 1.2566 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.4336 - rightLayer2_loss: 0.9172\n",
      "Epoch 00005: val_loss improved from 5.36179 to 5.19663, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.1956 - leftLayer1_loss: 0.1183 - midLayer1_loss: 1.3727 - rightLayer1_loss: 1.2561 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.4348 - rightLayer2_loss: 0.9175 - val_loss: 5.1966 - val_leftLayer1_loss: 0.1168 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.1939 - val_leftLayer2_loss: 0.1012 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "1141/1158 [============================>.] - ETA: 0s - loss: 5.0685 - leftLayer1_loss: 0.1154 - midLayer1_loss: 1.3741 - rightLayer1_loss: 1.1771 - leftLayer2_loss: 0.0900 - midLayer2_loss: 1.4374 - rightLayer2_loss: 0.8745\n",
      "Epoch 00006: val_loss improved from 5.19663 to 5.06580, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.0694 - leftLayer1_loss: 0.1154 - midLayer1_loss: 1.3747 - rightLayer1_loss: 1.1769 - leftLayer2_loss: 0.0900 - midLayer2_loss: 1.4373 - rightLayer2_loss: 0.8751 - val_loss: 5.0658 - val_leftLayer1_loss: 0.1139 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.1186 - val_leftLayer2_loss: 0.0976 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.0445\n",
      "Epoch 7/11\n",
      "1140/1158 [============================>.] - ETA: 0s - loss: 4.9630 - leftLayer1_loss: 0.1127 - midLayer1_loss: 1.3726 - rightLayer1_loss: 1.1130 - leftLayer2_loss: 0.0852 - midLayer2_loss: 1.4348 - rightLayer2_loss: 0.8447\n",
      "Epoch 00007: val_loss improved from 5.06580 to 4.96034, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.9653 - leftLayer1_loss: 0.1127 - midLayer1_loss: 1.3734 - rightLayer1_loss: 1.1130 - leftLayer2_loss: 0.0852 - midLayer2_loss: 1.4351 - rightLayer2_loss: 0.8460 - val_loss: 4.9603 - val_leftLayer1_loss: 0.1112 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.0574 - val_leftLayer2_loss: 0.0942 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 1.0063\n",
      "Epoch 8/11\n",
      "1144/1158 [============================>.] - ETA: 0s - loss: 4.8806 - leftLayer1_loss: 0.1101 - midLayer1_loss: 1.3722 - rightLayer1_loss: 1.0622 - leftLayer2_loss: 0.0807 - midLayer2_loss: 1.4312 - rightLayer2_loss: 0.8243\n",
      "Epoch 00008: val_loss improved from 4.96034 to 4.87403, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.8824 - leftLayer1_loss: 0.1100 - midLayer1_loss: 1.3726 - rightLayer1_loss: 1.0621 - leftLayer2_loss: 0.0807 - midLayer2_loss: 1.4321 - rightLayer2_loss: 0.8248 - val_loss: 4.8740 - val_leftLayer1_loss: 0.1086 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 1.0072 - val_leftLayer2_loss: 0.0911 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 0.9759\n",
      "Epoch 9/11\n",
      "1139/1158 [============================>.] - ETA: 0s - loss: 4.8130 - leftLayer1_loss: 0.1075 - midLayer1_loss: 1.3728 - rightLayer1_loss: 1.0198 - leftLayer2_loss: 0.0768 - midLayer2_loss: 1.4291 - rightLayer2_loss: 0.8070\n",
      "Epoch 00009: val_loss improved from 4.87403 to 4.80231, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.8161 - leftLayer1_loss: 0.1075 - midLayer1_loss: 1.3734 - rightLayer1_loss: 1.0202 - leftLayer2_loss: 0.0768 - midLayer2_loss: 1.4297 - rightLayer2_loss: 0.8085 - val_loss: 4.8023 - val_leftLayer1_loss: 0.1060 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.9659 - val_leftLayer2_loss: 0.0882 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 0.9509\n",
      "Epoch 10/11\n",
      "1147/1158 [============================>.] - ETA: 0s - loss: 4.7642 - leftLayer1_loss: 0.1050 - midLayer1_loss: 1.3744 - rightLayer1_loss: 0.9850 - leftLayer2_loss: 0.0732 - midLayer2_loss: 1.4324 - rightLayer2_loss: 0.7941\n",
      "Epoch 00010: val_loss improved from 4.80231 to 4.74186, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7655 - leftLayer1_loss: 0.1050 - midLayer1_loss: 1.3747 - rightLayer1_loss: 0.9853 - leftLayer2_loss: 0.0732 - midLayer2_loss: 1.4324 - rightLayer2_loss: 0.7950 - val_loss: 4.7419 - val_leftLayer1_loss: 0.1035 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.9315 - val_leftLayer2_loss: 0.0856 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 0.9300\n",
      "Epoch 11/11\n",
      "1145/1158 [============================>.] - ETA: 0s - loss: 4.7268 - leftLayer1_loss: 0.1027 - midLayer1_loss: 1.3743 - rightLayer1_loss: 0.9572 - leftLayer2_loss: 0.0700 - midLayer2_loss: 1.4378 - rightLayer2_loss: 0.7847\n",
      "Epoch 00011: val_loss improved from 4.74186 to 4.69029, saving model to ./experiments/0.009_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7272 - leftLayer1_loss: 0.1027 - midLayer1_loss: 1.3745 - rightLayer1_loss: 0.9576 - leftLayer2_loss: 0.0700 - midLayer2_loss: 1.4372 - rightLayer2_loss: 0.7852 - val_loss: 4.6903 - val_leftLayer1_loss: 0.1012 - val_midLayer1_loss: 1.3478 - val_rightLayer1_loss: 0.9026 - val_leftLayer2_loss: 0.0831 - val_midLayer2_loss: 1.3434 - val_rightLayer2_loss: 0.9121\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Fibrosis: 0.35754637657324395\n",
      "\n",
      "auprc 0Fibrosis: 0.011319035068738376\n",
      "\n",
      "auroc 1Fibrosis: 0.5756496299861997\n",
      "\n",
      "auprc 1Fibrosis: 0.019839765892741876\n",
      "\n",
      "auroc 2Fibrosis: 0.40870410435833526\n",
      "\n",
      "auprc 2Fibrosis: 0.012449037893171458\n",
      "\n",
      "auroc 3Fibrosis: 0.516227388706112\n",
      "\n",
      "auprc 3Fibrosis: 0.019107467823903417\n",
      "\n",
      "auroc 4Fibrosis: 0.30421891830258496\n",
      "\n",
      "auprc 4Fibrosis: 0.010378567721506471\n",
      "\n",
      "auroc 5Fibrosis: 0.5237363045580422\n",
      "\n",
      "auprc 5Fibrosis: 0.019112236456671487\n",
      "\n",
      "mean auroc: 0.4476804537474197\n",
      "\n",
      "mean auprc: 0.015367685142788847\n",
      "\n",
      "max auroc: 0.5756496299861997\n",
      "\n",
      "max auprc: 0.019839765892741876\n",
      "\n",
      "62.36223244667053\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1145/1158 [============================>.] - ETA: 0s - loss: 6.3521 - leftLayer1_loss: 0.1329 - midLayer1_loss: 1.2838 - rightLayer1_loss: 1.7865 - leftLayer2_loss: 0.1228 - midLayer2_loss: 1.3742 - rightLayer2_loss: 1.6518\n",
      "Epoch 00001: val_loss improved from inf to 6.10411, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 4s 3ms/step - loss: 6.3493 - leftLayer1_loss: 0.1329 - midLayer1_loss: 1.2840 - rightLayer1_loss: 1.7856 - leftLayer2_loss: 0.1228 - midLayer2_loss: 1.3744 - rightLayer2_loss: 1.6497 - val_loss: 6.1041 - val_leftLayer1_loss: 0.1313 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.6975 - val_leftLayer2_loss: 0.1168 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.5925\n",
      "Epoch 2/11\n",
      "1144/1158 [============================>.] - ETA: 0s - loss: 5.8396 - leftLayer1_loss: 0.1294 - midLayer1_loss: 1.2840 - rightLayer1_loss: 1.6242 - leftLayer2_loss: 0.1150 - midLayer2_loss: 1.3762 - rightLayer2_loss: 1.3110\n",
      "Epoch 00002: val_loss improved from 6.10411 to 5.74105, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.8379 - leftLayer1_loss: 0.1294 - midLayer1_loss: 1.2842 - rightLayer1_loss: 1.6233 - leftLayer2_loss: 0.1150 - midLayer2_loss: 1.3764 - rightLayer2_loss: 1.3097 - val_loss: 5.7411 - val_leftLayer1_loss: 0.1279 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.5391 - val_leftLayer2_loss: 0.1121 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.3959\n",
      "Epoch 3/11\n",
      "1135/1158 [============================>.] - ETA: 0s - loss: 5.4832 - leftLayer1_loss: 0.1262 - midLayer1_loss: 1.2841 - rightLayer1_loss: 1.4810 - leftLayer2_loss: 0.1079 - midLayer2_loss: 1.3725 - rightLayer2_loss: 1.1116\n",
      "Epoch 00003: val_loss improved from 5.74105 to 5.46350, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.4825 - leftLayer1_loss: 0.1262 - midLayer1_loss: 1.2846 - rightLayer1_loss: 1.4800 - leftLayer2_loss: 0.1079 - midLayer2_loss: 1.3733 - rightLayer2_loss: 1.1106 - val_loss: 5.4635 - val_leftLayer1_loss: 0.1246 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.4021 - val_leftLayer2_loss: 0.1078 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.2629\n",
      "Epoch 4/11\n",
      "1156/1158 [============================>.] - ETA: 0s - loss: 5.2330 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.2848 - rightLayer1_loss: 1.3576 - leftLayer2_loss: 0.1014 - midLayer2_loss: 1.3717 - rightLayer2_loss: 0.9943\n",
      "Epoch 00004: val_loss improved from 5.46350 to 5.25034, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.2342 - leftLayer1_loss: 0.1232 - midLayer1_loss: 1.2851 - rightLayer1_loss: 1.3578 - leftLayer2_loss: 0.1014 - midLayer2_loss: 1.3719 - rightLayer2_loss: 0.9949 - val_loss: 5.2503 - val_leftLayer1_loss: 0.1215 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.2874 - val_leftLayer2_loss: 0.1038 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.1716\n",
      "Epoch 5/11\n",
      "1153/1158 [============================>.] - ETA: 0s - loss: 5.0616 - leftLayer1_loss: 0.1200 - midLayer1_loss: 1.2851 - rightLayer1_loss: 1.2586 - leftLayer2_loss: 0.0958 - midLayer2_loss: 1.3782 - rightLayer2_loss: 0.9239\n",
      "Epoch 00005: val_loss improved from 5.25034 to 5.08456, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.0647 - leftLayer1_loss: 0.1200 - midLayer1_loss: 1.2855 - rightLayer1_loss: 1.2590 - leftLayer2_loss: 0.0958 - midLayer2_loss: 1.3793 - rightLayer2_loss: 0.9251 - val_loss: 5.0846 - val_leftLayer1_loss: 0.1184 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.1934 - val_leftLayer2_loss: 0.1001 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.1067\n",
      "Epoch 6/11\n",
      "1149/1158 [============================>.] - ETA: 0s - loss: 4.9227 - leftLayer1_loss: 0.1170 - midLayer1_loss: 1.2849 - rightLayer1_loss: 1.1779 - leftLayer2_loss: 0.0903 - midLayer2_loss: 1.3697 - rightLayer2_loss: 0.8829\n",
      "Epoch 00006: val_loss improved from 5.08456 to 4.95273, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.9246 - leftLayer1_loss: 0.1170 - midLayer1_loss: 1.2852 - rightLayer1_loss: 1.1783 - leftLayer2_loss: 0.0903 - midLayer2_loss: 1.3696 - rightLayer2_loss: 0.8842 - val_loss: 4.9527 - val_leftLayer1_loss: 0.1154 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.1171 - val_leftLayer2_loss: 0.0966 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.0576\n",
      "Epoch 7/11\n",
      "1145/1158 [============================>.] - ETA: 0s - loss: 4.8139 - leftLayer1_loss: 0.1143 - midLayer1_loss: 1.2851 - rightLayer1_loss: 1.1123 - leftLayer2_loss: 0.0850 - midLayer2_loss: 1.3678 - rightLayer2_loss: 0.8494\n",
      "Epoch 00007: val_loss improved from 4.95273 to 4.84643, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.8153 - leftLayer1_loss: 0.1143 - midLayer1_loss: 1.2853 - rightLayer1_loss: 1.1124 - leftLayer2_loss: 0.0850 - midLayer2_loss: 1.3685 - rightLayer2_loss: 0.8498 - val_loss: 4.8464 - val_leftLayer1_loss: 0.1126 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.0550 - val_leftLayer2_loss: 0.0935 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 1.0194\n",
      "Epoch 8/11\n",
      "1149/1158 [============================>.] - ETA: 0s - loss: 4.7415 - leftLayer1_loss: 0.1115 - midLayer1_loss: 1.2849 - rightLayer1_loss: 1.0601 - leftLayer2_loss: 0.0808 - midLayer2_loss: 1.3776 - rightLayer2_loss: 0.8265\n",
      "Epoch 00008: val_loss improved from 4.84643 to 4.75954, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7443 - leftLayer1_loss: 0.1115 - midLayer1_loss: 1.2851 - rightLayer1_loss: 1.0608 - leftLayer2_loss: 0.0809 - midLayer2_loss: 1.3780 - rightLayer2_loss: 0.8281 - val_loss: 4.7595 - val_leftLayer1_loss: 0.1098 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 1.0043 - val_leftLayer2_loss: 0.0905 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 0.9888\n",
      "Epoch 9/11\n",
      "1146/1158 [============================>.] - ETA: 0s - loss: 4.6795 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.2856 - rightLayer1_loss: 1.0162 - leftLayer2_loss: 0.0774 - midLayer2_loss: 1.3797 - rightLayer2_loss: 0.8118\n",
      "Epoch 00009: val_loss improved from 4.75954 to 4.68693, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.6826 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.2859 - rightLayer1_loss: 1.0169 - leftLayer2_loss: 0.0774 - midLayer2_loss: 1.3804 - rightLayer2_loss: 0.8131 - val_loss: 4.6869 - val_leftLayer1_loss: 0.1072 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 0.9627 - val_leftLayer2_loss: 0.0878 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 0.9633\n",
      "Epoch 10/11\n",
      "1153/1158 [============================>.] - ETA: 0s - loss: 4.6167 - leftLayer1_loss: 0.1063 - midLayer1_loss: 1.2846 - rightLayer1_loss: 0.9805 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3725 - rightLayer2_loss: 0.7989\n",
      "Epoch 00010: val_loss improved from 4.68693 to 4.62570, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.6204 - leftLayer1_loss: 0.1063 - midLayer1_loss: 1.2850 - rightLayer1_loss: 0.9815 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3729 - rightLayer2_loss: 0.8007 - val_loss: 4.6257 - val_leftLayer1_loss: 0.1046 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 0.9281 - val_leftLayer2_loss: 0.0853 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 0.9418\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1158 [============================>.] - ETA: 0s - loss: 4.5719 - leftLayer1_loss: 0.1038 - midLayer1_loss: 1.2835 - rightLayer1_loss: 0.9522 - leftLayer2_loss: 0.0705 - midLayer2_loss: 1.3770 - rightLayer2_loss: 0.7849\n",
      "Epoch 00011: val_loss improved from 4.62570 to 4.57383, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.5741 - leftLayer1_loss: 0.1038 - midLayer1_loss: 1.2837 - rightLayer1_loss: 0.9531 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.7863 - val_loss: 4.5738 - val_leftLayer1_loss: 0.1021 - val_midLayer1_loss: 1.2677 - val_rightLayer1_loss: 0.8991 - val_leftLayer2_loss: 0.0829 - val_midLayer2_loss: 1.2983 - val_rightLayer2_loss: 0.9237\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Fibrosis: 0.6160819264598354\n",
      "\n",
      "auprc 0Fibrosis: 0.022220813466176076\n",
      "\n",
      "auroc 1Fibrosis: 0.479039518620344\n",
      "\n",
      "auprc 1Fibrosis: 0.015231086117729494\n",
      "\n",
      "auroc 2Fibrosis: 0.5423272357341988\n",
      "\n",
      "auprc 2Fibrosis: 0.021150477843869833\n",
      "\n",
      "auroc 3Fibrosis: 0.40880761259931847\n",
      "\n",
      "auprc 3Fibrosis: 0.015004306850952226\n",
      "\n",
      "auroc 4Fibrosis: 0.27316337956033904\n",
      "\n",
      "auprc 4Fibrosis: 0.009955885973820688\n",
      "\n",
      "auroc 5Fibrosis: 0.41071750861296197\n",
      "\n",
      "auprc 5Fibrosis: 0.015682087655406813\n",
      "\n",
      "mean auroc: 0.4550228635978329\n",
      "\n",
      "mean auprc: 0.01654077631799252\n",
      "\n",
      "max auroc: 0.6160819264598354\n",
      "\n",
      "max auprc: 0.022220813466176076\n",
      "\n",
      "62.0655460357666\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1147/1158 [============================>.] - ETA: 0s - loss: 6.4267 - leftLayer1_loss: 0.1200 - midLayer1_loss: 1.3472 - rightLayer1_loss: 1.7590 - leftLayer2_loss: 0.1194 - midLayer2_loss: 1.4306 - rightLayer2_loss: 1.6506\n",
      "Epoch 00001: val_loss improved from inf to 6.15695, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 4s 3ms/step - loss: 6.4249 - leftLayer1_loss: 0.1199 - midLayer1_loss: 1.3476 - rightLayer1_loss: 1.7583 - leftLayer2_loss: 0.1193 - midLayer2_loss: 1.4308 - rightLayer2_loss: 1.6489 - val_loss: 6.1570 - val_leftLayer1_loss: 0.1186 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.6728 - val_leftLayer2_loss: 0.1165 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 1.5714\n",
      "Epoch 2/11\n",
      "1137/1158 [============================>.] - ETA: 0s - loss: 5.9015 - leftLayer1_loss: 0.1172 - midLayer1_loss: 1.3481 - rightLayer1_loss: 1.6054 - leftLayer2_loss: 0.1118 - midLayer2_loss: 1.4298 - rightLayer2_loss: 1.2893\n",
      "Epoch 00002: val_loss improved from 6.15695 to 5.78501, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.9009 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.3490 - rightLayer1_loss: 1.6041 - leftLayer2_loss: 0.1117 - midLayer2_loss: 1.4318 - rightLayer2_loss: 1.2872 - val_loss: 5.7850 - val_leftLayer1_loss: 0.1157 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.5228 - val_leftLayer2_loss: 0.1113 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 1.3575\n",
      "Epoch 3/11\n",
      "1149/1158 [============================>.] - ETA: 0s - loss: 5.5344 - leftLayer1_loss: 0.1143 - midLayer1_loss: 1.3469 - rightLayer1_loss: 1.4682 - leftLayer2_loss: 0.1046 - midLayer2_loss: 1.4201 - rightLayer2_loss: 1.0803\n",
      "Epoch 00003: val_loss improved from 5.78501 to 5.51010, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.5357 - leftLayer1_loss: 0.1143 - midLayer1_loss: 1.3476 - rightLayer1_loss: 1.4681 - leftLayer2_loss: 0.1046 - midLayer2_loss: 1.4204 - rightLayer2_loss: 1.0806 - val_loss: 5.5101 - val_leftLayer1_loss: 0.1130 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.3929 - val_leftLayer2_loss: 0.1065 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 1.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1143/1158 [============================>.] - ETA: 0s - loss: 5.3102 - leftLayer1_loss: 0.1117 - midLayer1_loss: 1.3462 - rightLayer1_loss: 1.3530 - leftLayer2_loss: 0.0973 - midLayer2_loss: 1.4291 - rightLayer2_loss: 0.9729\n",
      "Epoch 00004: val_loss improved from 5.51010 to 5.30268, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.3095 - leftLayer1_loss: 0.1116 - midLayer1_loss: 1.3469 - rightLayer1_loss: 1.3524 - leftLayer2_loss: 0.0973 - midLayer2_loss: 1.4284 - rightLayer2_loss: 0.9729 - val_loss: 5.3027 - val_leftLayer1_loss: 0.1103 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.2837 - val_leftLayer2_loss: 0.1021 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 1.1289\n",
      "Epoch 5/11\n",
      "1155/1158 [============================>.] - ETA: 0s - loss: 5.1376 - leftLayer1_loss: 0.1091 - midLayer1_loss: 1.3491 - rightLayer1_loss: 1.2571 - leftLayer2_loss: 0.0913 - midLayer2_loss: 1.4265 - rightLayer2_loss: 0.9045\n",
      "Epoch 00005: val_loss improved from 5.30268 to 5.14266, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.1395 - leftLayer1_loss: 0.1091 - midLayer1_loss: 1.3495 - rightLayer1_loss: 1.2573 - leftLayer2_loss: 0.0913 - midLayer2_loss: 1.4271 - rightLayer2_loss: 0.9052 - val_loss: 5.1427 - val_leftLayer1_loss: 0.1077 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.1938 - val_leftLayer2_loss: 0.0981 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 1.0653\n",
      "Epoch 6/11\n",
      "1149/1158 [============================>.] - ETA: 0s - loss: 5.0049 - leftLayer1_loss: 0.1067 - midLayer1_loss: 1.3466 - rightLayer1_loss: 1.1794 - leftLayer2_loss: 0.0862 - midLayer2_loss: 1.4258 - rightLayer2_loss: 0.8603\n",
      "Epoch 00006: val_loss improved from 5.14266 to 5.01587, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.0076 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.3474 - rightLayer1_loss: 1.1797 - leftLayer2_loss: 0.0862 - midLayer2_loss: 1.4263 - rightLayer2_loss: 0.8614 - val_loss: 5.0159 - val_leftLayer1_loss: 0.1052 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.1203 - val_leftLayer2_loss: 0.0943 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 1.0182\n",
      "Epoch 7/11\n",
      "1147/1158 [============================>.] - ETA: 0s - loss: 4.9070 - leftLayer1_loss: 0.1043 - midLayer1_loss: 1.3470 - rightLayer1_loss: 1.1171 - leftLayer2_loss: 0.0811 - midLayer2_loss: 1.4220 - rightLayer2_loss: 0.8354\n",
      "Epoch 00007: val_loss improved from 5.01587 to 4.91360, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.9091 - leftLayer1_loss: 0.1043 - midLayer1_loss: 1.3475 - rightLayer1_loss: 1.1173 - leftLayer2_loss: 0.0812 - midLayer2_loss: 1.4226 - rightLayer2_loss: 0.8362 - val_loss: 4.9136 - val_leftLayer1_loss: 0.1028 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.0603 - val_leftLayer2_loss: 0.0910 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 0.9818\n",
      "Epoch 8/11\n",
      "1144/1158 [============================>.] - ETA: 0s - loss: 4.8411 - leftLayer1_loss: 0.1021 - midLayer1_loss: 1.3480 - rightLayer1_loss: 1.0660 - leftLayer2_loss: 0.0769 - midLayer2_loss: 1.4336 - rightLayer2_loss: 0.8145\n",
      "Epoch 00008: val_loss improved from 4.91360 to 4.82973, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.8436 - leftLayer1_loss: 0.1021 - midLayer1_loss: 1.3488 - rightLayer1_loss: 1.0662 - leftLayer2_loss: 0.0769 - midLayer2_loss: 1.4345 - rightLayer2_loss: 0.8151 - val_loss: 4.8297 - val_leftLayer1_loss: 0.1005 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 1.0110 - val_leftLayer2_loss: 0.0879 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 0.9526\n",
      "Epoch 9/11\n",
      "1146/1158 [============================>.] - ETA: 0s - loss: 4.7761 - leftLayer1_loss: 0.0998 - midLayer1_loss: 1.3477 - rightLayer1_loss: 1.0228 - leftLayer2_loss: 0.0732 - midLayer2_loss: 1.4322 - rightLayer2_loss: 0.8005\n",
      "Epoch 00009: val_loss improved from 4.82973 to 4.75974, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7798 - leftLayer1_loss: 0.0998 - midLayer1_loss: 1.3484 - rightLayer1_loss: 1.0235 - leftLayer2_loss: 0.0732 - midLayer2_loss: 1.4331 - rightLayer2_loss: 0.8019 - val_loss: 4.7597 - val_leftLayer1_loss: 0.0983 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 0.9702 - val_leftLayer2_loss: 0.0850 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 0.9285\n",
      "Epoch 10/11\n",
      "1148/1158 [============================>.] - ETA: 0s - loss: 4.7213 - leftLayer1_loss: 0.0976 - midLayer1_loss: 1.3471 - rightLayer1_loss: 0.9882 - leftLayer2_loss: 0.0697 - midLayer2_loss: 1.4275 - rightLayer2_loss: 0.7912\n",
      "Epoch 00010: val_loss improved from 4.75974 to 4.70070, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7240 - leftLayer1_loss: 0.0976 - midLayer1_loss: 1.3478 - rightLayer1_loss: 0.9889 - leftLayer2_loss: 0.0697 - midLayer2_loss: 1.4276 - rightLayer2_loss: 0.7925 - val_loss: 4.7007 - val_leftLayer1_loss: 0.0961 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 0.9362 - val_leftLayer2_loss: 0.0824 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 0.9083\n",
      "Epoch 11/11\n",
      "1150/1158 [============================>.] - ETA: 0s - loss: 4.6743 - leftLayer1_loss: 0.0955 - midLayer1_loss: 1.3474 - rightLayer1_loss: 0.9603 - leftLayer2_loss: 0.0670 - midLayer2_loss: 1.4235 - rightLayer2_loss: 0.7805\n",
      "Epoch 00011: val_loss improved from 4.70070 to 4.65017, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.6785 - leftLayer1_loss: 0.0955 - midLayer1_loss: 1.3482 - rightLayer1_loss: 0.9612 - leftLayer2_loss: 0.0670 - midLayer2_loss: 1.4245 - rightLayer2_loss: 0.7821 - val_loss: 4.6502 - val_leftLayer1_loss: 0.0941 - val_midLayer1_loss: 1.3236 - val_rightLayer1_loss: 0.9074 - val_leftLayer2_loss: 0.0800 - val_midLayer2_loss: 1.3542 - val_rightLayer2_loss: 0.8909\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Fibrosis: 0.42907551495662793\n",
      "\n",
      "auprc 0Fibrosis: 0.013057181241620693\n",
      "\n",
      "auroc 1Fibrosis: 0.5141897031954383\n",
      "\n",
      "auprc 1Fibrosis: 0.016885496390690122\n",
      "\n",
      "auroc 2Fibrosis: 0.5334053760703465\n",
      "\n",
      "auprc 2Fibrosis: 0.023728364673908243\n",
      "\n",
      "auroc 3Fibrosis: 0.5847684932429269\n",
      "\n",
      "auprc 3Fibrosis: 0.02139882466394656\n",
      "\n",
      "auroc 4Fibrosis: 0.3725996914528227\n",
      "\n",
      "auprc 4Fibrosis: 0.01168483456862256\n",
      "\n",
      "auroc 5Fibrosis: 0.5792382494365872\n",
      "\n",
      "auprc 5Fibrosis: 0.021443407790073952\n",
      "\n",
      "mean auroc: 0.502212838059125\n",
      "\n",
      "mean auprc: 0.018033018221477022\n",
      "\n",
      "max auroc: 0.5847684932429269\n",
      "\n",
      "max auprc: 0.023728364673908243\n",
      "\n",
      "61.683185338974\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1136/1158 [============================>.] - ETA: 0s - loss: 6.5128 - leftLayer1_loss: 0.1268 - midLayer1_loss: 1.3546 - rightLayer1_loss: 1.7730 - leftLayer2_loss: 0.1280 - midLayer2_loss: 1.4538 - rightLayer2_loss: 1.6767\n",
      "Epoch 00001: val_loss improved from inf to 6.26504, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 4s 3ms/step - loss: 6.5106 - leftLayer1_loss: 0.1268 - midLayer1_loss: 1.3557 - rightLayer1_loss: 1.7714 - leftLayer2_loss: 0.1280 - midLayer2_loss: 1.4554 - rightLayer2_loss: 1.6734 - val_loss: 6.2650 - val_leftLayer1_loss: 0.1252 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.6801 - val_leftLayer2_loss: 0.1234 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.6419\n",
      "Epoch 2/11\n",
      "1139/1158 [============================>.] - ETA: 0s - loss: 5.9895 - leftLayer1_loss: 0.1235 - midLayer1_loss: 1.3535 - rightLayer1_loss: 1.6013 - leftLayer2_loss: 0.1201 - midLayer2_loss: 1.4530 - rightLayer2_loss: 1.3380\n",
      "Epoch 00002: val_loss improved from 6.26504 to 5.89933, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.9890 - leftLayer1_loss: 0.1235 - midLayer1_loss: 1.3546 - rightLayer1_loss: 1.6001 - leftLayer2_loss: 0.1201 - midLayer2_loss: 1.4540 - rightLayer2_loss: 1.3367 - val_loss: 5.8993 - val_leftLayer1_loss: 0.1219 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.5157 - val_leftLayer2_loss: 0.1188 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.4486\n",
      "Epoch 3/11\n",
      "1142/1158 [============================>.] - ETA: 0s - loss: 5.6254 - leftLayer1_loss: 0.1203 - midLayer1_loss: 1.3539 - rightLayer1_loss: 1.4522 - leftLayer2_loss: 0.1131 - midLayer2_loss: 1.4513 - rightLayer2_loss: 1.1346\n",
      "Epoch 00003: val_loss improved from 5.89933 to 5.61624, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.6248 - leftLayer1_loss: 0.1202 - midLayer1_loss: 1.3546 - rightLayer1_loss: 1.4516 - leftLayer2_loss: 0.1130 - midLayer2_loss: 1.4511 - rightLayer2_loss: 1.1343 - val_loss: 5.6162 - val_leftLayer1_loss: 0.1187 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.3752 - val_leftLayer2_loss: 0.1145 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.3135\n",
      "Epoch 4/11\n",
      "1144/1158 [============================>.] - ETA: 0s - loss: 5.3706 - leftLayer1_loss: 0.1172 - midLayer1_loss: 1.3552 - rightLayer1_loss: 1.3294 - leftLayer2_loss: 0.1063 - midLayer2_loss: 1.4519 - rightLayer2_loss: 1.0106\n",
      "Epoch 00004: val_loss improved from 5.61624 to 5.39976, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.3720 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.3559 - rightLayer1_loss: 1.3291 - leftLayer2_loss: 0.1063 - midLayer2_loss: 1.4531 - rightLayer2_loss: 1.0106 - val_loss: 5.3998 - val_leftLayer1_loss: 0.1157 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.2596 - val_leftLayer2_loss: 0.1104 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.2197\n",
      "Epoch 5/11\n",
      "1147/1158 [============================>.] - ETA: 0s - loss: 5.1904 - leftLayer1_loss: 0.1141 - midLayer1_loss: 1.3543 - rightLayer1_loss: 1.2284 - leftLayer2_loss: 0.1009 - midLayer2_loss: 1.4556 - rightLayer2_loss: 0.9370\n",
      "Epoch 00005: val_loss improved from 5.39976 to 5.23157, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.1918 - leftLayer1_loss: 0.1141 - midLayer1_loss: 1.3546 - rightLayer1_loss: 1.2285 - leftLayer2_loss: 0.1009 - midLayer2_loss: 1.4561 - rightLayer2_loss: 0.9375 - val_loss: 5.2316 - val_leftLayer1_loss: 0.1127 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.1661 - val_leftLayer2_loss: 0.1066 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.1518\n",
      "Epoch 6/11\n",
      "1145/1158 [============================>.] - ETA: 0s - loss: 5.0507 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.3543 - rightLayer1_loss: 1.1503 - leftLayer2_loss: 0.0949 - midLayer2_loss: 1.4508 - rightLayer2_loss: 0.8891\n",
      "Epoch 00006: val_loss improved from 5.23157 to 5.09910, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.0520 - leftLayer1_loss: 0.1113 - midLayer1_loss: 1.3548 - rightLayer1_loss: 1.1503 - leftLayer2_loss: 0.0948 - midLayer2_loss: 1.4513 - rightLayer2_loss: 0.8894 - val_loss: 5.0991 - val_leftLayer1_loss: 0.1098 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.0911 - val_leftLayer2_loss: 0.1031 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.1008\n",
      "Epoch 7/11\n",
      "1142/1158 [============================>.] - ETA: 0s - loss: 4.9549 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.3541 - rightLayer1_loss: 1.0862 - leftLayer2_loss: 0.0904 - midLayer2_loss: 1.4556 - rightLayer2_loss: 0.8600\n",
      "Epoch 00007: val_loss improved from 5.09910 to 4.99240, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.9573 - leftLayer1_loss: 0.1084 - midLayer1_loss: 1.3551 - rightLayer1_loss: 1.0864 - leftLayer2_loss: 0.0904 - midLayer2_loss: 1.4562 - rightLayer2_loss: 0.8608 - val_loss: 4.9924 - val_leftLayer1_loss: 0.1070 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 1.0308 - val_leftLayer2_loss: 0.0998 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.0605\n",
      "Epoch 8/11\n",
      "1140/1158 [============================>.] - ETA: 0s - loss: 4.8725 - leftLayer1_loss: 0.1057 - midLayer1_loss: 1.3525 - rightLayer1_loss: 1.0361 - leftLayer2_loss: 0.0857 - midLayer2_loss: 1.4579 - rightLayer2_loss: 0.8345\n",
      "Epoch 00008: val_loss improved from 4.99240 to 4.90545, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.8763 - leftLayer1_loss: 0.1057 - midLayer1_loss: 1.3535 - rightLayer1_loss: 1.0366 - leftLayer2_loss: 0.0856 - midLayer2_loss: 1.4586 - rightLayer2_loss: 0.8362 - val_loss: 4.9054 - val_leftLayer1_loss: 0.1044 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 0.9819 - val_leftLayer2_loss: 0.0967 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.0281\n",
      "Epoch 9/11\n",
      "1142/1158 [============================>.] - ETA: 0s - loss: 4.8038 - leftLayer1_loss: 0.1032 - midLayer1_loss: 1.3547 - rightLayer1_loss: 0.9955 - leftLayer2_loss: 0.0816 - midLayer2_loss: 1.4504 - rightLayer2_loss: 0.8184\n",
      "Epoch 00009: val_loss improved from 4.90545 to 4.83314, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.8077 - leftLayer1_loss: 0.1032 - midLayer1_loss: 1.3556 - rightLayer1_loss: 0.9959 - leftLayer2_loss: 0.0816 - midLayer2_loss: 1.4522 - rightLayer2_loss: 0.8192 - val_loss: 4.8331 - val_leftLayer1_loss: 0.1018 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 0.9419 - val_leftLayer2_loss: 0.0939 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 1.0012\n",
      "Epoch 10/11\n",
      "1142/1158 [============================>.] - ETA: 0s - loss: 4.7562 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.3551 - rightLayer1_loss: 0.9628 - leftLayer2_loss: 0.0779 - midLayer2_loss: 1.4544 - rightLayer2_loss: 0.8051\n",
      "Epoch 00010: val_loss improved from 4.83314 to 4.77230, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7606 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.3559 - rightLayer1_loss: 0.9635 - leftLayer2_loss: 0.0780 - midLayer2_loss: 1.4563 - rightLayer2_loss: 0.8062 - val_loss: 4.7723 - val_leftLayer1_loss: 0.0993 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 0.9089 - val_leftLayer2_loss: 0.0913 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 0.9785\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135/1158 [============================>.] - ETA: 0s - loss: 4.7122 - leftLayer1_loss: 0.0984 - midLayer1_loss: 1.3540 - rightLayer1_loss: 0.9345 - leftLayer2_loss: 0.0741 - midLayer2_loss: 1.4603 - rightLayer2_loss: 0.7908\n",
      "Epoch 00011: val_loss improved from 4.77230 to 4.72045, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.7180 - leftLayer1_loss: 0.0984 - midLayer1_loss: 1.3553 - rightLayer1_loss: 0.9356 - leftLayer2_loss: 0.0741 - midLayer2_loss: 1.4619 - rightLayer2_loss: 0.7929 - val_loss: 4.7205 - val_leftLayer1_loss: 0.0969 - val_midLayer1_loss: 1.3368 - val_rightLayer1_loss: 0.8812 - val_leftLayer2_loss: 0.0888 - val_midLayer2_loss: 1.3576 - val_rightLayer2_loss: 0.9591\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Fibrosis: 0.7085834991092284\n",
      "\n",
      "auprc 0Fibrosis: 0.056145690244525086\n",
      "\n",
      "auroc 1Fibrosis: 0.5408304965566926\n",
      "\n",
      "auprc 1Fibrosis: 0.017179383678749455\n",
      "\n",
      "auroc 2Fibrosis: 0.5599420979656062\n",
      "\n",
      "auprc 2Fibrosis: 0.023573881441725845\n",
      "\n",
      "auroc 3Fibrosis: 0.5761709886050819\n",
      "\n",
      "auprc 3Fibrosis: 0.020977993484819588\n",
      "\n",
      "auroc 4Fibrosis: 0.4960114907915214\n",
      "\n",
      "auprc 4Fibrosis: 0.014461691140439244\n",
      "\n",
      "auroc 5Fibrosis: 0.3434168132929113\n",
      "\n",
      "auprc 5Fibrosis: 0.013768694266540177\n",
      "\n",
      "mean auroc: 0.5374925643868403\n",
      "\n",
      "mean auprc: 0.02435122237613323\n",
      "\n",
      "max auroc: 0.7085834991092284\n",
      "\n",
      "max auprc: 0.056145690244525086\n",
      "\n",
      "59.212894916534424\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1134/1158 [============================>.] - ETA: 0s - loss: 6.5537 - leftLayer1_loss: 0.1229 - midLayer1_loss: 1.3421 - rightLayer1_loss: 1.7920 - leftLayer2_loss: 0.1282 - midLayer2_loss: 1.4709 - rightLayer2_loss: 1.6976\n",
      "Epoch 00001: val_loss improved from inf to 6.27844, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 4s 3ms/step - loss: 6.5493 - leftLayer1_loss: 0.1229 - midLayer1_loss: 1.3428 - rightLayer1_loss: 1.7906 - leftLayer2_loss: 0.1281 - midLayer2_loss: 1.4715 - rightLayer2_loss: 1.6934 - val_loss: 6.2784 - val_leftLayer1_loss: 0.1219 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.7152 - val_leftLayer2_loss: 0.1243 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.6413\n",
      "Epoch 2/11\n",
      "1141/1158 [============================>.] - ETA: 0s - loss: 6.0060 - leftLayer1_loss: 0.1201 - midLayer1_loss: 1.3416 - rightLayer1_loss: 1.6414 - leftLayer2_loss: 0.1195 - midLayer2_loss: 1.4577 - rightLayer2_loss: 1.3256\n",
      "Epoch 00002: val_loss improved from 6.27844 to 5.90319, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 6.0040 - leftLayer1_loss: 0.1201 - midLayer1_loss: 1.3424 - rightLayer1_loss: 1.6407 - leftLayer2_loss: 0.1195 - midLayer2_loss: 1.4572 - rightLayer2_loss: 1.3241 - val_loss: 5.9032 - val_leftLayer1_loss: 0.1191 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.5693 - val_leftLayer2_loss: 0.1189 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.4202\n",
      "Epoch 3/11\n",
      "1141/1158 [============================>.] - ETA: 0s - loss: 5.6449 - leftLayer1_loss: 0.1175 - midLayer1_loss: 1.3422 - rightLayer1_loss: 1.5076 - leftLayer2_loss: 0.1121 - midLayer2_loss: 1.4566 - rightLayer2_loss: 1.1090\n",
      "Epoch 00003: val_loss improved from 5.90319 to 5.61978, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.6445 - leftLayer1_loss: 0.1175 - midLayer1_loss: 1.3428 - rightLayer1_loss: 1.5068 - leftLayer2_loss: 0.1121 - midLayer2_loss: 1.4568 - rightLayer2_loss: 1.1085 - val_loss: 5.6198 - val_leftLayer1_loss: 0.1164 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.4405 - val_leftLayer2_loss: 0.1138 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.2733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1137/1158 [============================>.] - ETA: 0s - loss: 5.4081 - leftLayer1_loss: 0.1149 - midLayer1_loss: 1.3415 - rightLayer1_loss: 1.3928 - leftLayer2_loss: 0.1040 - midLayer2_loss: 1.4700 - rightLayer2_loss: 0.9849\n",
      "Epoch 00004: val_loss improved from 5.61978 to 5.40427, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.4100 - leftLayer1_loss: 0.1148 - midLayer1_loss: 1.3422 - rightLayer1_loss: 1.3922 - leftLayer2_loss: 0.1040 - midLayer2_loss: 1.4714 - rightLayer2_loss: 0.9853 - val_loss: 5.4043 - val_leftLayer1_loss: 0.1138 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.3303 - val_leftLayer2_loss: 0.1092 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.1753\n",
      "Epoch 5/11\n",
      "1141/1158 [============================>.] - ETA: 0s - loss: 5.2175 - leftLayer1_loss: 0.1123 - midLayer1_loss: 1.3421 - rightLayer1_loss: 1.2946 - leftLayer2_loss: 0.0983 - midLayer2_loss: 1.4530 - rightLayer2_loss: 0.9172\n",
      "Epoch 00005: val_loss improved from 5.40427 to 5.23552, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.2186 - leftLayer1_loss: 0.1123 - midLayer1_loss: 1.3427 - rightLayer1_loss: 1.2944 - leftLayer2_loss: 0.0982 - midLayer2_loss: 1.4535 - rightLayer2_loss: 0.9175 - val_loss: 5.2355 - val_leftLayer1_loss: 0.1113 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.2376 - val_leftLayer2_loss: 0.1049 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.1060\n",
      "Epoch 6/11\n",
      "1154/1158 [============================>.] - ETA: 0s - loss: 5.0851 - leftLayer1_loss: 0.1098 - midLayer1_loss: 1.3404 - rightLayer1_loss: 1.2145 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.4558 - rightLayer2_loss: 0.8725\n",
      "Epoch 00006: val_loss improved from 5.23552 to 5.10057, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.0881 - leftLayer1_loss: 0.1098 - midLayer1_loss: 1.3412 - rightLayer1_loss: 1.2150 - leftLayer2_loss: 0.0921 - midLayer2_loss: 1.4560 - rightLayer2_loss: 0.8739 - val_loss: 5.1006 - val_leftLayer1_loss: 0.1088 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.1607 - val_leftLayer2_loss: 0.1009 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.0543\n",
      "Epoch 7/11\n",
      "1135/1158 [============================>.] - ETA: 0s - loss: 4.9847 - leftLayer1_loss: 0.1075 - midLayer1_loss: 1.3413 - rightLayer1_loss: 1.1489 - leftLayer2_loss: 0.0868 - midLayer2_loss: 1.4595 - rightLayer2_loss: 0.8408\n",
      "Epoch 00007: val_loss improved from 5.10057 to 4.99101, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.9885 - leftLayer1_loss: 0.1075 - midLayer1_loss: 1.3421 - rightLayer1_loss: 1.1491 - leftLayer2_loss: 0.0868 - midLayer2_loss: 1.4606 - rightLayer2_loss: 0.8425 - val_loss: 4.9910 - val_leftLayer1_loss: 0.1064 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.0970 - val_leftLayer2_loss: 0.0973 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 1.0145\n",
      "Epoch 8/11\n",
      "1134/1158 [============================>.] - ETA: 0s - loss: 4.8993 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.3418 - rightLayer1_loss: 1.0944 - leftLayer2_loss: 0.0822 - midLayer2_loss: 1.4566 - rightLayer2_loss: 0.8191\n",
      "Epoch 00008: val_loss improved from 4.99101 to 4.90102, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.9028 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.3424 - rightLayer1_loss: 1.0948 - leftLayer2_loss: 0.0822 - midLayer2_loss: 1.4577 - rightLayer2_loss: 0.8206 - val_loss: 4.9010 - val_leftLayer1_loss: 0.1042 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.0442 - val_leftLayer2_loss: 0.0940 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 0.9829\n",
      "Epoch 9/11\n",
      "1156/1158 [============================>.] - ETA: 0s - loss: 4.8412 - leftLayer1_loss: 0.1030 - midLayer1_loss: 1.3427 - rightLayer1_loss: 1.0502 - leftLayer2_loss: 0.0781 - midLayer2_loss: 1.4615 - rightLayer2_loss: 0.8057\n",
      "Epoch 00009: val_loss improved from 4.90102 to 4.82544, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.8431 - leftLayer1_loss: 0.1030 - midLayer1_loss: 1.3431 - rightLayer1_loss: 1.0507 - leftLayer2_loss: 0.0781 - midLayer2_loss: 1.4617 - rightLayer2_loss: 0.8066 - val_loss: 4.8254 - val_leftLayer1_loss: 0.1019 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 1.0002 - val_leftLayer2_loss: 0.0909 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 0.9566\n",
      "Epoch 10/11\n",
      "1143/1158 [============================>.] - ETA: 0s - loss: 4.7858 - leftLayer1_loss: 0.1009 - midLayer1_loss: 1.3415 - rightLayer1_loss: 1.0137 - leftLayer2_loss: 0.0743 - midLayer2_loss: 1.4615 - rightLayer2_loss: 0.7938\n",
      "Epoch 00010: val_loss improved from 4.82544 to 4.76158, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7874 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.3423 - rightLayer1_loss: 1.0138 - leftLayer2_loss: 0.0743 - midLayer2_loss: 1.4619 - rightLayer2_loss: 0.7943 - val_loss: 4.7616 - val_leftLayer1_loss: 0.0998 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 0.9632 - val_leftLayer2_loss: 0.0881 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 0.9347\n",
      "Epoch 11/11\n",
      "1152/1158 [============================>.] - ETA: 0s - loss: 4.7277 - leftLayer1_loss: 0.0988 - midLayer1_loss: 1.3420 - rightLayer1_loss: 0.9814 - leftLayer2_loss: 0.0707 - midLayer2_loss: 1.4518 - rightLayer2_loss: 0.7830\n",
      "Epoch 00011: val_loss improved from 4.76158 to 4.70675, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.7330 - leftLayer1_loss: 0.0988 - midLayer1_loss: 1.3429 - rightLayer1_loss: 0.9827 - leftLayer2_loss: 0.0707 - midLayer2_loss: 1.4526 - rightLayer2_loss: 0.7853 - val_loss: 4.7068 - val_leftLayer1_loss: 0.0977 - val_midLayer1_loss: 1.3153 - val_rightLayer1_loss: 0.9320 - val_leftLayer2_loss: 0.0855 - val_midLayer2_loss: 1.3605 - val_rightLayer2_loss: 0.9158\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Fibrosis: 0.5933121160213486\n",
      "\n",
      "auprc 0Fibrosis: 0.021756192624510253\n",
      "\n",
      "auroc 1Fibrosis: 0.6179230464415318\n",
      "\n",
      "auprc 1Fibrosis: 0.02111692386796414\n",
      "\n",
      "auroc 2Fibrosis: 0.5863766258115759\n",
      "\n",
      "auprc 2Fibrosis: 0.02671171590235486\n",
      "\n",
      "auroc 3Fibrosis: 0.6648658485635636\n",
      "\n",
      "auprc 3Fibrosis: 0.03392234308692583\n",
      "\n",
      "auroc 4Fibrosis: 0.4397339224917275\n",
      "\n",
      "auprc 4Fibrosis: 0.01310655540234852\n",
      "\n",
      "auroc 5Fibrosis: 0.5508346243702206\n",
      "\n",
      "auprc 5Fibrosis: 0.02718059918220013\n",
      "\n",
      "mean auroc: 0.575507697283328\n",
      "\n",
      "mean auprc: 0.02396572167771729\n",
      "\n",
      "max auroc: 0.6648658485635636\n",
      "\n",
      "max auprc: 0.03392234308692583\n",
      "\n",
      "59.32183241844177\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1146/1158 [============================>.] - ETA: 0s - loss: 6.5098 - leftLayer1_loss: 0.1242 - midLayer1_loss: 1.4223 - rightLayer1_loss: 1.7561 - leftLayer2_loss: 0.1272 - midLayer2_loss: 1.3879 - rightLayer2_loss: 1.6922\n",
      "Epoch 00001: val_loss improved from inf to 6.16350, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 4s 3ms/step - loss: 6.5070 - leftLayer1_loss: 0.1242 - midLayer1_loss: 1.4224 - rightLayer1_loss: 1.7552 - leftLayer2_loss: 0.1272 - midLayer2_loss: 1.3882 - rightLayer2_loss: 1.6899 - val_loss: 6.1635 - val_leftLayer1_loss: 0.1225 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.6546 - val_leftLayer2_loss: 0.1219 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 1.5862\n",
      "Epoch 2/11\n",
      "1135/1158 [============================>.] - ETA: 0s - loss: 5.9530 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.4220 - rightLayer1_loss: 1.5768 - leftLayer2_loss: 0.1189 - midLayer2_loss: 1.3948 - rightLayer2_loss: 1.3198\n",
      "Epoch 00002: val_loss improved from 6.16350 to 5.76746, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.9502 - leftLayer1_loss: 0.1207 - midLayer1_loss: 1.4220 - rightLayer1_loss: 1.5752 - leftLayer2_loss: 0.1188 - midLayer2_loss: 1.3957 - rightLayer2_loss: 1.3177 - val_loss: 5.7675 - val_leftLayer1_loss: 0.1190 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.4828 - val_leftLayer2_loss: 0.1165 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 1.3707\n",
      "Epoch 3/11\n",
      "1147/1158 [============================>.] - ETA: 0s - loss: 5.5665 - leftLayer1_loss: 0.1174 - midLayer1_loss: 1.4216 - rightLayer1_loss: 1.4226 - leftLayer2_loss: 0.1109 - midLayer2_loss: 1.3926 - rightLayer2_loss: 1.1015\n",
      "Epoch 00003: val_loss improved from 5.76746 to 5.47526, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.5654 - leftLayer1_loss: 0.1173 - midLayer1_loss: 1.4215 - rightLayer1_loss: 1.4220 - leftLayer2_loss: 0.1109 - midLayer2_loss: 1.3928 - rightLayer2_loss: 1.1009 - val_loss: 5.4753 - val_leftLayer1_loss: 0.1157 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.3392 - val_leftLayer2_loss: 0.1115 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 1.2305\n",
      "Epoch 4/11\n",
      "1138/1158 [============================>.] - ETA: 0s - loss: 5.3127 - leftLayer1_loss: 0.1142 - midLayer1_loss: 1.4197 - rightLayer1_loss: 1.2984 - leftLayer2_loss: 0.1034 - midLayer2_loss: 1.3917 - rightLayer2_loss: 0.9853\n",
      "Epoch 00004: val_loss improved from 5.47526 to 5.25926, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.3133 - leftLayer1_loss: 0.1142 - midLayer1_loss: 1.4196 - rightLayer1_loss: 1.2979 - leftLayer2_loss: 0.1034 - midLayer2_loss: 1.3926 - rightLayer2_loss: 0.9857 - val_loss: 5.2593 - val_leftLayer1_loss: 0.1125 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.2234 - val_leftLayer2_loss: 0.1069 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 1.1381\n",
      "Epoch 5/11\n",
      "1152/1158 [============================>.] - ETA: 0s - loss: 5.1291 - leftLayer1_loss: 0.1111 - midLayer1_loss: 1.4214 - rightLayer1_loss: 1.1979 - leftLayer2_loss: 0.0969 - midLayer2_loss: 1.3893 - rightLayer2_loss: 0.9125\n",
      "Epoch 00005: val_loss improved from 5.25926 to 5.09515, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.1316 - leftLayer1_loss: 0.1111 - midLayer1_loss: 1.4215 - rightLayer1_loss: 1.1984 - leftLayer2_loss: 0.0969 - midLayer2_loss: 1.3897 - rightLayer2_loss: 0.9140 - val_loss: 5.0951 - val_leftLayer1_loss: 0.1094 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.1314 - val_leftLayer2_loss: 0.1027 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 1.0733\n",
      "Epoch 6/11\n",
      "1156/1158 [============================>.] - ETA: 0s - loss: 5.0041 - leftLayer1_loss: 0.1081 - midLayer1_loss: 1.4223 - rightLayer1_loss: 1.1216 - leftLayer2_loss: 0.0915 - midLayer2_loss: 1.3866 - rightLayer2_loss: 0.8740\n",
      "Epoch 00006: val_loss improved from 5.09515 to 4.96742, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.0049 - leftLayer1_loss: 0.1081 - midLayer1_loss: 1.4222 - rightLayer1_loss: 1.1219 - leftLayer2_loss: 0.0915 - midLayer2_loss: 1.3864 - rightLayer2_loss: 0.8747 - val_loss: 4.9674 - val_leftLayer1_loss: 0.1064 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.0587 - val_leftLayer2_loss: 0.0988 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 1.0252\n",
      "Epoch 7/11\n",
      "1152/1158 [============================>.] - ETA: 0s - loss: 4.9008 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.4216 - rightLayer1_loss: 1.0610 - leftLayer2_loss: 0.0861 - midLayer2_loss: 1.3887 - rightLayer2_loss: 0.8381\n",
      "Epoch 00007: val_loss improved from 4.96742 to 4.86632, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.9044 - leftLayer1_loss: 0.1053 - midLayer1_loss: 1.4218 - rightLayer1_loss: 1.0620 - leftLayer2_loss: 0.0861 - midLayer2_loss: 1.3890 - rightLayer2_loss: 0.8401 - val_loss: 4.8663 - val_leftLayer1_loss: 0.1036 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 1.0009 - val_leftLayer2_loss: 0.0952 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 0.9883\n",
      "Epoch 8/11\n",
      "1150/1158 [============================>.] - ETA: 0s - loss: 4.8228 - leftLayer1_loss: 0.1025 - midLayer1_loss: 1.4205 - rightLayer1_loss: 1.0125 - leftLayer2_loss: 0.0814 - midLayer2_loss: 1.3863 - rightLayer2_loss: 0.8196\n",
      "Epoch 00008: val_loss improved from 4.86632 to 4.78452, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.8254 - leftLayer1_loss: 0.1025 - midLayer1_loss: 1.4205 - rightLayer1_loss: 1.0132 - leftLayer2_loss: 0.0814 - midLayer2_loss: 1.3869 - rightLayer2_loss: 0.8209 - val_loss: 4.7845 - val_leftLayer1_loss: 0.1009 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 0.9545 - val_leftLayer2_loss: 0.0919 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 0.9589\n",
      "Epoch 9/11\n",
      "1143/1158 [============================>.] - ETA: 0s - loss: 4.7567 - leftLayer1_loss: 0.0999 - midLayer1_loss: 1.4223 - rightLayer1_loss: 0.9751 - leftLayer2_loss: 0.0772 - midLayer2_loss: 1.3773 - rightLayer2_loss: 0.8048\n",
      "Epoch 00009: val_loss improved from 4.78452 to 4.71699, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7565 - leftLayer1_loss: 0.0999 - midLayer1_loss: 1.4223 - rightLayer1_loss: 0.9753 - leftLayer2_loss: 0.0772 - midLayer2_loss: 1.3766 - rightLayer2_loss: 0.8053 - val_loss: 4.7170 - val_leftLayer1_loss: 0.0982 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 0.9169 - val_leftLayer2_loss: 0.0889 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 0.9346\n",
      "Epoch 10/11\n",
      "1146/1158 [============================>.] - ETA: 0s - loss: 4.7167 - leftLayer1_loss: 0.0974 - midLayer1_loss: 1.4213 - rightLayer1_loss: 0.9435 - leftLayer2_loss: 0.0738 - midLayer2_loss: 1.3866 - rightLayer2_loss: 0.7940\n",
      "Epoch 00010: val_loss improved from 4.71699 to 4.66035, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7188 - leftLayer1_loss: 0.0974 - midLayer1_loss: 1.4213 - rightLayer1_loss: 0.9444 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3866 - rightLayer2_loss: 0.7953 - val_loss: 4.6604 - val_leftLayer1_loss: 0.0957 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 0.8859 - val_leftLayer2_loss: 0.0861 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 0.9142\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144/1158 [============================>.] - ETA: 0s - loss: 4.6825 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.4220 - rightLayer1_loss: 0.9187 - leftLayer2_loss: 0.0702 - midLayer2_loss: 1.3944 - rightLayer2_loss: 0.7822\n",
      "Epoch 00011: val_loss improved from 4.66035 to 4.61237, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.6835 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.4219 - rightLayer1_loss: 0.9193 - leftLayer2_loss: 0.0702 - midLayer2_loss: 1.3940 - rightLayer2_loss: 0.7832 - val_loss: 4.6124 - val_leftLayer1_loss: 0.0933 - val_midLayer1_loss: 1.3961 - val_rightLayer1_loss: 0.8602 - val_leftLayer2_loss: 0.0835 - val_midLayer2_loss: 1.2823 - val_rightLayer2_loss: 0.8970\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Fibrosis: 0.43053733418342766\n",
      "\n",
      "auprc 0Fibrosis: 0.013040549056484378\n",
      "\n",
      "auroc 1Fibrosis: 0.4227356664866849\n",
      "\n",
      "auprc 1Fibrosis: 0.012962322014687697\n",
      "\n",
      "auroc 2Fibrosis: 0.6085871538137468\n",
      "\n",
      "auprc 2Fibrosis: 0.03268912264485903\n",
      "\n",
      "auroc 3Fibrosis: 0.4477541840734486\n",
      "\n",
      "auprc 3Fibrosis: 0.016342355047122087\n",
      "\n",
      "auroc 4Fibrosis: 0.5459820028331469\n",
      "\n",
      "auprc 4Fibrosis: 0.018041530099025385\n",
      "\n",
      "auroc 5Fibrosis: 0.4609620609129102\n",
      "\n",
      "auprc 5Fibrosis: 0.017267619753948547\n",
      "\n",
      "mean auroc: 0.4860930670505608\n",
      "\n",
      "mean auprc: 0.018390583102687857\n",
      "\n",
      "max auroc: 0.6085871538137468\n",
      "\n",
      "max auprc: 0.03268912264485903\n",
      "\n",
      "59.69277238845825\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1158 steps, validate for 166 steps\n",
      "Epoch 1/11\n",
      "1136/1158 [============================>.] - ETA: 0s - loss: 6.5405 - leftLayer1_loss: 0.1230 - midLayer1_loss: 1.4100 - rightLayer1_loss: 1.7699 - leftLayer2_loss: 0.1286 - midLayer2_loss: 1.4192 - rightLayer2_loss: 1.6898\n",
      "Epoch 00001: val_loss improved from inf to 6.28127, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 4s 3ms/step - loss: 6.5367 - leftLayer1_loss: 0.1230 - midLayer1_loss: 1.4105 - rightLayer1_loss: 1.7683 - leftLayer2_loss: 0.1285 - midLayer2_loss: 1.4199 - rightLayer2_loss: 1.6865 - val_loss: 6.2813 - val_leftLayer1_loss: 0.1213 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.6813 - val_leftLayer2_loss: 0.1223 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.6174\n",
      "Epoch 2/11\n",
      "1154/1158 [============================>.] - ETA: 0s - loss: 6.0149 - leftLayer1_loss: 0.1201 - midLayer1_loss: 1.4090 - rightLayer1_loss: 1.6101 - leftLayer2_loss: 0.1208 - midLayer2_loss: 1.4156 - rightLayer2_loss: 1.3393\n",
      "Epoch 00002: val_loss improved from 6.28127 to 5.91780, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 6.0158 - leftLayer1_loss: 0.1201 - midLayer1_loss: 1.4094 - rightLayer1_loss: 1.6102 - leftLayer2_loss: 0.1208 - midLayer2_loss: 1.4160 - rightLayer2_loss: 1.3394 - val_loss: 5.9178 - val_leftLayer1_loss: 0.1183 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.5279 - val_leftLayer2_loss: 0.1174 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.4152\n",
      "Epoch 3/11\n",
      "1149/1158 [============================>.] - ETA: 0s - loss: 5.6500 - leftLayer1_loss: 0.1171 - midLayer1_loss: 1.4098 - rightLayer1_loss: 1.4706 - leftLayer2_loss: 0.1132 - midLayer2_loss: 1.4153 - rightLayer2_loss: 1.1240\n",
      "Epoch 00003: val_loss improved from 5.91780 to 5.64054, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.6502 - leftLayer1_loss: 0.1172 - midLayer1_loss: 1.4102 - rightLayer1_loss: 1.4704 - leftLayer2_loss: 0.1132 - midLayer2_loss: 1.4147 - rightLayer2_loss: 1.1245 - val_loss: 5.6405 - val_leftLayer1_loss: 0.1155 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.3952 - val_leftLayer2_loss: 0.1128 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.2782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1151/1158 [============================>.] - ETA: 0s - loss: 5.4002 - leftLayer1_loss: 0.1144 - midLayer1_loss: 1.4104 - rightLayer1_loss: 1.3520 - leftLayer2_loss: 0.1060 - midLayer2_loss: 1.4145 - rightLayer2_loss: 1.0030\n",
      "Epoch 00004: val_loss improved from 5.64054 to 5.42836, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.4025 - leftLayer1_loss: 0.1144 - midLayer1_loss: 1.4107 - rightLayer1_loss: 1.3522 - leftLayer2_loss: 0.1060 - midLayer2_loss: 1.4153 - rightLayer2_loss: 1.0039 - val_loss: 5.4284 - val_leftLayer1_loss: 0.1127 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.2840 - val_leftLayer2_loss: 0.1085 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.1843\n",
      "Epoch 5/11\n",
      "1150/1158 [============================>.] - ETA: 0s - loss: 5.2165 - leftLayer1_loss: 0.1117 - midLayer1_loss: 1.4093 - rightLayer1_loss: 1.2555 - leftLayer2_loss: 0.0995 - midLayer2_loss: 1.4116 - rightLayer2_loss: 0.9288\n",
      "Epoch 00005: val_loss improved from 5.42836 to 5.26346, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 5.2179 - leftLayer1_loss: 0.1117 - midLayer1_loss: 1.4097 - rightLayer1_loss: 1.2556 - leftLayer2_loss: 0.0995 - midLayer2_loss: 1.4117 - rightLayer2_loss: 0.9297 - val_loss: 5.2635 - val_leftLayer1_loss: 0.1100 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.1926 - val_leftLayer2_loss: 0.1046 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.1174\n",
      "Epoch 6/11\n",
      "1137/1158 [============================>.] - ETA: 0s - loss: 5.0919 - leftLayer1_loss: 0.1091 - midLayer1_loss: 1.4109 - rightLayer1_loss: 1.1769 - leftLayer2_loss: 0.0943 - midLayer2_loss: 1.4175 - rightLayer2_loss: 0.8832\n",
      "Epoch 00006: val_loss improved from 5.26346 to 5.13227, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 5.0951 - leftLayer1_loss: 0.1091 - midLayer1_loss: 1.4115 - rightLayer1_loss: 1.1768 - leftLayer2_loss: 0.0943 - midLayer2_loss: 1.4187 - rightLayer2_loss: 0.8848 - val_loss: 5.1323 - val_leftLayer1_loss: 0.1074 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.1181 - val_leftLayer2_loss: 0.1009 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.0670\n",
      "Epoch 7/11\n",
      "1145/1158 [============================>.] - ETA: 0s - loss: 4.9863 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.4102 - rightLayer1_loss: 1.1132 - leftLayer2_loss: 0.0896 - midLayer2_loss: 1.4133 - rightLayer2_loss: 0.8535\n",
      "Epoch 00007: val_loss improved from 5.13227 to 5.02639, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.9868 - leftLayer1_loss: 0.1066 - midLayer1_loss: 1.4104 - rightLayer1_loss: 1.1132 - leftLayer2_loss: 0.0896 - midLayer2_loss: 1.4128 - rightLayer2_loss: 0.8542 - val_loss: 5.0264 - val_leftLayer1_loss: 0.1048 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.0573 - val_leftLayer2_loss: 0.0975 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 1.0278\n",
      "Epoch 8/11\n",
      "1141/1158 [============================>.] - ETA: 0s - loss: 4.9049 - leftLayer1_loss: 0.1042 - midLayer1_loss: 1.4099 - rightLayer1_loss: 1.0615 - leftLayer2_loss: 0.0845 - midLayer2_loss: 1.4159 - rightLayer2_loss: 0.8288\n",
      "Epoch 00008: val_loss improved from 5.02639 to 4.93973, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.9065 - leftLayer1_loss: 0.1042 - midLayer1_loss: 1.4103 - rightLayer1_loss: 1.0618 - leftLayer2_loss: 0.0845 - midLayer2_loss: 1.4161 - rightLayer2_loss: 0.8297 - val_loss: 4.9397 - val_leftLayer1_loss: 0.1024 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 1.0075 - val_leftLayer2_loss: 0.0944 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 0.9965\n",
      "Epoch 9/11\n",
      "1147/1158 [============================>.] - ETA: 0s - loss: 4.8408 - leftLayer1_loss: 0.1017 - midLayer1_loss: 1.4091 - rightLayer1_loss: 1.0198 - leftLayer2_loss: 0.0799 - midLayer2_loss: 1.4181 - rightLayer2_loss: 0.8121\n",
      "Epoch 00009: val_loss improved from 4.93973 to 4.86783, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.8419 - leftLayer1_loss: 0.1018 - midLayer1_loss: 1.4093 - rightLayer1_loss: 1.0202 - leftLayer2_loss: 0.0799 - midLayer2_loss: 1.4179 - rightLayer2_loss: 0.8129 - val_loss: 4.8678 - val_leftLayer1_loss: 0.1001 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 0.9664 - val_leftLayer2_loss: 0.0915 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 0.9709\n",
      "Epoch 10/11\n",
      "1140/1158 [============================>.] - ETA: 0s - loss: 4.7853 - leftLayer1_loss: 0.0995 - midLayer1_loss: 1.4106 - rightLayer1_loss: 0.9855 - leftLayer2_loss: 0.0763 - midLayer2_loss: 1.4156 - rightLayer2_loss: 0.7977\n",
      "Epoch 00010: val_loss improved from 4.86783 to 4.80696, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 3ms/step - loss: 4.7885 - leftLayer1_loss: 0.0995 - midLayer1_loss: 1.4108 - rightLayer1_loss: 0.9861 - leftLayer2_loss: 0.0763 - midLayer2_loss: 1.4167 - rightLayer2_loss: 0.7992 - val_loss: 4.8070 - val_leftLayer1_loss: 0.0978 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 0.9322 - val_leftLayer2_loss: 0.0888 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 0.9492\n",
      "Epoch 11/11\n",
      "1149/1158 [============================>.] - ETA: 0s - loss: 4.7360 - leftLayer1_loss: 0.0974 - midLayer1_loss: 1.4085 - rightLayer1_loss: 0.9565 - leftLayer2_loss: 0.0729 - midLayer2_loss: 1.4129 - rightLayer2_loss: 0.7878\n",
      "Epoch 00011: val_loss improved from 4.80696 to 4.75481, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1158/1158 [==============================] - 3s 2ms/step - loss: 4.7395 - leftLayer1_loss: 0.0974 - midLayer1_loss: 1.4089 - rightLayer1_loss: 0.9574 - leftLayer2_loss: 0.0729 - midLayer2_loss: 1.4133 - rightLayer2_loss: 0.7895 - val_loss: 4.7548 - val_leftLayer1_loss: 0.0957 - val_midLayer1_loss: 1.3882 - val_rightLayer1_loss: 0.9034 - val_leftLayer2_loss: 0.0864 - val_midLayer2_loss: 1.3507 - val_rightLayer2_loss: 0.9305\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Fibrosis: 0.5073162303174762\n",
      "\n",
      "auprc 0Fibrosis: 0.015814988899646658\n",
      "\n",
      "auroc 1Fibrosis: 0.32822757344391573\n",
      "\n",
      "auprc 1Fibrosis: 0.010727182049448107\n",
      "\n",
      "auroc 2Fibrosis: 0.5463357081403036\n",
      "\n",
      "auprc 2Fibrosis: 0.024475923670711906\n",
      "\n",
      "auroc 3Fibrosis: 0.6899863724579465\n",
      "\n",
      "auprc 3Fibrosis: 0.038439489923769034\n",
      "\n",
      "auroc 4Fibrosis: 0.5199570647315757\n",
      "\n",
      "auprc 4Fibrosis: 0.019205854434290657\n",
      "\n",
      "auroc 5Fibrosis: 0.4936264831904869\n",
      "\n",
      "auprc 5Fibrosis: 0.01768001401254578\n",
      "\n",
      "mean auroc: 0.5142415720469508\n",
      "\n",
      "mean auprc: 0.021057242165068688\n",
      "\n",
      "max auroc: 0.6899863724579465\n",
      "\n",
      "max auprc: 0.038439489923769034\n",
      "\n",
      "59.639408111572266\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7085834991092284\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
