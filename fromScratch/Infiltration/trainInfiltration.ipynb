{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Infiltration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path=None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "2281: 13914\n",
      "431: 13914\n",
      "2801: 13914\n",
      "13914: 13914\n",
      "822: 13914\n",
      "1057: 13914\n",
      "414: 13914\n",
      "662: 13914\n",
      "841: 13914\n",
      "726: 13914\n",
      "313: 13914\n",
      "234: 13914\n",
      "511: 13914\n",
      "22: 13914\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13905/13914 [============================>.] - ETA: 0s - loss: 5.0568 - leftLayer1_loss: 0.1100 - midLayer1_loss: 1.3642 - rightLayer1_loss: 1.1902 - leftLayer2_loss: 0.0917 - midLayer2_loss: 1.3413 - rightLayer2_loss: 0.9594\n",
      "Epoch 00001: val_loss improved from inf to 4.59152, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 39s 3ms/step - loss: 5.0566 - leftLayer1_loss: 0.1100 - midLayer1_loss: 1.3642 - rightLayer1_loss: 1.1900 - leftLayer2_loss: 0.0917 - midLayer2_loss: 1.3413 - rightLayer2_loss: 0.9594 - val_loss: 4.5915 - val_leftLayer1_loss: 0.0940 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.8504 - val_leftLayer2_loss: 0.0842 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.8972\n",
      "Epoch 2/11\n",
      "13893/13914 [============================>.] - ETA: 0s - loss: 4.3147 - leftLayer1_loss: 0.0829 - midLayer1_loss: 1.3640 - rightLayer1_loss: 0.7831 - leftLayer2_loss: 0.0546 - midLayer2_loss: 1.3390 - rightLayer2_loss: 0.6912\n",
      "Epoch 00002: val_loss improved from 4.59152 to 4.31974, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 37s 3ms/step - loss: 4.3149 - leftLayer1_loss: 0.0829 - midLayer1_loss: 1.3640 - rightLayer1_loss: 0.7832 - leftLayer2_loss: 0.0545 - midLayer2_loss: 1.3390 - rightLayer2_loss: 0.6914 - val_loss: 4.3197 - val_leftLayer1_loss: 0.0727 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.7214 - val_leftLayer2_loss: 0.0663 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.7937\n",
      "Epoch 3/11\n",
      "13913/13914 [============================>.] - ETA: 0s - loss: 4.1890 - leftLayer1_loss: 0.0661 - midLayer1_loss: 1.3641 - rightLayer1_loss: 0.7122 - leftLayer2_loss: 0.0416 - midLayer2_loss: 1.3410 - rightLayer2_loss: 0.6639\n",
      "Epoch 00003: val_loss improved from 4.31974 to 4.21382, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 38s 3ms/step - loss: 4.1891 - leftLayer1_loss: 0.0661 - midLayer1_loss: 1.3641 - rightLayer1_loss: 0.7123 - leftLayer2_loss: 0.0416 - midLayer2_loss: 1.3410 - rightLayer2_loss: 0.6640 - val_loss: 4.2138 - val_leftLayer1_loss: 0.0594 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6806 - val_leftLayer2_loss: 0.0571 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.7509\n",
      "Epoch 4/11\n",
      "13911/13914 [============================>.] - ETA: 0s - loss: 4.1316 - leftLayer1_loss: 0.0554 - midLayer1_loss: 1.3641 - rightLayer1_loss: 0.6846 - leftLayer2_loss: 0.0358 - midLayer2_loss: 1.3385 - rightLayer2_loss: 0.6533\n",
      "Epoch 00004: val_loss improved from 4.21382 to 4.15564, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 38s 3ms/step - loss: 4.1316 - leftLayer1_loss: 0.0554 - midLayer1_loss: 1.3641 - rightLayer1_loss: 0.6845 - leftLayer2_loss: 0.0358 - midLayer2_loss: 1.3385 - rightLayer2_loss: 0.6533 - val_loss: 4.1556 - val_leftLayer1_loss: 0.0509 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6609 - val_leftLayer2_loss: 0.0516 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.7265\n",
      "Epoch 5/11\n",
      "13908/13914 [============================>.] - ETA: 0s - loss: 4.1013 - leftLayer1_loss: 0.0484 - midLayer1_loss: 1.3638 - rightLayer1_loss: 0.6695 - leftLayer2_loss: 0.0327 - midLayer2_loss: 1.3393 - rightLayer2_loss: 0.6475\n",
      "Epoch 00005: val_loss improved from 4.15564 to 4.11820, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 38s 3ms/step - loss: 4.1016 - leftLayer1_loss: 0.0484 - midLayer1_loss: 1.3638 - rightLayer1_loss: 0.6696 - leftLayer2_loss: 0.0327 - midLayer2_loss: 1.3394 - rightLayer2_loss: 0.6476 - val_loss: 4.1182 - val_leftLayer1_loss: 0.0452 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6492 - val_leftLayer2_loss: 0.0479 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.7102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "13901/13914 [============================>.] - ETA: 0s - loss: 4.0820 - leftLayer1_loss: 0.0436 - midLayer1_loss: 1.3640 - rightLayer1_loss: 0.6603 - leftLayer2_loss: 0.0308 - midLayer2_loss: 1.3397 - rightLayer2_loss: 0.6435\n",
      "Epoch 00006: val_loss improved from 4.11820 to 4.09199, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0824 - leftLayer1_loss: 0.0436 - midLayer1_loss: 1.3640 - rightLayer1_loss: 0.6604 - leftLayer2_loss: 0.0308 - midLayer2_loss: 1.3397 - rightLayer2_loss: 0.6437 - val_loss: 4.0920 - val_leftLayer1_loss: 0.0411 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6414 - val_leftLayer2_loss: 0.0453 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.6985\n",
      "Epoch 7/11\n",
      "13902/13914 [============================>.] - ETA: 0s - loss: 4.0693 - leftLayer1_loss: 0.0402 - midLayer1_loss: 1.3642 - rightLayer1_loss: 0.6537 - leftLayer2_loss: 0.0297 - midLayer2_loss: 1.3406 - rightLayer2_loss: 0.6409\n",
      "Epoch 00007: val_loss improved from 4.09199 to 4.07248, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0696 - leftLayer1_loss: 0.0402 - midLayer1_loss: 1.3642 - rightLayer1_loss: 0.6538 - leftLayer2_loss: 0.0297 - midLayer2_loss: 1.3406 - rightLayer2_loss: 0.6411 - val_loss: 4.0725 - val_leftLayer1_loss: 0.0382 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6357 - val_leftLayer2_loss: 0.0433 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.6895\n",
      "Epoch 8/11\n",
      "13896/13914 [============================>.] - ETA: 0s - loss: 4.0578 - leftLayer1_loss: 0.0377 - midLayer1_loss: 1.3643 - rightLayer1_loss: 0.6487 - leftLayer2_loss: 0.0288 - midLayer2_loss: 1.3393 - rightLayer2_loss: 0.6391\n",
      "Epoch 00008: val_loss improved from 4.07248 to 4.05729, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0583 - leftLayer1_loss: 0.0377 - midLayer1_loss: 1.3643 - rightLayer1_loss: 0.6489 - leftLayer2_loss: 0.0288 - midLayer2_loss: 1.3393 - rightLayer2_loss: 0.6393 - val_loss: 4.0573 - val_leftLayer1_loss: 0.0360 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6314 - val_leftLayer2_loss: 0.0417 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.6824\n",
      "Epoch 9/11\n",
      "13906/13914 [============================>.] - ETA: 0s - loss: 4.0516 - leftLayer1_loss: 0.0358 - midLayer1_loss: 1.3639 - rightLayer1_loss: 0.6451 - leftLayer2_loss: 0.0282 - midLayer2_loss: 1.3411 - rightLayer2_loss: 0.6376\n",
      "Epoch 00009: val_loss improved from 4.05729 to 4.04513, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0519 - leftLayer1_loss: 0.0358 - midLayer1_loss: 1.3639 - rightLayer1_loss: 0.6452 - leftLayer2_loss: 0.0282 - midLayer2_loss: 1.3412 - rightLayer2_loss: 0.6377 - val_loss: 4.0451 - val_leftLayer1_loss: 0.0343 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6280 - val_leftLayer2_loss: 0.0404 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.6767\n",
      "Epoch 10/11\n",
      "13908/13914 [============================>.] - ETA: 0s - loss: 4.0433 - leftLayer1_loss: 0.0342 - midLayer1_loss: 1.3641 - rightLayer1_loss: 0.6417 - leftLayer2_loss: 0.0277 - midLayer2_loss: 1.3391 - rightLayer2_loss: 0.6365\n",
      "Epoch 00010: val_loss improved from 4.04513 to 4.03499, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0436 - leftLayer1_loss: 0.0342 - midLayer1_loss: 1.3642 - rightLayer1_loss: 0.6418 - leftLayer2_loss: 0.0277 - midLayer2_loss: 1.3391 - rightLayer2_loss: 0.6366 - val_loss: 4.0350 - val_leftLayer1_loss: 0.0329 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6251 - val_leftLayer2_loss: 0.0394 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.6718\n",
      "Epoch 11/11\n",
      "13893/13914 [============================>.] - ETA: 0s - loss: 4.0404 - leftLayer1_loss: 0.0330 - midLayer1_loss: 1.3639 - rightLayer1_loss: 0.6390 - leftLayer2_loss: 0.0274 - midLayer2_loss: 1.3416 - rightLayer2_loss: 0.6355\n",
      "Epoch 00011: val_loss improved from 4.03499 to 4.02646, saving model to ./experiments/0.009_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0408 - leftLayer1_loss: 0.0330 - midLayer1_loss: 1.3639 - rightLayer1_loss: 0.6392 - leftLayer2_loss: 0.0274 - midLayer2_loss: 1.3416 - rightLayer2_loss: 0.6358 - val_loss: 4.0265 - val_leftLayer1_loss: 0.0319 - val_midLayer1_loss: 1.3582 - val_rightLayer1_loss: 0.6226 - val_leftLayer2_loss: 0.0385 - val_midLayer2_loss: 1.3076 - val_rightLayer2_loss: 0.6677\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Infiltration: 0.4717135264070795\n",
      "\n",
      "auprc 0Infiltration: 0.16169377863485784\n",
      "\n",
      "auroc 1Infiltration: 0.5456427972311021\n",
      "\n",
      "auprc 1Infiltration: 0.21150115815471265\n",
      "\n",
      "auroc 2Infiltration: 0.4206346107296236\n",
      "\n",
      "auprc 2Infiltration: 0.14515397244150507\n",
      "\n",
      "auroc 3Infiltration: 0.4411972626261253\n",
      "\n",
      "auprc 3Infiltration: 0.14819531239091602\n",
      "\n",
      "auroc 4Infiltration: 0.4835658162453416\n",
      "\n",
      "auprc 4Infiltration: 0.16484346459310367\n",
      "\n",
      "auroc 5Infiltration: 0.4649429910572511\n",
      "\n",
      "auprc 5Infiltration: 0.15635566410398524\n",
      "\n",
      "mean auroc: 0.47128283404942056\n",
      "\n",
      "mean auprc: 0.16462389171984676\n",
      "\n",
      "max auroc: 0.5456427972311021\n",
      "\n",
      "max auprc: 0.21150115815471265\n",
      "\n",
      "428.68783259391785\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13896/13914 [============================>.] - ETA: 0s - loss: 5.0611 - leftLayer1_loss: 0.1046 - midLayer1_loss: 1.3661 - rightLayer1_loss: 1.1845 - leftLayer2_loss: 0.0866 - midLayer2_loss: 1.3744 - rightLayer2_loss: 0.9450\n",
      "Epoch 00001: val_loss improved from inf to 4.61443, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 5.0607 - leftLayer1_loss: 0.1046 - midLayer1_loss: 1.3662 - rightLayer1_loss: 1.1842 - leftLayer2_loss: 0.0865 - midLayer2_loss: 1.3744 - rightLayer2_loss: 0.9448 - val_loss: 4.6144 - val_leftLayer1_loss: 0.0901 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.8533 - val_leftLayer2_loss: 0.0803 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.8978\n",
      "Epoch 2/11\n",
      "13910/13914 [============================>.] - ETA: 0s - loss: 4.3453 - leftLayer1_loss: 0.0798 - midLayer1_loss: 1.3661 - rightLayer1_loss: 0.7861 - leftLayer2_loss: 0.0519 - midLayer2_loss: 1.3729 - rightLayer2_loss: 0.6885\n",
      "Epoch 00002: val_loss improved from 4.61443 to 4.34688, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.3453 - leftLayer1_loss: 0.0798 - midLayer1_loss: 1.3661 - rightLayer1_loss: 0.7860 - leftLayer2_loss: 0.0519 - midLayer2_loss: 1.3729 - rightLayer2_loss: 0.6886 - val_loss: 4.3469 - val_leftLayer1_loss: 0.0706 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.7247 - val_leftLayer2_loss: 0.0635 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.7952\n",
      "Epoch 3/11\n",
      "13908/13914 [============================>.] - ETA: 0s - loss: 4.2231 - leftLayer1_loss: 0.0642 - midLayer1_loss: 1.3660 - rightLayer1_loss: 0.7149 - leftLayer2_loss: 0.0400 - midLayer2_loss: 1.3752 - rightLayer2_loss: 0.6627\n",
      "Epoch 00003: val_loss improved from 4.34688 to 4.24211, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.2233 - leftLayer1_loss: 0.0642 - midLayer1_loss: 1.3660 - rightLayer1_loss: 0.7150 - leftLayer2_loss: 0.0400 - midLayer2_loss: 1.3752 - rightLayer2_loss: 0.6628 - val_loss: 4.2421 - val_leftLayer1_loss: 0.0582 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6835 - val_leftLayer2_loss: 0.0550 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.7525\n",
      "Epoch 4/11\n",
      "13910/13914 [============================>.] - ETA: 0s - loss: 4.1675 - leftLayer1_loss: 0.0543 - midLayer1_loss: 1.3659 - rightLayer1_loss: 0.6873 - leftLayer2_loss: 0.0348 - midLayer2_loss: 1.3727 - rightLayer2_loss: 0.6524\n",
      "Epoch 00004: val_loss improved from 4.24211 to 4.18441, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.1675 - leftLayer1_loss: 0.0543 - midLayer1_loss: 1.3659 - rightLayer1_loss: 0.6873 - leftLayer2_loss: 0.0348 - midLayer2_loss: 1.3727 - rightLayer2_loss: 0.6524 - val_loss: 4.1844 - val_leftLayer1_loss: 0.0502 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6634 - val_leftLayer2_loss: 0.0498 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.7280\n",
      "Epoch 5/11\n",
      "13895/13914 [============================>.] - ETA: 0s - loss: 4.1390 - leftLayer1_loss: 0.0477 - midLayer1_loss: 1.3660 - rightLayer1_loss: 0.6719 - leftLayer2_loss: 0.0319 - midLayer2_loss: 1.3750 - rightLayer2_loss: 0.6465\n",
      "Epoch 00005: val_loss improved from 4.18441 to 4.14744, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 4.1393 - leftLayer1_loss: 0.0477 - midLayer1_loss: 1.3661 - rightLayer1_loss: 0.6720 - leftLayer2_loss: 0.0319 - midLayer2_loss: 1.3750 - rightLayer2_loss: 0.6466 - val_loss: 4.1474 - val_leftLayer1_loss: 0.0448 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6515 - val_leftLayer2_loss: 0.0464 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.7118\n",
      "Epoch 6/11\n",
      "13902/13914 [============================>.] - ETA: 0s - loss: 4.1183 - leftLayer1_loss: 0.0432 - midLayer1_loss: 1.3663 - rightLayer1_loss: 0.6626 - leftLayer2_loss: 0.0303 - midLayer2_loss: 1.3731 - rightLayer2_loss: 0.6428\n",
      "Epoch 00006: val_loss improved from 4.14744 to 4.12144, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1185 - leftLayer1_loss: 0.0432 - midLayer1_loss: 1.3663 - rightLayer1_loss: 0.6627 - leftLayer2_loss: 0.0303 - midLayer2_loss: 1.3731 - rightLayer2_loss: 0.6429 - val_loss: 4.1214 - val_leftLayer1_loss: 0.0409 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6435 - val_leftLayer2_loss: 0.0439 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.7001\n",
      "Epoch 7/11\n",
      "13899/13914 [============================>.] - ETA: 0s - loss: 4.1036 - leftLayer1_loss: 0.0399 - midLayer1_loss: 1.3663 - rightLayer1_loss: 0.6558 - leftLayer2_loss: 0.0292 - midLayer2_loss: 1.3718 - rightLayer2_loss: 0.6406\n",
      "Epoch 00007: val_loss improved from 4.12144 to 4.10202, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1039 - leftLayer1_loss: 0.0399 - midLayer1_loss: 1.3663 - rightLayer1_loss: 0.6559 - leftLayer2_loss: 0.0292 - midLayer2_loss: 1.3718 - rightLayer2_loss: 0.6408 - val_loss: 4.1020 - val_leftLayer1_loss: 0.0381 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6378 - val_leftLayer2_loss: 0.0420 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.6911\n",
      "Epoch 8/11\n",
      "13909/13914 [============================>.] - ETA: 0s - loss: 4.0941 - leftLayer1_loss: 0.0374 - midLayer1_loss: 1.3659 - rightLayer1_loss: 0.6510 - leftLayer2_loss: 0.0285 - midLayer2_loss: 1.3724 - rightLayer2_loss: 0.6390\n",
      "Epoch 00008: val_loss improved from 4.10202 to 4.08693, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0942 - leftLayer1_loss: 0.0374 - midLayer1_loss: 1.3659 - rightLayer1_loss: 0.6510 - leftLayer2_loss: 0.0285 - midLayer2_loss: 1.3724 - rightLayer2_loss: 0.6390 - val_loss: 4.0869 - val_leftLayer1_loss: 0.0359 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6335 - val_leftLayer2_loss: 0.0405 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.6840\n",
      "Epoch 9/11\n",
      "13913/13914 [============================>.] - ETA: 0s - loss: 4.0874 - leftLayer1_loss: 0.0356 - midLayer1_loss: 1.3661 - rightLayer1_loss: 0.6472 - leftLayer2_loss: 0.0279 - midLayer2_loss: 1.3733 - rightLayer2_loss: 0.6373\n",
      "Epoch 00009: val_loss improved from 4.08693 to 4.07481, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0876 - leftLayer1_loss: 0.0356 - midLayer1_loss: 1.3661 - rightLayer1_loss: 0.6472 - leftLayer2_loss: 0.0279 - midLayer2_loss: 1.3734 - rightLayer2_loss: 0.6374 - val_loss: 4.0748 - val_leftLayer1_loss: 0.0343 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6300 - val_leftLayer2_loss: 0.0393 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.6782\n",
      "Epoch 10/11\n",
      "13897/13914 [============================>.] - ETA: 0s - loss: 4.0840 - leftLayer1_loss: 0.0341 - midLayer1_loss: 1.3660 - rightLayer1_loss: 0.6439 - leftLayer2_loss: 0.0275 - midLayer2_loss: 1.3764 - rightLayer2_loss: 0.6361\n",
      "Epoch 00010: val_loss improved from 4.07481 to 4.06483, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0845 - leftLayer1_loss: 0.0341 - midLayer1_loss: 1.3661 - rightLayer1_loss: 0.6441 - leftLayer2_loss: 0.0275 - midLayer2_loss: 1.3764 - rightLayer2_loss: 0.6363 - val_loss: 4.0648 - val_leftLayer1_loss: 0.0330 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6272 - val_leftLayer2_loss: 0.0384 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.6733\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13902/13914 [============================>.] - ETA: 0s - loss: 4.0741 - leftLayer1_loss: 0.0329 - midLayer1_loss: 1.3663 - rightLayer1_loss: 0.6412 - leftLayer2_loss: 0.0271 - midLayer2_loss: 1.3713 - rightLayer2_loss: 0.6353\n",
      "Epoch 00011: val_loss improved from 4.06483 to 4.05638, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0743 - leftLayer1_loss: 0.0329 - midLayer1_loss: 1.3663 - rightLayer1_loss: 0.6413 - leftLayer2_loss: 0.0271 - midLayer2_loss: 1.3712 - rightLayer2_loss: 0.6354 - val_loss: 4.0564 - val_leftLayer1_loss: 0.0319 - val_midLayer1_loss: 1.3634 - val_rightLayer1_loss: 0.6248 - val_leftLayer2_loss: 0.0375 - val_midLayer2_loss: 1.3295 - val_rightLayer2_loss: 0.6692\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Infiltration: 0.502374106023741\n",
      "\n",
      "auprc 0Infiltration: 0.16746115101094922\n",
      "\n",
      "auroc 1Infiltration: 0.4293642084919661\n",
      "\n",
      "auprc 1Infiltration: 0.146463680759498\n",
      "\n",
      "auroc 2Infiltration: 0.3829089945246206\n",
      "\n",
      "auprc 2Infiltration: 0.13348486650964483\n",
      "\n",
      "auroc 3Infiltration: 0.40482068575491076\n",
      "\n",
      "auprc 3Infiltration: 0.1410009135448698\n",
      "\n",
      "auroc 4Infiltration: 0.3810524195591275\n",
      "\n",
      "auprc 4Infiltration: 0.13190004100307162\n",
      "\n",
      "auroc 5Infiltration: 0.3630529835867682\n",
      "\n",
      "auprc 5Infiltration: 0.1309564714179775\n",
      "\n",
      "mean auroc: 0.41059556632352234\n",
      "\n",
      "mean auprc: 0.1418778540410018\n",
      "\n",
      "max auroc: 0.502374106023741\n",
      "\n",
      "max auprc: 0.16746115101094922\n",
      "\n",
      "408.0464963912964\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13897/13914 [============================>.] - ETA: 0s - loss: 5.1956 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.2992 - rightLayer1_loss: 1.2069 - leftLayer2_loss: 0.0909 - midLayer2_loss: 1.5480 - rightLayer2_loss: 0.9435\n",
      "Epoch 00001: val_loss improved from inf to 4.60838, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 5.1953 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.2993 - rightLayer1_loss: 1.2066 - leftLayer2_loss: 0.0909 - midLayer2_loss: 1.5481 - rightLayer2_loss: 0.9433 - val_loss: 4.6084 - val_leftLayer1_loss: 0.0924 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.8649 - val_leftLayer2_loss: 0.0812 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.8783\n",
      "Epoch 2/11\n",
      "13896/13914 [============================>.] - ETA: 0s - loss: 4.4581 - leftLayer1_loss: 0.0817 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.7913 - leftLayer2_loss: 0.0528 - midLayer2_loss: 1.5456 - rightLayer2_loss: 0.6877\n",
      "Epoch 00002: val_loss improved from 4.60838 to 4.33821, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.4585 - leftLayer1_loss: 0.0817 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.7914 - leftLayer2_loss: 0.0528 - midLayer2_loss: 1.5457 - rightLayer2_loss: 0.6879 - val_loss: 4.3382 - val_leftLayer1_loss: 0.0723 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.7299 - val_leftLayer2_loss: 0.0632 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.7813\n",
      "Epoch 3/11\n",
      "13912/13914 [============================>.] - ETA: 0s - loss: 4.3349 - leftLayer1_loss: 0.0657 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.7178 - leftLayer2_loss: 0.0404 - midLayer2_loss: 1.5487 - rightLayer2_loss: 0.6630\n",
      "Epoch 00003: val_loss improved from 4.33821 to 4.23343, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.3349 - leftLayer1_loss: 0.0657 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.7178 - leftLayer2_loss: 0.0404 - midLayer2_loss: 1.5487 - rightLayer2_loss: 0.6630 - val_loss: 4.2334 - val_leftLayer1_loss: 0.0596 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6868 - val_leftLayer2_loss: 0.0543 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.7412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "13896/13914 [============================>.] - ETA: 0s - loss: 4.2774 - leftLayer1_loss: 0.0554 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6888 - leftLayer2_loss: 0.0349 - midLayer2_loss: 1.5471 - rightLayer2_loss: 0.6521\n",
      "Epoch 00004: val_loss improved from 4.23343 to 4.17619, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2779 - leftLayer1_loss: 0.0554 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6890 - leftLayer2_loss: 0.0349 - midLayer2_loss: 1.5472 - rightLayer2_loss: 0.6523 - val_loss: 4.1762 - val_leftLayer1_loss: 0.0513 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6658 - val_leftLayer2_loss: 0.0490 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.7185\n",
      "Epoch 5/11\n",
      "13902/13914 [============================>.] - ETA: 0s - loss: 4.2439 - leftLayer1_loss: 0.0485 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6732 - leftLayer2_loss: 0.0320 - midLayer2_loss: 1.5441 - rightLayer2_loss: 0.6470\n",
      "Epoch 00005: val_loss improved from 4.17619 to 4.13951, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2442 - leftLayer1_loss: 0.0485 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6733 - leftLayer2_loss: 0.0321 - midLayer2_loss: 1.5441 - rightLayer2_loss: 0.6471 - val_loss: 4.1395 - val_leftLayer1_loss: 0.0456 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6534 - val_leftLayer2_loss: 0.0456 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.7034\n",
      "Epoch 6/11\n",
      "13907/13914 [============================>.] - ETA: 0s - loss: 4.2275 - leftLayer1_loss: 0.0438 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6634 - leftLayer2_loss: 0.0304 - midLayer2_loss: 1.5475 - rightLayer2_loss: 0.6434\n",
      "Epoch 00006: val_loss improved from 4.13951 to 4.11390, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2278 - leftLayer1_loss: 0.0438 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6635 - leftLayer2_loss: 0.0304 - midLayer2_loss: 1.5475 - rightLayer2_loss: 0.6435 - val_loss: 4.1139 - val_leftLayer1_loss: 0.0416 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6451 - val_leftLayer2_loss: 0.0431 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.6926\n",
      "Epoch 7/11\n",
      "13899/13914 [============================>.] - ETA: 0s - loss: 4.2140 - leftLayer1_loss: 0.0404 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.6567 - leftLayer2_loss: 0.0293 - midLayer2_loss: 1.5472 - rightLayer2_loss: 0.6411\n",
      "Epoch 00007: val_loss improved from 4.11390 to 4.09482, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2143 - leftLayer1_loss: 0.0404 - midLayer1_loss: 1.2994 - rightLayer1_loss: 0.6568 - leftLayer2_loss: 0.0293 - midLayer2_loss: 1.5472 - rightLayer2_loss: 0.6412 - val_loss: 4.0948 - val_leftLayer1_loss: 0.0386 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6391 - val_leftLayer2_loss: 0.0412 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.6843\n",
      "Epoch 8/11\n",
      "13913/13914 [============================>.] - ETA: 0s - loss: 4.2005 - leftLayer1_loss: 0.0379 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6518 - leftLayer2_loss: 0.0285 - midLayer2_loss: 1.5442 - rightLayer2_loss: 0.6391\n",
      "Epoch 00008: val_loss improved from 4.09482 to 4.08001, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2006 - leftLayer1_loss: 0.0379 - midLayer1_loss: 1.2991 - rightLayer1_loss: 0.6519 - leftLayer2_loss: 0.0285 - midLayer2_loss: 1.5442 - rightLayer2_loss: 0.6391 - val_loss: 4.0800 - val_leftLayer1_loss: 0.0364 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6345 - val_leftLayer2_loss: 0.0398 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.6778\n",
      "Epoch 9/11\n",
      "13900/13914 [============================>.] - ETA: 0s - loss: 4.1929 - leftLayer1_loss: 0.0359 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.6478 - leftLayer2_loss: 0.0280 - midLayer2_loss: 1.5441 - rightLayer2_loss: 0.6378\n",
      "Epoch 00009: val_loss improved from 4.08001 to 4.06813, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1932 - leftLayer1_loss: 0.0359 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.6480 - leftLayer2_loss: 0.0280 - midLayer2_loss: 1.5442 - rightLayer2_loss: 0.6379 - val_loss: 4.0681 - val_leftLayer1_loss: 0.0347 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6309 - val_leftLayer2_loss: 0.0386 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.6724\n",
      "Epoch 10/11\n",
      "13893/13914 [============================>.] - ETA: 0s - loss: 4.1900 - leftLayer1_loss: 0.0344 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.6443 - leftLayer2_loss: 0.0275 - midLayer2_loss: 1.5480 - rightLayer2_loss: 0.6365\n",
      "Epoch 00010: val_loss improved from 4.06813 to 4.05839, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1906 - leftLayer1_loss: 0.0344 - midLayer1_loss: 1.2994 - rightLayer1_loss: 0.6445 - leftLayer2_loss: 0.0275 - midLayer2_loss: 1.5480 - rightLayer2_loss: 0.6367 - val_loss: 4.0584 - val_leftLayer1_loss: 0.0333 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6279 - val_leftLayer2_loss: 0.0376 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.6680\n",
      "Epoch 11/11\n",
      "13890/13914 [============================>.] - ETA: 0s - loss: 4.1848 - leftLayer1_loss: 0.0332 - midLayer1_loss: 1.2992 - rightLayer1_loss: 0.6416 - leftLayer2_loss: 0.0272 - midLayer2_loss: 1.5482 - rightLayer2_loss: 0.6354\n",
      "Epoch 00011: val_loss improved from 4.05839 to 4.05014, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1854 - leftLayer1_loss: 0.0332 - midLayer1_loss: 1.2993 - rightLayer1_loss: 0.6418 - leftLayer2_loss: 0.0272 - midLayer2_loss: 1.5482 - rightLayer2_loss: 0.6357 - val_loss: 4.0501 - val_leftLayer1_loss: 0.0322 - val_midLayer1_loss: 1.2923 - val_rightLayer1_loss: 0.6254 - val_leftLayer2_loss: 0.0368 - val_midLayer2_loss: 1.3993 - val_rightLayer2_loss: 0.6642\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Infiltration: 0.4580385334677224\n",
      "\n",
      "auprc 0Infiltration: 0.15609510384066297\n",
      "\n",
      "auroc 1Infiltration: 0.504438868698951\n",
      "\n",
      "auprc 1Infiltration: 0.16591969264115541\n",
      "\n",
      "auroc 2Infiltration: 0.4511402749648478\n",
      "\n",
      "auprc 2Infiltration: 0.1503342146966355\n",
      "\n",
      "auroc 3Infiltration: 0.47301926137916844\n",
      "\n",
      "auprc 3Infiltration: 0.1581038686779669\n",
      "\n",
      "auroc 4Infiltration: 0.4545069282173225\n",
      "\n",
      "auprc 4Infiltration: 0.1612067085501439\n",
      "\n",
      "auroc 5Infiltration: 0.45651342771597225\n",
      "\n",
      "auprc 5Infiltration: 0.15250083226175576\n",
      "\n",
      "mean auroc: 0.4662762157406641\n",
      "\n",
      "mean auprc: 0.15736007011138675\n",
      "\n",
      "max auroc: 0.504438868698951\n",
      "\n",
      "max auprc: 0.16591969264115541\n",
      "\n",
      "397.8473811149597\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13898/13914 [============================>.] - ETA: 0s - loss: 4.9855 - leftLayer1_loss: 0.1115 - midLayer1_loss: 1.3013 - rightLayer1_loss: 1.1792 - leftLayer2_loss: 0.0954 - midLayer2_loss: 1.3658 - rightLayer2_loss: 0.9324\n",
      "Epoch 00001: val_loss improved from inf to 4.48298, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.9852 - leftLayer1_loss: 0.1115 - midLayer1_loss: 1.3013 - rightLayer1_loss: 1.1789 - leftLayer2_loss: 0.0953 - midLayer2_loss: 1.3658 - rightLayer2_loss: 0.9323 - val_loss: 4.4830 - val_leftLayer1_loss: 0.0945 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.8386 - val_leftLayer2_loss: 0.0835 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.8803\n",
      "Epoch 2/11\n",
      "13910/13914 [============================>.] - ETA: 0s - loss: 4.2674 - leftLayer1_loss: 0.0831 - midLayer1_loss: 1.3012 - rightLayer1_loss: 0.7751 - leftLayer2_loss: 0.0548 - midLayer2_loss: 1.3662 - rightLayer2_loss: 0.6870\n",
      "Epoch 00002: val_loss improved from 4.48298 to 4.21921, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2674 - leftLayer1_loss: 0.0831 - midLayer1_loss: 1.3012 - rightLayer1_loss: 0.7751 - leftLayer2_loss: 0.0548 - midLayer2_loss: 1.3662 - rightLayer2_loss: 0.6871 - val_loss: 4.2192 - val_leftLayer1_loss: 0.0724 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.7147 - val_leftLayer2_loss: 0.0646 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.7815\n",
      "Epoch 3/11\n",
      "13913/13914 [============================>.] - ETA: 0s - loss: 4.1427 - leftLayer1_loss: 0.0657 - midLayer1_loss: 1.3011 - rightLayer1_loss: 0.7075 - leftLayer2_loss: 0.0413 - midLayer2_loss: 1.3650 - rightLayer2_loss: 0.6620\n",
      "Epoch 00003: val_loss improved from 4.21921 to 4.11661, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1428 - leftLayer1_loss: 0.0657 - midLayer1_loss: 1.3011 - rightLayer1_loss: 0.7075 - leftLayer2_loss: 0.0413 - midLayer2_loss: 1.3651 - rightLayer2_loss: 0.6621 - val_loss: 4.1166 - val_leftLayer1_loss: 0.0589 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6760 - val_leftLayer2_loss: 0.0552 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.7404\n",
      "Epoch 4/11\n",
      "13899/13914 [============================>.] - ETA: 0s - loss: 4.0882 - leftLayer1_loss: 0.0550 - midLayer1_loss: 1.3010 - rightLayer1_loss: 0.6811 - leftLayer2_loss: 0.0355 - midLayer2_loss: 1.3640 - rightLayer2_loss: 0.6517\n",
      "Epoch 00004: val_loss improved from 4.11661 to 4.06061, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 4.0885 - leftLayer1_loss: 0.0550 - midLayer1_loss: 1.3010 - rightLayer1_loss: 0.6812 - leftLayer2_loss: 0.0355 - midLayer2_loss: 1.3640 - rightLayer2_loss: 0.6519 - val_loss: 4.0606 - val_leftLayer1_loss: 0.0503 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6574 - val_leftLayer2_loss: 0.0497 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.7171\n",
      "Epoch 5/11\n",
      "13894/13914 [============================>.] - ETA: 0s - loss: 4.0589 - leftLayer1_loss: 0.0480 - midLayer1_loss: 1.3007 - rightLayer1_loss: 0.6671 - leftLayer2_loss: 0.0325 - midLayer2_loss: 1.3644 - rightLayer2_loss: 0.6461\n",
      "Epoch 00005: val_loss improved from 4.06061 to 4.02477, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0593 - leftLayer1_loss: 0.0480 - midLayer1_loss: 1.3008 - rightLayer1_loss: 0.6673 - leftLayer2_loss: 0.0325 - midLayer2_loss: 1.3645 - rightLayer2_loss: 0.6463 - val_loss: 4.0248 - val_leftLayer1_loss: 0.0446 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6464 - val_leftLayer2_loss: 0.0461 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.7015\n",
      "Epoch 6/11\n",
      "13905/13914 [============================>.] - ETA: 0s - loss: 4.0416 - leftLayer1_loss: 0.0432 - midLayer1_loss: 1.3012 - rightLayer1_loss: 0.6585 - leftLayer2_loss: 0.0307 - midLayer2_loss: 1.3656 - rightLayer2_loss: 0.6425\n",
      "Epoch 00006: val_loss improved from 4.02477 to 3.99984, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0418 - leftLayer1_loss: 0.0432 - midLayer1_loss: 1.3012 - rightLayer1_loss: 0.6585 - leftLayer2_loss: 0.0307 - midLayer2_loss: 1.3656 - rightLayer2_loss: 0.6426 - val_loss: 3.9998 - val_leftLayer1_loss: 0.0407 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6392 - val_leftLayer2_loss: 0.0435 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.6904\n",
      "Epoch 7/11\n",
      "13891/13914 [============================>.] - ETA: 0s - loss: 4.0252 - leftLayer1_loss: 0.0398 - midLayer1_loss: 1.3015 - rightLayer1_loss: 0.6521 - leftLayer2_loss: 0.0295 - midLayer2_loss: 1.3625 - rightLayer2_loss: 0.6397\n",
      "Epoch 00007: val_loss improved from 3.99984 to 3.98141, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0257 - leftLayer1_loss: 0.0398 - midLayer1_loss: 1.3015 - rightLayer1_loss: 0.6523 - leftLayer2_loss: 0.0295 - midLayer2_loss: 1.3627 - rightLayer2_loss: 0.6399 - val_loss: 3.9814 - val_leftLayer1_loss: 0.0378 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6339 - val_leftLayer2_loss: 0.0416 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.6820\n",
      "Epoch 8/11\n",
      "13910/13914 [============================>.] - ETA: 0s - loss: 4.0174 - leftLayer1_loss: 0.0373 - midLayer1_loss: 1.3015 - rightLayer1_loss: 0.6478 - leftLayer2_loss: 0.0287 - midLayer2_loss: 1.3641 - rightLayer2_loss: 0.6380\n",
      "Epoch 00008: val_loss improved from 3.98141 to 3.96714, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0175 - leftLayer1_loss: 0.0373 - midLayer1_loss: 1.3015 - rightLayer1_loss: 0.6478 - leftLayer2_loss: 0.0287 - midLayer2_loss: 1.3641 - rightLayer2_loss: 0.6381 - val_loss: 3.9671 - val_leftLayer1_loss: 0.0356 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6300 - val_leftLayer2_loss: 0.0401 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.6754\n",
      "Epoch 9/11\n",
      "13902/13914 [============================>.] - ETA: 0s - loss: 4.0091 - leftLayer1_loss: 0.0354 - midLayer1_loss: 1.3011 - rightLayer1_loss: 0.6441 - leftLayer2_loss: 0.0281 - midLayer2_loss: 1.3636 - rightLayer2_loss: 0.6367\n",
      "Epoch 00009: val_loss improved from 3.96714 to 3.95563, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 4.0093 - leftLayer1_loss: 0.0355 - midLayer1_loss: 1.3011 - rightLayer1_loss: 0.6442 - leftLayer2_loss: 0.0281 - midLayer2_loss: 1.3636 - rightLayer2_loss: 0.6368 - val_loss: 3.9556 - val_leftLayer1_loss: 0.0340 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6268 - val_leftLayer2_loss: 0.0389 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.6699\n",
      "Epoch 10/11\n",
      "13892/13914 [============================>.] - ETA: 0s - loss: 4.0028 - leftLayer1_loss: 0.0339 - midLayer1_loss: 1.3014 - rightLayer1_loss: 0.6412 - leftLayer2_loss: 0.0277 - midLayer2_loss: 1.3631 - rightLayer2_loss: 0.6355\n",
      "Epoch 00010: val_loss improved from 3.95563 to 3.94615, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 4.0034 - leftLayer1_loss: 0.0339 - midLayer1_loss: 1.3015 - rightLayer1_loss: 0.6414 - leftLayer2_loss: 0.0277 - midLayer2_loss: 1.3632 - rightLayer2_loss: 0.6357 - val_loss: 3.9462 - val_leftLayer1_loss: 0.0327 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6242 - val_leftLayer2_loss: 0.0379 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.6653\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13908/13914 [============================>.] - ETA: 0s - loss: 4.0006 - leftLayer1_loss: 0.0328 - midLayer1_loss: 1.3014 - rightLayer1_loss: 0.6388 - leftLayer2_loss: 0.0273 - midLayer2_loss: 1.3658 - rightLayer2_loss: 0.6346\n",
      "Epoch 00011: val_loss improved from 3.94615 to 3.93818, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.0009 - leftLayer1_loss: 0.0328 - midLayer1_loss: 1.3014 - rightLayer1_loss: 0.6389 - leftLayer2_loss: 0.0273 - midLayer2_loss: 1.3658 - rightLayer2_loss: 0.6347 - val_loss: 3.9382 - val_leftLayer1_loss: 0.0316 - val_midLayer1_loss: 1.2977 - val_rightLayer1_loss: 0.6221 - val_leftLayer2_loss: 0.0370 - val_midLayer2_loss: 1.2884 - val_rightLayer2_loss: 0.6614\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Infiltration: 0.4118709145581877\n",
      "\n",
      "auprc 0Infiltration: 0.14500530931553396\n",
      "\n",
      "auroc 1Infiltration: 0.3992720981649742\n",
      "\n",
      "auprc 1Infiltration: 0.13853827686065215\n",
      "\n",
      "auroc 2Infiltration: 0.3935724121284616\n",
      "\n",
      "auprc 2Infiltration: 0.1387344833488518\n",
      "\n",
      "auroc 3Infiltration: 0.4313204356632975\n",
      "\n",
      "auprc 3Infiltration: 0.14840658569212103\n",
      "\n",
      "auroc 4Infiltration: 0.5982636378876643\n",
      "\n",
      "auprc 4Infiltration: 0.2406326659418536\n",
      "\n",
      "auroc 5Infiltration: 0.4107148913045418\n",
      "\n",
      "auprc 5Infiltration: 0.14234193275818824\n",
      "\n",
      "mean auroc: 0.44083573161785444\n",
      "\n",
      "mean auprc: 0.15894320898620015\n",
      "\n",
      "max auroc: 0.5982636378876643\n",
      "\n",
      "max auprc: 0.2406326659418536\n",
      "\n",
      "413.445583820343\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13904/13914 [============================>.] - ETA: 0s - loss: 5.1068 - leftLayer1_loss: 0.1073 - midLayer1_loss: 1.3863 - rightLayer1_loss: 1.1772 - leftLayer2_loss: 0.0946 - midLayer2_loss: 1.4040 - rightLayer2_loss: 0.9374\n",
      "Epoch 00001: val_loss improved from inf to 4.64008, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 5.1066 - leftLayer1_loss: 0.1073 - midLayer1_loss: 1.3863 - rightLayer1_loss: 1.1770 - leftLayer2_loss: 0.0946 - midLayer2_loss: 1.4040 - rightLayer2_loss: 0.9374 - val_loss: 4.6401 - val_leftLayer1_loss: 0.0917 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.8456 - val_leftLayer2_loss: 0.0859 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.9266\n",
      "Epoch 2/11\n",
      "13901/13914 [============================>.] - ETA: 0s - loss: 4.3982 - leftLayer1_loss: 0.0805 - midLayer1_loss: 1.3855 - rightLayer1_loss: 0.7783 - leftLayer2_loss: 0.0558 - midLayer2_loss: 1.4042 - rightLayer2_loss: 0.6939\n",
      "Epoch 00002: val_loss improved from 4.64008 to 4.36889, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.3985 - leftLayer1_loss: 0.0805 - midLayer1_loss: 1.3855 - rightLayer1_loss: 0.7784 - leftLayer2_loss: 0.0558 - midLayer2_loss: 1.4042 - rightLayer2_loss: 0.6940 - val_loss: 4.3689 - val_leftLayer1_loss: 0.0709 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.7205 - val_leftLayer2_loss: 0.0678 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.8195\n",
      "Epoch 3/11\n",
      "13904/13914 [============================>.] - ETA: 0s - loss: 4.2735 - leftLayer1_loss: 0.0642 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.7098 - leftLayer2_loss: 0.0422 - midLayer2_loss: 1.4048 - rightLayer2_loss: 0.6666\n",
      "Epoch 00003: val_loss improved from 4.36889 to 4.26100, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 4.2737 - leftLayer1_loss: 0.0642 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.7099 - leftLayer2_loss: 0.0422 - midLayer2_loss: 1.4048 - rightLayer2_loss: 0.6667 - val_loss: 4.2610 - val_leftLayer1_loss: 0.0581 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6805 - val_leftLayer2_loss: 0.0585 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.7736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "13910/13914 [============================>.] - ETA: 0s - loss: 4.2187 - leftLayer1_loss: 0.0540 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.6831 - leftLayer2_loss: 0.0362 - midLayer2_loss: 1.4041 - rightLayer2_loss: 0.6554\n",
      "Epoch 00004: val_loss improved from 4.26100 to 4.20107, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 35s 2ms/step - loss: 4.2187 - leftLayer1_loss: 0.0540 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.6831 - leftLayer2_loss: 0.0362 - midLayer2_loss: 1.4041 - rightLayer2_loss: 0.6554 - val_loss: 4.2011 - val_leftLayer1_loss: 0.0499 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6610 - val_leftLayer2_loss: 0.0529 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.7470\n",
      "Epoch 5/11\n",
      "13902/13914 [============================>.] - ETA: 0s - loss: 4.1887 - leftLayer1_loss: 0.0472 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.6685 - leftLayer2_loss: 0.0330 - midLayer2_loss: 1.4049 - rightLayer2_loss: 0.6491\n",
      "Epoch 00005: val_loss improved from 4.20107 to 4.16240, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.1889 - leftLayer1_loss: 0.0472 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6686 - leftLayer2_loss: 0.0330 - midLayer2_loss: 1.4049 - rightLayer2_loss: 0.6492 - val_loss: 4.1624 - val_leftLayer1_loss: 0.0444 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6494 - val_leftLayer2_loss: 0.0491 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.7292\n",
      "Epoch 6/11\n",
      "13899/13914 [============================>.] - ETA: 0s - loss: 4.1718 - leftLayer1_loss: 0.0427 - midLayer1_loss: 1.3863 - rightLayer1_loss: 0.6591 - leftLayer2_loss: 0.0311 - midLayer2_loss: 1.4073 - rightLayer2_loss: 0.6453\n",
      "Epoch 00006: val_loss improved from 4.16240 to 4.13507, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.1721 - leftLayer1_loss: 0.0427 - midLayer1_loss: 1.3863 - rightLayer1_loss: 0.6593 - leftLayer2_loss: 0.0312 - midLayer2_loss: 1.4073 - rightLayer2_loss: 0.6455 - val_loss: 4.1351 - val_leftLayer1_loss: 0.0406 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6416 - val_leftLayer2_loss: 0.0464 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.7162\n",
      "Epoch 7/11\n",
      "13891/13914 [============================>.] - ETA: 0s - loss: 4.1543 - leftLayer1_loss: 0.0394 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6528 - leftLayer2_loss: 0.0299 - midLayer2_loss: 1.4040 - rightLayer2_loss: 0.6423\n",
      "Epoch 00007: val_loss improved from 4.13507 to 4.11468, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.1547 - leftLayer1_loss: 0.0394 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6530 - leftLayer2_loss: 0.0299 - midLayer2_loss: 1.4040 - rightLayer2_loss: 0.6424 - val_loss: 4.1147 - val_leftLayer1_loss: 0.0378 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6360 - val_leftLayer2_loss: 0.0444 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.7063\n",
      "Epoch 8/11\n",
      "13896/13914 [============================>.] - ETA: 0s - loss: 4.1451 - leftLayer1_loss: 0.0370 - midLayer1_loss: 1.3857 - rightLayer1_loss: 0.6480 - leftLayer2_loss: 0.0290 - midLayer2_loss: 1.4050 - rightLayer2_loss: 0.6403\n",
      "Epoch 00008: val_loss improved from 4.11468 to 4.09874, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 35s 3ms/step - loss: 4.1456 - leftLayer1_loss: 0.0370 - midLayer1_loss: 1.3857 - rightLayer1_loss: 0.6482 - leftLayer2_loss: 0.0290 - midLayer2_loss: 1.4050 - rightLayer2_loss: 0.6405 - val_loss: 4.0987 - val_leftLayer1_loss: 0.0356 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6316 - val_leftLayer2_loss: 0.0428 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.6984\n",
      "Epoch 9/11\n",
      "13891/13914 [============================>.] - ETA: 0s - loss: 4.1370 - leftLayer1_loss: 0.0352 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6443 - leftLayer2_loss: 0.0284 - midLayer2_loss: 1.4045 - rightLayer2_loss: 0.6387\n",
      "Epoch 00009: val_loss improved from 4.09874 to 4.08586, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 36s 3ms/step - loss: 4.1375 - leftLayer1_loss: 0.0352 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6444 - leftLayer2_loss: 0.0284 - midLayer2_loss: 1.4046 - rightLayer2_loss: 0.6388 - val_loss: 4.0859 - val_leftLayer1_loss: 0.0340 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6281 - val_leftLayer2_loss: 0.0415 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.6920\n",
      "Epoch 10/11\n",
      "13904/13914 [============================>.] - ETA: 0s - loss: 4.1326 - leftLayer1_loss: 0.0337 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6410 - leftLayer2_loss: 0.0279 - midLayer2_loss: 1.4066 - rightLayer2_loss: 0.6374\n",
      "Epoch 00010: val_loss improved from 4.08586 to 4.07517, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1328 - leftLayer1_loss: 0.0337 - midLayer1_loss: 1.3860 - rightLayer1_loss: 0.6411 - leftLayer2_loss: 0.0279 - midLayer2_loss: 1.4065 - rightLayer2_loss: 0.6375 - val_loss: 4.0752 - val_leftLayer1_loss: 0.0327 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6252 - val_leftLayer2_loss: 0.0404 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.6865\n",
      "Epoch 11/11\n",
      "13911/13914 [============================>.] - ETA: 0s - loss: 4.1267 - leftLayer1_loss: 0.0326 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.6386 - leftLayer2_loss: 0.0276 - midLayer2_loss: 1.4052 - rightLayer2_loss: 0.6368\n",
      "Epoch 00011: val_loss improved from 4.07517 to 4.06608, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1266 - leftLayer1_loss: 0.0326 - midLayer1_loss: 1.3859 - rightLayer1_loss: 0.6386 - leftLayer2_loss: 0.0276 - midLayer2_loss: 1.4051 - rightLayer2_loss: 0.6368 - val_loss: 4.0661 - val_leftLayer1_loss: 0.0317 - val_midLayer1_loss: 1.3749 - val_rightLayer1_loss: 0.6227 - val_leftLayer2_loss: 0.0395 - val_midLayer2_loss: 1.3154 - val_rightLayer2_loss: 0.6819\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Infiltration: 0.46141847047731316\n",
      "\n",
      "auprc 0Infiltration: 0.15772077464336112\n",
      "\n",
      "auroc 1Infiltration: 0.40615674339117636\n",
      "\n",
      "auprc 1Infiltration: 0.14809341982184507\n",
      "\n",
      "auroc 2Infiltration: 0.4327470974475827\n",
      "\n",
      "auprc 2Infiltration: 0.14546154382463491\n",
      "\n",
      "auroc 3Infiltration: 0.46025869207372283\n",
      "\n",
      "auprc 3Infiltration: 0.15381090606397016\n",
      "\n",
      "auroc 4Infiltration: 0.4378421356931327\n",
      "\n",
      "auprc 4Infiltration: 0.15137085717606433\n",
      "\n",
      "auroc 5Infiltration: 0.47370921354528583\n",
      "\n",
      "auprc 5Infiltration: 0.15772595815375431\n",
      "\n",
      "mean auroc: 0.44535539210470226\n",
      "\n",
      "mean auprc: 0.15236390994727167\n",
      "\n",
      "max auroc: 0.47370921354528583\n",
      "\n",
      "max auprc: 0.15772595815375431\n",
      "\n",
      "411.2750096321106\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13907/13914 [============================>.] - ETA: 0s - loss: 4.9902 - leftLayer1_loss: 0.1074 - midLayer1_loss: 1.3465 - rightLayer1_loss: 1.2202 - leftLayer2_loss: 0.0901 - midLayer2_loss: 1.3017 - rightLayer2_loss: 0.9242\n",
      "Epoch 00001: val_loss improved from inf to 4.59230, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.9901 - leftLayer1_loss: 0.1074 - midLayer1_loss: 1.3465 - rightLayer1_loss: 1.2201 - leftLayer2_loss: 0.0901 - midLayer2_loss: 1.3018 - rightLayer2_loss: 0.9242 - val_loss: 4.5923 - val_leftLayer1_loss: 0.0936 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.8804 - val_leftLayer2_loss: 0.0845 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.9062\n",
      "Epoch 2/11\n",
      "13897/13914 [============================>.] - ETA: 0s - loss: 4.2796 - leftLayer1_loss: 0.0833 - midLayer1_loss: 1.3465 - rightLayer1_loss: 0.8042 - leftLayer2_loss: 0.0541 - midLayer2_loss: 1.3008 - rightLayer2_loss: 0.6907\n",
      "Epoch 00002: val_loss improved from 4.59230 to 4.30872, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 4.2798 - leftLayer1_loss: 0.0833 - midLayer1_loss: 1.3465 - rightLayer1_loss: 0.8043 - leftLayer2_loss: 0.0541 - midLayer2_loss: 1.3008 - rightLayer2_loss: 0.6908 - val_loss: 4.3087 - val_leftLayer1_loss: 0.0741 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.7378 - val_leftLayer2_loss: 0.0669 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.8023\n",
      "Epoch 3/11\n",
      "13896/13914 [============================>.] - ETA: 0s - loss: 4.1444 - leftLayer1_loss: 0.0676 - midLayer1_loss: 1.3464 - rightLayer1_loss: 0.7249 - leftLayer2_loss: 0.0414 - midLayer2_loss: 1.3004 - rightLayer2_loss: 0.6637\n",
      "Epoch 00003: val_loss improved from 4.30872 to 4.19736, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 4.1448 - leftLayer1_loss: 0.0676 - midLayer1_loss: 1.3464 - rightLayer1_loss: 0.7251 - leftLayer2_loss: 0.0414 - midLayer2_loss: 1.3004 - rightLayer2_loss: 0.6639 - val_loss: 4.1974 - val_leftLayer1_loss: 0.0614 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6920 - val_leftLayer2_loss: 0.0578 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.7585\n",
      "Epoch 4/11\n",
      "13895/13914 [============================>.] - ETA: 0s - loss: 4.0863 - leftLayer1_loss: 0.0572 - midLayer1_loss: 1.3466 - rightLayer1_loss: 0.6936 - leftLayer2_loss: 0.0357 - midLayer2_loss: 1.2999 - rightLayer2_loss: 0.6532\n",
      "Epoch 00004: val_loss improved from 4.19736 to 4.13586, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 4.0866 - leftLayer1_loss: 0.0572 - midLayer1_loss: 1.3466 - rightLayer1_loss: 0.6937 - leftLayer2_loss: 0.0357 - midLayer2_loss: 1.3000 - rightLayer2_loss: 0.6533 - val_loss: 4.1359 - val_leftLayer1_loss: 0.0530 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6697 - val_leftLayer2_loss: 0.0523 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.7333\n",
      "Epoch 5/11\n",
      "13895/13914 [============================>.] - ETA: 0s - loss: 4.0522 - leftLayer1_loss: 0.0502 - midLayer1_loss: 1.3462 - rightLayer1_loss: 0.6770 - leftLayer2_loss: 0.0327 - midLayer2_loss: 1.2986 - rightLayer2_loss: 0.6474\n",
      "Epoch 00005: val_loss improved from 4.13586 to 4.09621, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 4.0526 - leftLayer1_loss: 0.0502 - midLayer1_loss: 1.3462 - rightLayer1_loss: 0.6771 - leftLayer2_loss: 0.0327 - midLayer2_loss: 1.2987 - rightLayer2_loss: 0.6476 - val_loss: 4.0962 - val_leftLayer1_loss: 0.0471 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6564 - val_leftLayer2_loss: 0.0486 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.7165\n",
      "Epoch 6/11\n",
      "13890/13914 [============================>.] - ETA: 0s - loss: 4.0333 - leftLayer1_loss: 0.0453 - midLayer1_loss: 1.3462 - rightLayer1_loss: 0.6664 - leftLayer2_loss: 0.0309 - midLayer2_loss: 1.3010 - rightLayer2_loss: 0.6436\n",
      "Epoch 00006: val_loss improved from 4.09621 to 4.06830, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0339 - leftLayer1_loss: 0.0453 - midLayer1_loss: 1.3462 - rightLayer1_loss: 0.6666 - leftLayer2_loss: 0.0309 - midLayer2_loss: 1.3011 - rightLayer2_loss: 0.6438 - val_loss: 4.0683 - val_leftLayer1_loss: 0.0429 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6476 - val_leftLayer2_loss: 0.0460 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.7042\n",
      "Epoch 7/11\n",
      "13906/13914 [============================>.] - ETA: 0s - loss: 4.0184 - leftLayer1_loss: 0.0417 - midLayer1_loss: 1.3463 - rightLayer1_loss: 0.6590 - leftLayer2_loss: 0.0298 - midLayer2_loss: 1.3004 - rightLayer2_loss: 0.6413\n",
      "Epoch 00007: val_loss improved from 4.06830 to 4.04741, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0187 - leftLayer1_loss: 0.0417 - midLayer1_loss: 1.3463 - rightLayer1_loss: 0.6590 - leftLayer2_loss: 0.0298 - midLayer2_loss: 1.3005 - rightLayer2_loss: 0.6414 - val_loss: 4.0474 - val_leftLayer1_loss: 0.0398 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6413 - val_leftLayer2_loss: 0.0439 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.6948\n",
      "Epoch 8/11\n",
      "13906/13914 [============================>.] - ETA: 0s - loss: 4.0092 - leftLayer1_loss: 0.0390 - midLayer1_loss: 1.3465 - rightLayer1_loss: 0.6538 - leftLayer2_loss: 0.0289 - midLayer2_loss: 1.3015 - rightLayer2_loss: 0.6394\n",
      "Epoch 00008: val_loss improved from 4.04741 to 4.03116, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 4.0093 - leftLayer1_loss: 0.0390 - midLayer1_loss: 1.3466 - rightLayer1_loss: 0.6538 - leftLayer2_loss: 0.0289 - midLayer2_loss: 1.3014 - rightLayer2_loss: 0.6395 - val_loss: 4.0312 - val_leftLayer1_loss: 0.0374 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6364 - val_leftLayer2_loss: 0.0423 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.6873\n",
      "Epoch 9/11\n",
      "13904/13914 [============================>.] - ETA: 0s - loss: 3.9990 - leftLayer1_loss: 0.0370 - midLayer1_loss: 1.3465 - rightLayer1_loss: 0.6496 - leftLayer2_loss: 0.0283 - midLayer2_loss: 1.3001 - rightLayer2_loss: 0.6375\n",
      "Epoch 00009: val_loss improved from 4.03116 to 4.01815, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 3.9993 - leftLayer1_loss: 0.0370 - midLayer1_loss: 1.3465 - rightLayer1_loss: 0.6497 - leftLayer2_loss: 0.0283 - midLayer2_loss: 1.3002 - rightLayer2_loss: 0.6376 - val_loss: 4.0181 - val_leftLayer1_loss: 0.0356 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6326 - val_leftLayer2_loss: 0.0410 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.6813\n",
      "Epoch 10/11\n",
      "13903/13914 [============================>.] - ETA: 0s - loss: 3.9893 - leftLayer1_loss: 0.0353 - midLayer1_loss: 1.3464 - rightLayer1_loss: 0.6462 - leftLayer2_loss: 0.0278 - midLayer2_loss: 1.2971 - rightLayer2_loss: 0.6364\n",
      "Epoch 00010: val_loss improved from 4.01815 to 4.00741, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 3.9895 - leftLayer1_loss: 0.0353 - midLayer1_loss: 1.3464 - rightLayer1_loss: 0.6462 - leftLayer2_loss: 0.0278 - midLayer2_loss: 1.2971 - rightLayer2_loss: 0.6365 - val_loss: 4.0074 - val_leftLayer1_loss: 0.0341 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6295 - val_leftLayer2_loss: 0.0400 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.6762\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13907/13914 [============================>.] - ETA: 0s - loss: 3.9848 - leftLayer1_loss: 0.0340 - midLayer1_loss: 1.3463 - rightLayer1_loss: 0.6433 - leftLayer2_loss: 0.0275 - midLayer2_loss: 1.2983 - rightLayer2_loss: 0.6355\n",
      "Epoch 00011: val_loss improved from 4.00741 to 3.99833, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "13914/13914 [==============================] - 33s 2ms/step - loss: 3.9851 - leftLayer1_loss: 0.0340 - midLayer1_loss: 1.3463 - rightLayer1_loss: 0.6434 - leftLayer2_loss: 0.0275 - midLayer2_loss: 1.2983 - rightLayer2_loss: 0.6356 - val_loss: 3.9983 - val_leftLayer1_loss: 0.0329 - val_midLayer1_loss: 1.3435 - val_rightLayer1_loss: 0.6269 - val_leftLayer2_loss: 0.0391 - val_midLayer2_loss: 1.2841 - val_rightLayer2_loss: 0.6718\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Infiltration: 0.4312245592023759\n",
      "\n",
      "auprc 0Infiltration: 0.1461606771739267\n",
      "\n",
      "auroc 1Infiltration: 0.5885596507971422\n",
      "\n",
      "auprc 1Infiltration: 0.214805773071767\n",
      "\n",
      "auroc 2Infiltration: 0.4073538810744699\n",
      "\n",
      "auprc 2Infiltration: 0.14006075509631263\n",
      "\n",
      "auroc 3Infiltration: 0.40498719610573786\n",
      "\n",
      "auprc 3Infiltration: 0.14029845306715868\n",
      "\n",
      "auroc 4Infiltration: 0.4267308941471972\n",
      "\n",
      "auprc 4Infiltration: 0.14312411996872287\n",
      "\n",
      "auroc 5Infiltration: 0.44136885307011314\n",
      "\n",
      "auprc 5Infiltration: 0.1493590106534098\n",
      "\n",
      "mean auroc: 0.45003750573283935\n",
      "\n",
      "mean auprc: 0.15563479817188294\n",
      "\n",
      "max auroc: 0.5885596507971422\n",
      "\n",
      "max auprc: 0.214805773071767\n",
      "\n",
      "395.4628713130951\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 13914 steps, validate for 2018 steps\n",
      "Epoch 1/11\n",
      "13893/13914 [============================>.] - ETA: 0s - loss: 4.9940 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.3123 - rightLayer1_loss: 1.1773 - leftLayer2_loss: 0.0919 - midLayer2_loss: 1.3591 - rightLayer2_loss: 0.9455\n",
      "Epoch 00001: val_loss improved from inf to 4.55355, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 35s 2ms/step - loss: 4.9933 - leftLayer1_loss: 0.1079 - midLayer1_loss: 1.3123 - rightLayer1_loss: 1.1769 - leftLayer2_loss: 0.0919 - midLayer2_loss: 1.3590 - rightLayer2_loss: 0.9453 - val_loss: 4.5535 - val_leftLayer1_loss: 0.0919 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.8411 - val_leftLayer2_loss: 0.0851 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.9042\n",
      "Epoch 2/11\n",
      "13897/13914 [============================>.] - ETA: 0s - loss: 4.2736 - leftLayer1_loss: 0.0811 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.7789 - leftLayer2_loss: 0.0545 - midLayer2_loss: 1.3554 - rightLayer2_loss: 0.6910\n",
      "Epoch 00002: val_loss improved from 4.55355 to 4.28809, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.2738 - leftLayer1_loss: 0.0811 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.7789 - leftLayer2_loss: 0.0545 - midLayer2_loss: 1.3555 - rightLayer2_loss: 0.6911 - val_loss: 4.2881 - val_leftLayer1_loss: 0.0710 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.7173 - val_leftLayer2_loss: 0.0672 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.8014\n",
      "Epoch 3/11\n",
      "13903/13914 [============================>.] - ETA: 0s - loss: 4.1485 - leftLayer1_loss: 0.0647 - midLayer1_loss: 1.3121 - rightLayer1_loss: 0.7102 - leftLayer2_loss: 0.0415 - midLayer2_loss: 1.3560 - rightLayer2_loss: 0.6641\n",
      "Epoch 00003: val_loss improved from 4.28809 to 4.18382, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.1488 - leftLayer1_loss: 0.0647 - midLayer1_loss: 1.3121 - rightLayer1_loss: 0.7103 - leftLayer2_loss: 0.0415 - midLayer2_loss: 1.3561 - rightLayer2_loss: 0.6642 - val_loss: 4.1838 - val_leftLayer1_loss: 0.0581 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6782 - val_leftLayer2_loss: 0.0580 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.7583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "13898/13914 [============================>.] - ETA: 0s - loss: 4.0950 - leftLayer1_loss: 0.0544 - midLayer1_loss: 1.3124 - rightLayer1_loss: 0.6835 - leftLayer2_loss: 0.0357 - midLayer2_loss: 1.3558 - rightLayer2_loss: 0.6533\n",
      "Epoch 00004: val_loss improved from 4.18382 to 4.12611, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0954 - leftLayer1_loss: 0.0544 - midLayer1_loss: 1.3124 - rightLayer1_loss: 0.6837 - leftLayer2_loss: 0.0357 - midLayer2_loss: 1.3558 - rightLayer2_loss: 0.6535 - val_loss: 4.1261 - val_leftLayer1_loss: 0.0499 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6592 - val_leftLayer2_loss: 0.0525 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.7333\n",
      "Epoch 5/11\n",
      "13894/13914 [============================>.] - ETA: 0s - loss: 4.0684 - leftLayer1_loss: 0.0476 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.6690 - leftLayer2_loss: 0.0327 - midLayer2_loss: 1.3590 - rightLayer2_loss: 0.6476\n",
      "Epoch 00005: val_loss improved from 4.12611 to 4.08900, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0688 - leftLayer1_loss: 0.0476 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.6691 - leftLayer2_loss: 0.0327 - midLayer2_loss: 1.3590 - rightLayer2_loss: 0.6478 - val_loss: 4.0890 - val_leftLayer1_loss: 0.0443 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6480 - val_leftLayer2_loss: 0.0488 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.7167\n",
      "Epoch 6/11\n",
      "13891/13914 [============================>.] - ETA: 0s - loss: 4.0459 - leftLayer1_loss: 0.0430 - midLayer1_loss: 1.3124 - rightLayer1_loss: 0.6599 - leftLayer2_loss: 0.0308 - midLayer2_loss: 1.3562 - rightLayer2_loss: 0.6436\n",
      "Epoch 00006: val_loss improved from 4.08900 to 4.06295, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0463 - leftLayer1_loss: 0.0430 - midLayer1_loss: 1.3125 - rightLayer1_loss: 0.6600 - leftLayer2_loss: 0.0308 - midLayer2_loss: 1.3562 - rightLayer2_loss: 0.6438 - val_loss: 4.0630 - val_leftLayer1_loss: 0.0405 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6405 - val_leftLayer2_loss: 0.0461 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.7047\n",
      "Epoch 7/11\n",
      "13905/13914 [============================>.] - ETA: 0s - loss: 4.0346 - leftLayer1_loss: 0.0397 - midLayer1_loss: 1.3121 - rightLayer1_loss: 0.6537 - leftLayer2_loss: 0.0297 - midLayer2_loss: 1.3580 - rightLayer2_loss: 0.6415\n",
      "Epoch 00007: val_loss improved from 4.06295 to 4.04340, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0348 - leftLayer1_loss: 0.0397 - midLayer1_loss: 1.3121 - rightLayer1_loss: 0.6538 - leftLayer2_loss: 0.0297 - midLayer2_loss: 1.3580 - rightLayer2_loss: 0.6416 - val_loss: 4.0434 - val_leftLayer1_loss: 0.0376 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6351 - val_leftLayer2_loss: 0.0441 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.6954\n",
      "Epoch 8/11\n",
      "13897/13914 [============================>.] - ETA: 0s - loss: 4.0221 - leftLayer1_loss: 0.0372 - midLayer1_loss: 1.3124 - rightLayer1_loss: 0.6487 - leftLayer2_loss: 0.0288 - midLayer2_loss: 1.3560 - rightLayer2_loss: 0.6391\n",
      "Epoch 00008: val_loss improved from 4.04340 to 4.02832, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0226 - leftLayer1_loss: 0.0372 - midLayer1_loss: 1.3124 - rightLayer1_loss: 0.6488 - leftLayer2_loss: 0.0288 - midLayer2_loss: 1.3560 - rightLayer2_loss: 0.6393 - val_loss: 4.0283 - val_leftLayer1_loss: 0.0355 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6309 - val_leftLayer2_loss: 0.0425 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.6881\n",
      "Epoch 9/11\n",
      "13910/13914 [============================>.] - ETA: 0s - loss: 4.0171 - leftLayer1_loss: 0.0354 - midLayer1_loss: 1.3126 - rightLayer1_loss: 0.6453 - leftLayer2_loss: 0.0282 - midLayer2_loss: 1.3576 - rightLayer2_loss: 0.6379\n",
      "Epoch 00009: val_loss improved from 4.02832 to 4.01610, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0171 - leftLayer1_loss: 0.0354 - midLayer1_loss: 1.3127 - rightLayer1_loss: 0.6453 - leftLayer2_loss: 0.0282 - midLayer2_loss: 1.3576 - rightLayer2_loss: 0.6379 - val_loss: 4.0161 - val_leftLayer1_loss: 0.0339 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6276 - val_leftLayer2_loss: 0.0412 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.6821\n",
      "Epoch 10/11\n",
      "13895/13914 [============================>.] - ETA: 0s - loss: 4.0077 - leftLayer1_loss: 0.0339 - midLayer1_loss: 1.3122 - rightLayer1_loss: 0.6421 - leftLayer2_loss: 0.0277 - midLayer2_loss: 1.3553 - rightLayer2_loss: 0.6365\n",
      "Epoch 00010: val_loss improved from 4.01610 to 4.00603, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0081 - leftLayer1_loss: 0.0339 - midLayer1_loss: 1.3123 - rightLayer1_loss: 0.6423 - leftLayer2_loss: 0.0277 - midLayer2_loss: 1.3553 - rightLayer2_loss: 0.6366 - val_loss: 4.0060 - val_leftLayer1_loss: 0.0326 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6249 - val_leftLayer2_loss: 0.0401 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.6771\n",
      "Epoch 11/11\n",
      "13893/13914 [============================>.] - ETA: 0s - loss: 4.0025 - leftLayer1_loss: 0.0327 - midLayer1_loss: 1.3123 - rightLayer1_loss: 0.6395 - leftLayer2_loss: 0.0274 - midLayer2_loss: 1.3548 - rightLayer2_loss: 0.6358\n",
      "Epoch 00011: val_loss improved from 4.00603 to 3.99743, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "13914/13914 [==============================] - 34s 2ms/step - loss: 4.0029 - leftLayer1_loss: 0.0327 - midLayer1_loss: 1.3123 - rightLayer1_loss: 0.6397 - leftLayer2_loss: 0.0274 - midLayer2_loss: 1.3548 - rightLayer2_loss: 0.6360 - val_loss: 3.9974 - val_leftLayer1_loss: 0.0316 - val_midLayer1_loss: 1.3058 - val_rightLayer1_loss: 0.6226 - val_leftLayer2_loss: 0.0392 - val_midLayer2_loss: 1.3255 - val_rightLayer2_loss: 0.6728\n",
      "22433/22433 [==============================] - 27s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Infiltration: 0.3918745900742394\n",
      "\n",
      "auprc 0Infiltration: 0.13854368119473678\n",
      "\n",
      "auroc 1Infiltration: 0.44940258790929594\n",
      "\n",
      "auprc 1Infiltration: 0.151032633561404\n",
      "\n",
      "auroc 2Infiltration: 0.3819559759126696\n",
      "\n",
      "auprc 2Infiltration: 0.13480468151660324\n",
      "\n",
      "auroc 3Infiltration: 0.4184915391048409\n",
      "\n",
      "auprc 3Infiltration: 0.14295238393024762\n",
      "\n",
      "auroc 4Infiltration: 0.43645319703306085\n",
      "\n",
      "auprc 4Infiltration: 0.15098506191953226\n",
      "\n",
      "auroc 5Infiltration: 0.422182116946216\n",
      "\n",
      "auprc 5Infiltration: 0.14263076979592254\n",
      "\n",
      "mean auroc: 0.4167266678300538\n",
      "\n",
      "mean auprc: 0.1434915353197411\n",
      "\n",
      "max auroc: 0.44940258790929594\n",
      "\n",
      "max auprc: 0.151032633561404\n",
      "\n",
      "401.27589440345764\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5982636378876643\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
