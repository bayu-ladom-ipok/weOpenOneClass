{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "from callback import MultipleClassAUROC, MultiGPUModelCheckpoint\n",
    "from configparser import ConfigParser\n",
    "from generator import AugmentedImageSequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from utility import get_sample_counts\n",
    "from weights import get_class_weights\n",
    "from augmenter import augmenter\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Input, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_radam import RAdam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(\"TensorFlow version: \", tf.__version__)\n",
    "#assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#    \"This notebook requires TensorFlow 2.0 or above.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "# UPDATED: import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics\n",
    "import gc\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneClass = \"Edema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "\n",
    "    # default config\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "\n",
    "    # train config\n",
    "use_base_model_weights = cp[\"TRAIN\"].getboolean(\"use_base_model_weights\")\n",
    "use_trained_model_weights = cp[\"TRAIN\"].getboolean(\"use_trained_model_weights\")\n",
    "use_best_weights = cp[\"TRAIN\"].getboolean(\"use_best_weights\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "epochs = cp[\"TRAIN\"].getint(\"epochs\")\n",
    "batch_size = cp[\"TRAIN\"].getint(\"batch_size\")\n",
    "initial_learning_rate = cp[\"TRAIN\"].getfloat(\"initial_learning_rate\")\n",
    "generator_workers = cp[\"TRAIN\"].getint(\"generator_workers\")\n",
    "image_dimension = cp[\"TRAIN\"].getint(\"image_dimension\")\n",
    "train_steps = cp[\"TRAIN\"].get(\"train_steps\")\n",
    "patience_reduce_lr = cp[\"TRAIN\"].getint(\"patience_reduce_lr\")\n",
    "min_lr = cp[\"TRAIN\"].getfloat(\"min_lr\")\n",
    "validation_steps = cp[\"TRAIN\"].get(\"validation_steps\")\n",
    "positive_weights_multiply = cp[\"TRAIN\"].getfloat(\"positive_weights_multiply\")\n",
    "dataset_csv_dir = cp[\"TRAIN\"].get(\"dataset_csv_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=1.0, alpha=0.5):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(tf.cast(y_pred,tf.float32) - tf.cast(y_true,tf.float32)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network1(dropout=0.08425517073874295, neuronPct=0.1767547775828121, neuronShrink=0.33180474398878285):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat1'))\n",
    "    model.add(Dense(neuronCount,name='dense1'))\n",
    "    model.add(Activation('relu',name='relu1'))\n",
    "    model.add(Dropout(dropout, name='dropout1'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer1')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer1')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer1')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network2(dropout=0.15672137551441198, neuronPct=0.2197894476507525, neuronShrink=0.3803316528497302, noisePct=0.282563134185142):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "    # Construct neural network\n",
    "    neuronCount = neuronCount * neuronShrink\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,1536)))\n",
    "    model.add(Flatten(name='flat2'))\n",
    "    model.add(Dense(neuronCount,name='dense2'))\n",
    "    model.add(GaussianNoise(noisePct))\n",
    "    model.add(Activation('relu',name='relu2'))\n",
    "    model.add(Dropout(dropout, name='dropout2'))\n",
    "    model.add(Dense(14, activation='sigmoid',name='midLayer2')) # Output\n",
    "    weights_path = None\n",
    "    if weights_path is not None:\n",
    "        print(f\"load model weights_path: {weights_path}\")\n",
    "        model.load_weights(weights_path)\n",
    "    #model.layers.pop()\n",
    "    dr = model.layers[-2].output\n",
    "    model.trainable = False\n",
    "    left = Dense(14, activation=\"sigmoid\", name='leftLayer2')(dr)\n",
    "    right = Dense(14, activation=\"sigmoid\", name='rightLayer2')(dr)\n",
    "    model = Model(model.input, [left,model.output,right])\n",
    "    #model = Model(model.input, model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(model1,model2):\n",
    "    model = Model([model1.input,model2.input], [model1.output,model2.output])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** compute class weights from training data **\n",
      "163: 1690\n",
      "85: 1690\n",
      "437: 1690\n",
      "726: 1690\n",
      "90: 1690\n",
      "92: 1690\n",
      "246: 1690\n",
      "24: 1690\n",
      "109: 1690\n",
      "1690: 1690\n",
      "26: 1690\n",
      "7: 1690\n",
      "41: 1690\n",
      "3: 1690\n",
      "** class_weights **\n",
      "[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}]\n"
     ]
    }
   ],
   "source": [
    "# compute steps\n",
    "train_counts, train_pos_counts = get_sample_counts(output_dir, \"train\"+oneClass, class_names)\n",
    "dev_counts, _ = get_sample_counts(output_dir, \"dev\"+oneClass, class_names)\n",
    "    \n",
    "if train_steps == \"auto\":\n",
    "    train_steps = int(train_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        train_steps = int(train_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"train_steps: {train_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "    print(f\"** train_steps: {train_steps} **\")\n",
    "\n",
    "if validation_steps == \"auto\":\n",
    "    validation_steps = int(dev_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        validation_steps = int(validation_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"validation_steps: {validation_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        print(f\"** validation_steps: {validation_steps} **\")\n",
    "\n",
    "        # compute class weights\n",
    "keras.backend.clear_session()\n",
    "print(\"** compute class weights from training data **\")\n",
    "class_weights = get_class_weights(train_counts,train_pos_counts,multiply=positive_weights_multiply,)\n",
    "print(\"** class_weights **\")\n",
    "print(class_weights)\n",
    "#print(str(train_steps))\n",
    "#print(str(train_counts))\n",
    "#print(str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test_steps: 22433 **\n"
     ]
    }
   ],
   "source": [
    "test_steps = cp[\"TEST\"].get(\"test_steps\")\n",
    "test_counts, _ = get_sample_counts(output_dir, \"test\", class_names)\n",
    "\n",
    "if test_steps == \"auto\":\n",
    "    test_steps = int(test_counts / batch_size)\n",
    "else:\n",
    "    try:\n",
    "        test_steps = int(test_steps)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"\"\"test_steps: {test_steps} is invalid,please use 'auto' or integer.\"\"\")\n",
    "        \n",
    "print(f\"** test_steps: {test_steps} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"train\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps,\n",
    "        )\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_csv_file=os.path.join(output_dir, \"dev\"+oneClass+\".csv\"),\n",
    "            class_names=class_names,\n",
    "            source_image_dir=image_source_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_dimension, image_dimension),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False,\n",
    ")\n",
    "\n",
    "test_sequence = AugmentedImageSequence(\n",
    "        dataset_csv_file=os.path.join(output_dir, \"test.csv\"),\n",
    "        class_names=class_names,\n",
    "        source_image_dir=image_source_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        augmenter=None,\n",
    "        steps=test_steps,\n",
    "        shuffle_on_epoch_end=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(lr):\n",
    "    gc.collect()\n",
    "      # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model1 = construct_network1()\n",
    "    model2 = construct_network2()\n",
    "    \n",
    "    optimizer = SGD(lr=initial_learning_rate)\n",
    "    \n",
    "    alpha = 0.9340456763831478\n",
    "    gamma = 1.4195808780694898\n",
    "    model1.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss})\n",
    "\n",
    "    alpha = 0.7297456293468533\n",
    "    gamma = 1.2700405014991505\n",
    "    model2.compile(optimizer=optimizer,loss={'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "  \n",
    "    model = construct_network(model1=model1,model2=model2)\n",
    "    model.compile(optimizer=optimizer,loss={'leftLayer1':tf.keras.losses.Huber(),'midLayer1':focal_loss(gamma=gamma,alpha=alpha),'rightLayer1':euclidean_distance_loss,'leftLayer2':tf.keras.losses.Huber(),'midLayer2':focal_loss(gamma=gamma,alpha=alpha),'rightLayer2':euclidean_distance_loss})\n",
    "\n",
    "    output_weights_path = os.path.join(output_dir,  str(lr)+\"_\"+output_weights_name)\n",
    "    \n",
    "    print(f\"** set output weights path to: {output_weights_path} **\")\n",
    "                  \n",
    "    \n",
    "                  \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                 output_weights_path,\n",
    "                 save_weights_only=True,\n",
    "                 save_best_only=True,\n",
    "                 verbose=1,\n",
    "            )\n",
    "    start_time = time.time()\n",
    "  \n",
    "    model.summary()\n",
    "  \n",
    "    callbacks = [\n",
    "            checkpoint,\n",
    "            #keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "            #TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n",
    "                              verbose=1, mode=\"min\", min_lr=min_lr), \n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            generator=train_sequence,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_sequence,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=[class_weights,class_weights,class_weights,class_weights,class_weights,class_weights],\n",
    "            workers=generator_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    y_hat = model.predict_generator(test_sequence, verbose=1)\n",
    "    y = test_sequence.get_y_true()\n",
    "    \n",
    "    test_log_path = os.path.join(output_dir, str(lr)+\"_\"+\"test.log\")\n",
    "    print(f\"** write log to {test_log_path} **\")\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    threshold = dict()\n",
    "    with open(test_log_path, \"w\") as f:\n",
    "        for k in range(6):\n",
    "            for i in range(len(class_names)):\n",
    "                 if(class_names[i] == str(oneClass)):\n",
    "                \n",
    "                    try:\n",
    "                        score = roc_auc_score(y[:, i], y_hat[k][:, i])\n",
    "                        precision[i], recall[i], threshold[i] = precision_recall_curve(y[:, i], y_hat[k][:, i])\n",
    "                        tmp = auc(recall[i], precision[i])\n",
    "                        aurocs.append(score)\n",
    "                        auprcs.append(tmp) \n",
    "                    except ValueError:\n",
    "                        score = 0\n",
    "               \n",
    "                    print(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    print(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "                    f.write(f\"auroc {str(k)+class_names[i]}: {score}\\n\")\n",
    "                    f.write(f\"auprc {str(k)+class_names[i]}: {tmp}\\n\")\n",
    "        \n",
    "        mean_auroc = np.mean(aurocs)\n",
    "        mean_auprc = float(np.mean(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        print(f\"mean auroc: {mean_auroc}\\n\")\n",
    "        f.write(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        print(f\"mean auprc: {mean_auprc}\\n\")\n",
    "        \n",
    "        max_auroc = np.max(aurocs)\n",
    "        max_auprc = float(np.max(auprcs))\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(f\"max auroc: {max_auroc}\\n\")\n",
    "        print(f\"max auroc: {max_auroc}\\n\")\n",
    "        f.write(f\"max auprc: {max_auprc}\\n\")\n",
    "        print(f\"max auprc: {max_auprc}\\n\")\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    time_took = time.time() - start_time\n",
    "    \n",
    "    return max_auroc, time_took\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** set output weights path to: ./experiments/0.009_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:58: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1672/1690 [============================>.] - ETA: 0s - loss: 6.4999 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.4829 - rightLayer1_loss: 1.7467 - leftLayer2_loss: 0.1194 - midLayer2_loss: 1.4230 - rightLayer2_loss: 1.6051\n",
      "Epoch 00001: val_loss improved from inf to 6.26413, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.4980 - leftLayer1_loss: 0.1227 - midLayer1_loss: 1.4833 - rightLayer1_loss: 1.7454 - leftLayer2_loss: 0.1193 - midLayer2_loss: 1.4245 - rightLayer2_loss: 1.6028 - val_loss: 6.2641 - val_leftLayer1_loss: 0.1206 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.6230 - val_leftLayer2_loss: 0.1158 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.5490\n",
      "Epoch 2/11\n",
      "1672/1690 [============================>.] - ETA: 0s - loss: 5.8794 - leftLayer1_loss: 0.1180 - midLayer1_loss: 1.4831 - rightLayer1_loss: 1.5085 - leftLayer2_loss: 0.1097 - midLayer2_loss: 1.4230 - rightLayer2_loss: 1.2372\n",
      "Epoch 00002: val_loss improved from 6.26413 to 5.86734, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.8779 - leftLayer1_loss: 0.1179 - midLayer1_loss: 1.4835 - rightLayer1_loss: 1.5075 - leftLayer2_loss: 0.1096 - midLayer2_loss: 1.4226 - rightLayer2_loss: 1.2366 - val_loss: 5.8673 - val_leftLayer1_loss: 0.1160 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.4213 - val_leftLayer2_loss: 0.1101 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.3642\n",
      "Epoch 3/11\n",
      "1683/1690 [============================>.] - ETA: 0s - loss: 5.5293 - leftLayer1_loss: 0.1135 - midLayer1_loss: 1.4845 - rightLayer1_loss: 1.3322 - leftLayer2_loss: 0.1005 - midLayer2_loss: 1.4203 - rightLayer2_loss: 1.0783\n",
      "Epoch 00003: val_loss improved from 5.86734 to 5.61658, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.5288 - leftLayer1_loss: 0.1135 - midLayer1_loss: 1.4847 - rightLayer1_loss: 1.3318 - leftLayer2_loss: 0.1005 - midLayer2_loss: 1.4204 - rightLayer2_loss: 1.0780 - val_loss: 5.6166 - val_leftLayer1_loss: 0.1117 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.2808 - val_leftLayer2_loss: 0.1050 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.2633\n",
      "Epoch 4/11\n",
      "1668/1690 [============================>.] - ETA: 0s - loss: 5.3300 - leftLayer1_loss: 0.1093 - midLayer1_loss: 1.4841 - rightLayer1_loss: 1.2119 - leftLayer2_loss: 0.0934 - midLayer2_loss: 1.4244 - rightLayer2_loss: 1.0068\n",
      "Epoch 00004: val_loss improved from 5.61658 to 5.45278, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.3303 - leftLayer1_loss: 0.1092 - midLayer1_loss: 1.4843 - rightLayer1_loss: 1.2112 - leftLayer2_loss: 0.0934 - midLayer2_loss: 1.4254 - rightLayer2_loss: 1.0066 - val_loss: 5.4528 - val_leftLayer1_loss: 0.1077 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.1867 - val_leftLayer2_loss: 0.1004 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.2023\n",
      "Epoch 5/11\n",
      "1671/1690 [============================>.] - ETA: 0s - loss: 5.1932 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.4846 - rightLayer1_loss: 1.1299 - leftLayer2_loss: 0.0877 - midLayer2_loss: 1.4173 - rightLayer2_loss: 0.9686\n",
      "Epoch 00005: val_loss improved from 5.45278 to 5.34128, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1943 - leftLayer1_loss: 0.1052 - midLayer1_loss: 1.4849 - rightLayer1_loss: 1.1299 - leftLayer2_loss: 0.0877 - midLayer2_loss: 1.4176 - rightLayer2_loss: 0.9690 - val_loss: 5.3413 - val_leftLayer1_loss: 0.1039 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.1233 - val_leftLayer2_loss: 0.0963 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11\n",
      "1670/1690 [============================>.] - ETA: 0s - loss: 5.1033 - leftLayer1_loss: 0.1015 - midLayer1_loss: 1.4845 - rightLayer1_loss: 1.0736 - leftLayer2_loss: 0.0816 - midLayer2_loss: 1.4160 - rightLayer2_loss: 0.9461\n",
      "Epoch 00006: val_loss improved from 5.34128 to 5.26174, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1047 - leftLayer1_loss: 0.1014 - midLayer1_loss: 1.4848 - rightLayer1_loss: 1.0735 - leftLayer2_loss: 0.0816 - midLayer2_loss: 1.4169 - rightLayer2_loss: 0.9465 - val_loss: 5.2617 - val_leftLayer1_loss: 0.1003 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.0797 - val_leftLayer2_loss: 0.0927 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.1334\n",
      "Epoch 7/11\n",
      "1676/1690 [============================>.] - ETA: 0s - loss: 5.0422 - leftLayer1_loss: 0.0980 - midLayer1_loss: 1.4847 - rightLayer1_loss: 1.0343 - leftLayer2_loss: 0.0767 - midLayer2_loss: 1.4161 - rightLayer2_loss: 0.9325\n",
      "Epoch 00007: val_loss improved from 5.26174 to 5.20262, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0427 - leftLayer1_loss: 0.0979 - midLayer1_loss: 1.4848 - rightLayer1_loss: 1.0341 - leftLayer2_loss: 0.0766 - midLayer2_loss: 1.4167 - rightLayer2_loss: 0.9325 - val_loss: 5.2026 - val_leftLayer1_loss: 0.0969 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.0487 - val_leftLayer2_loss: 0.0894 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.1118\n",
      "Epoch 8/11\n",
      "1680/1690 [============================>.] - ETA: 0s - loss: 5.0060 - leftLayer1_loss: 0.0946 - midLayer1_loss: 1.4835 - rightLayer1_loss: 1.0058 - leftLayer2_loss: 0.0722 - midLayer2_loss: 1.4248 - rightLayer2_loss: 0.9251\n",
      "Epoch 00008: val_loss improved from 5.20262 to 5.15720, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0042 - leftLayer1_loss: 0.0946 - midLayer1_loss: 1.4834 - rightLayer1_loss: 1.0052 - leftLayer2_loss: 0.0722 - midLayer2_loss: 1.4246 - rightLayer2_loss: 0.9244 - val_loss: 5.1572 - val_leftLayer1_loss: 0.0938 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.0261 - val_leftLayer2_loss: 0.0864 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0950\n",
      "Epoch 9/11\n",
      "1687/1690 [============================>.] - ETA: 0s - loss: 4.9721 - leftLayer1_loss: 0.0916 - midLayer1_loss: 1.4848 - rightLayer1_loss: 0.9854 - leftLayer2_loss: 0.0685 - midLayer2_loss: 1.4262 - rightLayer2_loss: 0.9156\n",
      "Epoch 00009: val_loss improved from 5.15720 to 5.12128, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9725 - leftLayer1_loss: 0.0916 - midLayer1_loss: 1.4851 - rightLayer1_loss: 0.9854 - leftLayer2_loss: 0.0685 - midLayer2_loss: 1.4264 - rightLayer2_loss: 0.9157 - val_loss: 5.1213 - val_leftLayer1_loss: 0.0909 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 1.0091 - val_leftLayer2_loss: 0.0838 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0817\n",
      "Epoch 10/11\n",
      "1677/1690 [============================>.] - ETA: 0s - loss: 4.9371 - leftLayer1_loss: 0.0886 - midLayer1_loss: 1.4825 - rightLayer1_loss: 0.9688 - leftLayer2_loss: 0.0654 - midLayer2_loss: 1.4227 - rightLayer2_loss: 0.9091\n",
      "Epoch 00010: val_loss improved from 5.12128 to 5.09192, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9374 - leftLayer1_loss: 0.0886 - midLayer1_loss: 1.4826 - rightLayer1_loss: 0.9685 - leftLayer2_loss: 0.0654 - midLayer2_loss: 1.4234 - rightLayer2_loss: 0.9090 - val_loss: 5.0919 - val_leftLayer1_loss: 0.0881 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 0.9961 - val_leftLayer2_loss: 0.0814 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0705\n",
      "Epoch 11/11\n",
      "1674/1690 [============================>.] - ETA: 0s - loss: 4.9179 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.4833 - rightLayer1_loss: 0.9553 - leftLayer2_loss: 0.0630 - midLayer2_loss: 1.4228 - rightLayer2_loss: 0.9076\n",
      "Epoch 00011: val_loss improved from 5.09192 to 5.06755, saving model to ./experiments/0.009_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9178 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.4835 - rightLayer1_loss: 0.9553 - leftLayer2_loss: 0.0630 - midLayer2_loss: 1.4226 - rightLayer2_loss: 0.9076 - val_loss: 5.0676 - val_leftLayer1_loss: 0.0855 - val_midLayer1_loss: 1.4800 - val_rightLayer1_loss: 0.9858 - val_leftLayer2_loss: 0.0793 - val_midLayer2_loss: 1.3758 - val_rightLayer2_loss: 1.0611\n",
      "WARNING:tensorflow:From <ipython-input-15-3539473a5eed>:61: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009_test.log **\n",
      "auroc 0Edema: 0.5385377149982516\n",
      "\n",
      "auprc 0Edema: 0.02524739846137831\n",
      "\n",
      "auroc 1Edema: 0.21566163712055736\n",
      "\n",
      "auprc 1Edema: 0.01062091600271404\n",
      "\n",
      "auroc 2Edema: 0.6840661582140822\n",
      "\n",
      "auprc 2Edema: 0.04476883706024787\n",
      "\n",
      "auroc 3Edema: 0.38899844517310916\n",
      "\n",
      "auprc 3Edema: 0.013467237161349182\n",
      "\n",
      "auroc 4Edema: 0.6295016856786588\n",
      "\n",
      "auprc 4Edema: 0.027898647452159316\n",
      "\n",
      "auroc 5Edema: 0.5713011833838048\n",
      "\n",
      "auprc 5Edema: 0.020951922361653823\n",
      "\n",
      "mean auroc: 0.504677804094744\n",
      "\n",
      "mean auprc: 0.02382582641658376\n",
      "\n",
      "max auroc: 0.6840661582140822\n",
      "\n",
      "max auprc: 0.04476883706024787\n",
      "\n",
      "76.84544563293457\n",
      "** set output weights path to: ./experiments/0.009999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1669/1690 [============================>.] - ETA: 0s - loss: 6.5686 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4159 - rightLayer1_loss: 1.7682 - leftLayer2_loss: 0.1135 - midLayer2_loss: 1.5615 - rightLayer2_loss: 1.5867\n",
      "Epoch 00001: val_loss improved from inf to 6.28310, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.5649 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4163 - rightLayer1_loss: 1.7668 - leftLayer2_loss: 0.1134 - midLayer2_loss: 1.5618 - rightLayer2_loss: 1.5839 - val_loss: 6.2831 - val_leftLayer1_loss: 0.1208 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.6538 - val_leftLayer2_loss: 0.1120 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.5182\n",
      "Epoch 2/11\n",
      "1680/1690 [============================>.] - ETA: 0s - loss: 5.9668 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.4157 - rightLayer1_loss: 1.5536 - leftLayer2_loss: 0.1037 - midLayer2_loss: 1.5583 - rightLayer2_loss: 1.2168\n",
      "Epoch 00002: val_loss improved from 6.28310 to 5.90386, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.9648 - leftLayer1_loss: 0.1186 - midLayer1_loss: 1.4155 - rightLayer1_loss: 1.5530 - leftLayer2_loss: 0.1036 - midLayer2_loss: 1.5581 - rightLayer2_loss: 1.2159 - val_loss: 5.9039 - val_leftLayer1_loss: 0.1167 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.4674 - val_leftLayer2_loss: 0.1063 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.3352\n",
      "Epoch 3/11\n",
      "1682/1690 [============================>.] - ETA: 0s - loss: 5.6302 - leftLayer1_loss: 0.1146 - midLayer1_loss: 1.4156 - rightLayer1_loss: 1.3856 - leftLayer2_loss: 0.0955 - midLayer2_loss: 1.5522 - rightLayer2_loss: 1.0667\n",
      "Epoch 00003: val_loss improved from 5.90386 to 5.65876, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.6288 - leftLayer1_loss: 0.1146 - midLayer1_loss: 1.4156 - rightLayer1_loss: 1.3851 - leftLayer2_loss: 0.0955 - midLayer2_loss: 1.5519 - rightLayer2_loss: 1.0662 - val_loss: 5.6588 - val_leftLayer1_loss: 0.1129 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.3293 - val_leftLayer2_loss: 0.1011 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.2372\n",
      "Epoch 4/11\n",
      "1669/1690 [============================>.] - ETA: 0s - loss: 5.4396 - leftLayer1_loss: 0.1108 - midLayer1_loss: 1.4154 - rightLayer1_loss: 1.2647 - leftLayer2_loss: 0.0882 - midLayer2_loss: 1.5638 - rightLayer2_loss: 0.9967\n",
      "Epoch 00004: val_loss improved from 5.65876 to 5.49512, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.4396 - leftLayer1_loss: 0.1108 - midLayer1_loss: 1.4158 - rightLayer1_loss: 1.2641 - leftLayer2_loss: 0.0881 - midLayer2_loss: 1.5641 - rightLayer2_loss: 0.9967 - val_loss: 5.4951 - val_leftLayer1_loss: 0.1093 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.2316 - val_leftLayer2_loss: 0.0966 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.1794\n",
      "Epoch 5/11\n",
      "1687/1690 [============================>.] - ETA: 0s - loss: 5.3028 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.4151 - rightLayer1_loss: 1.1775 - leftLayer2_loss: 0.0822 - midLayer2_loss: 1.5575 - rightLayer2_loss: 0.9635\n",
      "Epoch 00005: val_loss improved from 5.49512 to 5.38124, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.3024 - leftLayer1_loss: 0.1071 - midLayer1_loss: 1.4150 - rightLayer1_loss: 1.1774 - leftLayer2_loss: 0.0821 - midLayer2_loss: 1.5573 - rightLayer2_loss: 0.9635 - val_loss: 5.3812 - val_leftLayer1_loss: 0.1058 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.1628 - val_leftLayer2_loss: 0.0926 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.1417\n",
      "Epoch 6/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 5.2222 - leftLayer1_loss: 0.1037 - midLayer1_loss: 1.4157 - rightLayer1_loss: 1.1153 - leftLayer2_loss: 0.0768 - midLayer2_loss: 1.5675 - rightLayer2_loss: 0.9432\n",
      "Epoch 00006: val_loss improved from 5.38124 to 5.29895, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.2224 - leftLayer1_loss: 0.1037 - midLayer1_loss: 1.4157 - rightLayer1_loss: 1.1152 - leftLayer2_loss: 0.0768 - midLayer2_loss: 1.5675 - rightLayer2_loss: 0.9434 - val_loss: 5.2989 - val_leftLayer1_loss: 0.1026 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.1140 - val_leftLayer2_loss: 0.0890 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.1150\n",
      "Epoch 7/11\n",
      "1689/1690 [============================>.] - ETA: 0s - loss: 5.1503 - leftLayer1_loss: 0.1005 - midLayer1_loss: 1.4153 - rightLayer1_loss: 1.0709 - leftLayer2_loss: 0.0723 - midLayer2_loss: 1.5594 - rightLayer2_loss: 0.9319\n",
      "Epoch 00007: val_loss improved from 5.29895 to 5.23736, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1502 - leftLayer1_loss: 0.1005 - midLayer1_loss: 1.4153 - rightLayer1_loss: 1.0709 - leftLayer2_loss: 0.0723 - midLayer2_loss: 1.5593 - rightLayer2_loss: 0.9319 - val_loss: 5.2374 - val_leftLayer1_loss: 0.0995 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.0785 - val_leftLayer2_loss: 0.0859 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.0952\n",
      "Epoch 8/11\n",
      "1674/1690 [============================>.] - ETA: 0s - loss: 5.1034 - leftLayer1_loss: 0.0975 - midLayer1_loss: 1.4160 - rightLayer1_loss: 1.0378 - leftLayer2_loss: 0.0690 - midLayer2_loss: 1.5605 - rightLayer2_loss: 0.9227\n",
      "Epoch 00008: val_loss improved from 5.23736 to 5.18961, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1035 - leftLayer1_loss: 0.0975 - midLayer1_loss: 1.4159 - rightLayer1_loss: 1.0377 - leftLayer2_loss: 0.0689 - midLayer2_loss: 1.5606 - rightLayer2_loss: 0.9229 - val_loss: 5.1896 - val_leftLayer1_loss: 0.0966 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.0521 - val_leftLayer2_loss: 0.0831 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.0796\n",
      "Epoch 9/11\n",
      "1670/1690 [============================>.] - ETA: 0s - loss: 5.0617 - leftLayer1_loss: 0.0946 - midLayer1_loss: 1.4157 - rightLayer1_loss: 1.0120 - leftLayer2_loss: 0.0652 - midLayer2_loss: 1.5596 - rightLayer2_loss: 0.9146\n",
      "Epoch 00009: val_loss improved from 5.18961 to 5.15195, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0632 - leftLayer1_loss: 0.0946 - midLayer1_loss: 1.4160 - rightLayer1_loss: 1.0123 - leftLayer2_loss: 0.0651 - midLayer2_loss: 1.5600 - rightLayer2_loss: 0.9152 - val_loss: 5.1520 - val_leftLayer1_loss: 0.0939 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.0320 - val_leftLayer2_loss: 0.0805 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.0672\n",
      "Epoch 10/11\n",
      "1675/1690 [============================>.] - ETA: 0s - loss: 5.0287 - leftLayer1_loss: 0.0918 - midLayer1_loss: 1.4156 - rightLayer1_loss: 0.9929 - leftLayer2_loss: 0.0623 - midLayer2_loss: 1.5568 - rightLayer2_loss: 0.9092\n",
      "Epoch 00010: val_loss improved from 5.15195 to 5.12147, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0288 - leftLayer1_loss: 0.0918 - midLayer1_loss: 1.4156 - rightLayer1_loss: 0.9930 - leftLayer2_loss: 0.0623 - midLayer2_loss: 1.5568 - rightLayer2_loss: 0.9093 - val_loss: 5.1215 - val_leftLayer1_loss: 0.0913 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.0165 - val_leftLayer2_loss: 0.0783 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.0572\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1690 [============================>.] - ETA: 0s - loss: 5.0032 - leftLayer1_loss: 0.0893 - midLayer1_loss: 1.4171 - rightLayer1_loss: 0.9776 - leftLayer2_loss: 0.0599 - midLayer2_loss: 1.5565 - rightLayer2_loss: 0.9028\n",
      "Epoch 00011: val_loss improved from 5.12147 to 5.09613, saving model to ./experiments/0.009999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0049 - leftLayer1_loss: 0.0893 - midLayer1_loss: 1.4175 - rightLayer1_loss: 0.9779 - leftLayer2_loss: 0.0599 - midLayer2_loss: 1.5566 - rightLayer2_loss: 0.9036 - val_loss: 5.0961 - val_leftLayer1_loss: 0.0888 - val_midLayer1_loss: 1.4206 - val_rightLayer1_loss: 1.0042 - val_leftLayer2_loss: 0.0762 - val_midLayer2_loss: 1.4577 - val_rightLayer2_loss: 1.0486\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.009999999999999998_test.log **\n",
      "auroc 0Edema: 0.49294626500671856\n",
      "\n",
      "auprc 0Edema: 0.01701201645737696\n",
      "\n",
      "auroc 1Edema: 0.5112538568283731\n",
      "\n",
      "auprc 1Edema: 0.018300900585080663\n",
      "\n",
      "auroc 2Edema: 0.6001533384794364\n",
      "\n",
      "auprc 2Edema: 0.026130622213392213\n",
      "\n",
      "auroc 3Edema: 0.6005468834187719\n",
      "\n",
      "auprc 3Edema: 0.022701135639878398\n",
      "\n",
      "auroc 4Edema: 0.595984829991665\n",
      "\n",
      "auprc 4Edema: 0.03641781288525901\n",
      "\n",
      "auroc 5Edema: 0.5446592136138619\n",
      "\n",
      "auprc 5Edema: 0.01947052232657804\n",
      "\n",
      "mean auroc: 0.5575907312231378\n",
      "\n",
      "mean auprc: 0.023338835017927547\n",
      "\n",
      "max auroc: 0.6005468834187719\n",
      "\n",
      "max auprc: 0.03641781288525901\n",
      "\n",
      "75.84983229637146\n",
      "** set output weights path to: ./experiments/0.010999999999999998_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 6.5134 - leftLayer1_loss: 0.1167 - midLayer1_loss: 1.4608 - rightLayer1_loss: 1.7502 - leftLayer2_loss: 0.1195 - midLayer2_loss: 1.4541 - rightLayer2_loss: 1.6122\n",
      "Epoch 00001: val_loss improved from inf to 6.29347, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.5124 - leftLayer1_loss: 0.1166 - midLayer1_loss: 1.4609 - rightLayer1_loss: 1.7498 - leftLayer2_loss: 0.1195 - midLayer2_loss: 1.4541 - rightLayer2_loss: 1.6114 - val_loss: 6.2935 - val_leftLayer1_loss: 0.1147 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.6463 - val_leftLayer2_loss: 0.1160 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.5259\n",
      "Epoch 2/11\n",
      "1674/1690 [============================>.] - ETA: 0s - loss: 5.9177 - leftLayer1_loss: 0.1128 - midLayer1_loss: 1.4622 - rightLayer1_loss: 1.5411 - leftLayer2_loss: 0.1089 - midLayer2_loss: 1.4643 - rightLayer2_loss: 1.2285\n",
      "Epoch 00002: val_loss improved from 6.29347 to 5.90826, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.9166 - leftLayer1_loss: 0.1127 - midLayer1_loss: 1.4624 - rightLayer1_loss: 1.5403 - leftLayer2_loss: 0.1089 - midLayer2_loss: 1.4647 - rightLayer2_loss: 1.2276 - val_loss: 5.9083 - val_leftLayer1_loss: 0.1109 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.4630 - val_leftLayer2_loss: 0.1097 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.3339\n",
      "Epoch 3/11\n",
      "1681/1690 [============================>.] - ETA: 0s - loss: 5.5884 - leftLayer1_loss: 0.1092 - midLayer1_loss: 1.4617 - rightLayer1_loss: 1.3789 - leftLayer2_loss: 0.0996 - midLayer2_loss: 1.4710 - rightLayer2_loss: 1.0680\n",
      "Epoch 00003: val_loss improved from 5.90826 to 5.66350, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.5863 - leftLayer1_loss: 0.1092 - midLayer1_loss: 1.4616 - rightLayer1_loss: 1.3783 - leftLayer2_loss: 0.0996 - midLayer2_loss: 1.4704 - rightLayer2_loss: 1.0672 - val_loss: 5.6635 - val_leftLayer1_loss: 0.1074 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.3276 - val_leftLayer2_loss: 0.1042 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.2337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1689/1690 [============================>.] - ETA: 0s - loss: 5.3784 - leftLayer1_loss: 0.1055 - midLayer1_loss: 1.4616 - rightLayer1_loss: 1.2592 - leftLayer2_loss: 0.0924 - midLayer2_loss: 1.4630 - rightLayer2_loss: 0.9967\n",
      "Epoch 00004: val_loss improved from 5.66350 to 5.49994, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.3784 - leftLayer1_loss: 0.1055 - midLayer1_loss: 1.4616 - rightLayer1_loss: 1.2592 - leftLayer2_loss: 0.0924 - midLayer2_loss: 1.4629 - rightLayer2_loss: 0.9967 - val_loss: 5.4999 - val_leftLayer1_loss: 0.1041 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.2313 - val_leftLayer2_loss: 0.0993 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.1747\n",
      "Epoch 5/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 5.2502 - leftLayer1_loss: 0.1022 - midLayer1_loss: 1.4608 - rightLayer1_loss: 1.1751 - leftLayer2_loss: 0.0852 - midLayer2_loss: 1.4646 - rightLayer2_loss: 0.9622\n",
      "Epoch 00005: val_loss improved from 5.49994 to 5.38622, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.2502 - leftLayer1_loss: 0.1022 - midLayer1_loss: 1.4610 - rightLayer1_loss: 1.1751 - leftLayer2_loss: 0.0852 - midLayer2_loss: 1.4646 - rightLayer2_loss: 0.9621 - val_loss: 5.3862 - val_leftLayer1_loss: 0.1009 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.1634 - val_leftLayer2_loss: 0.0949 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.1363\n",
      "Epoch 6/11\n",
      "1689/1690 [============================>.] - ETA: 0s - loss: 5.1640 - leftLayer1_loss: 0.0992 - midLayer1_loss: 1.4607 - rightLayer1_loss: 1.1146 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.4689 - rightLayer2_loss: 0.9410\n",
      "Epoch 00006: val_loss improved from 5.38622 to 5.30409, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1640 - leftLayer1_loss: 0.0992 - midLayer1_loss: 1.4608 - rightLayer1_loss: 1.1145 - leftLayer2_loss: 0.0795 - midLayer2_loss: 1.4689 - rightLayer2_loss: 0.9411 - val_loss: 5.3041 - val_leftLayer1_loss: 0.0979 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.1150 - val_leftLayer2_loss: 0.0911 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.1095\n",
      "Epoch 7/11\n",
      "1688/1690 [============================>.] - ETA: 0s - loss: 5.0952 - leftLayer1_loss: 0.0962 - midLayer1_loss: 1.4616 - rightLayer1_loss: 1.0698 - leftLayer2_loss: 0.0744 - midLayer2_loss: 1.4673 - rightLayer2_loss: 0.9259\n",
      "Epoch 00007: val_loss improved from 5.30409 to 5.24310, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0954 - leftLayer1_loss: 0.0962 - midLayer1_loss: 1.4617 - rightLayer1_loss: 1.0698 - leftLayer2_loss: 0.0744 - midLayer2_loss: 1.4672 - rightLayer2_loss: 0.9261 - val_loss: 5.2431 - val_leftLayer1_loss: 0.0951 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.0798 - val_leftLayer2_loss: 0.0877 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.0899\n",
      "Epoch 8/11\n",
      "1683/1690 [============================>.] - ETA: 0s - loss: 5.0489 - leftLayer1_loss: 0.0934 - midLayer1_loss: 1.4617 - rightLayer1_loss: 1.0377 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.4660 - rightLayer2_loss: 0.9195\n",
      "Epoch 00008: val_loss improved from 5.24310 to 5.19589, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0483 - leftLayer1_loss: 0.0934 - midLayer1_loss: 1.4618 - rightLayer1_loss: 1.0375 - leftLayer2_loss: 0.0706 - midLayer2_loss: 1.4658 - rightLayer2_loss: 0.9194 - val_loss: 5.1959 - val_leftLayer1_loss: 0.0925 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.0535 - val_leftLayer2_loss: 0.0846 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.0747\n",
      "Epoch 9/11\n",
      "1686/1690 [============================>.] - ETA: 0s - loss: 5.0083 - leftLayer1_loss: 0.0908 - midLayer1_loss: 1.4608 - rightLayer1_loss: 1.0121 - leftLayer2_loss: 0.0666 - midLayer2_loss: 1.4667 - rightLayer2_loss: 0.9114\n",
      "Epoch 00009: val_loss improved from 5.19589 to 5.15844, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0083 - leftLayer1_loss: 0.0908 - midLayer1_loss: 1.4608 - rightLayer1_loss: 1.0120 - leftLayer2_loss: 0.0666 - midLayer2_loss: 1.4667 - rightLayer2_loss: 0.9114 - val_loss: 5.1584 - val_leftLayer1_loss: 0.0899 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.0336 - val_leftLayer2_loss: 0.0819 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.0624\n",
      "Epoch 10/11\n",
      "1679/1690 [============================>.] - ETA: 0s - loss: 4.9748 - leftLayer1_loss: 0.0884 - midLayer1_loss: 1.4622 - rightLayer1_loss: 0.9937 - leftLayer2_loss: 0.0639 - midLayer2_loss: 1.4584 - rightLayer2_loss: 0.9083\n",
      "Epoch 00010: val_loss improved from 5.15844 to 5.12789, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9743 - leftLayer1_loss: 0.0883 - midLayer1_loss: 1.4621 - rightLayer1_loss: 0.9934 - leftLayer2_loss: 0.0639 - midLayer2_loss: 1.4586 - rightLayer2_loss: 0.9079 - val_loss: 5.1279 - val_leftLayer1_loss: 0.0876 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.0181 - val_leftLayer2_loss: 0.0795 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.0521\n",
      "Epoch 11/11\n",
      "1683/1690 [============================>.] - ETA: 0s - loss: 4.9578 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.4620 - rightLayer1_loss: 0.9778 - leftLayer2_loss: 0.0608 - midLayer2_loss: 1.4675 - rightLayer2_loss: 0.9038\n",
      "Epoch 00011: val_loss improved from 5.12789 to 5.10278, saving model to ./experiments/0.010999999999999998_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9568 - leftLayer1_loss: 0.0859 - midLayer1_loss: 1.4621 - rightLayer1_loss: 0.9775 - leftLayer2_loss: 0.0608 - midLayer2_loss: 1.4669 - rightLayer2_loss: 0.9035 - val_loss: 5.1028 - val_leftLayer1_loss: 0.0853 - val_midLayer1_loss: 1.4625 - val_rightLayer1_loss: 1.0059 - val_leftLayer2_loss: 0.0773 - val_midLayer2_loss: 1.4281 - val_rightLayer2_loss: 1.0437\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.010999999999999998_test.log **\n",
      "auroc 0Edema: 0.5293010096478439\n",
      "\n",
      "auprc 0Edema: 0.01936205230760788\n",
      "\n",
      "auroc 1Edema: 0.6094421096383873\n",
      "\n",
      "auprc 1Edema: 0.025139365834361903\n",
      "\n",
      "auroc 2Edema: 0.5159255948257473\n",
      "\n",
      "auprc 2Edema: 0.017645421343738085\n",
      "\n",
      "auroc 3Edema: 0.4313734157589513\n",
      "\n",
      "auprc 3Edema: 0.014515947876349262\n",
      "\n",
      "auroc 4Edema: 0.4690273315255996\n",
      "\n",
      "auprc 4Edema: 0.01650154428665529\n",
      "\n",
      "auroc 5Edema: 0.5661425998376999\n",
      "\n",
      "auprc 5Edema: 0.019953873323966934\n",
      "\n",
      "mean auroc: 0.5202020102057049\n",
      "\n",
      "mean auprc: 0.018853034162113227\n",
      "\n",
      "max auroc: 0.6094421096383873\n",
      "\n",
      "max auprc: 0.025139365834361903\n",
      "\n",
      "76.4187970161438\n",
      "** set output weights path to: ./experiments/0.011999999999999997_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1677/1690 [============================>.] - ETA: 0s - loss: 6.5786 - leftLayer1_loss: 0.1217 - midLayer1_loss: 1.3701 - rightLayer1_loss: 1.7759 - leftLayer2_loss: 0.1133 - midLayer2_loss: 1.5840 - rightLayer2_loss: 1.6136\n",
      "Epoch 00001: val_loss improved from inf to 6.24316, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.5753 - leftLayer1_loss: 0.1217 - midLayer1_loss: 1.3700 - rightLayer1_loss: 1.7748 - leftLayer2_loss: 0.1133 - midLayer2_loss: 1.5839 - rightLayer2_loss: 1.6118 - val_loss: 6.2432 - val_leftLayer1_loss: 0.1194 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.6227 - val_leftLayer2_loss: 0.1134 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.5232\n",
      "Epoch 2/11\n",
      "1674/1690 [============================>.] - ETA: 0s - loss: 5.8992 - leftLayer1_loss: 0.1160 - midLayer1_loss: 1.3698 - rightLayer1_loss: 1.4870 - leftLayer2_loss: 0.1034 - midLayer2_loss: 1.5940 - rightLayer2_loss: 1.2290\n",
      "Epoch 00002: val_loss improved from 6.24316 to 5.80320, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.8977 - leftLayer1_loss: 0.1160 - midLayer1_loss: 1.3696 - rightLayer1_loss: 1.4860 - leftLayer2_loss: 0.1033 - midLayer2_loss: 1.5946 - rightLayer2_loss: 1.2282 - val_loss: 5.8032 - val_leftLayer1_loss: 0.1141 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.3884 - val_leftLayer2_loss: 0.1073 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.3290\n",
      "Epoch 3/11\n",
      "1675/1690 [============================>.] - ETA: 0s - loss: 5.5181 - leftLayer1_loss: 0.1107 - midLayer1_loss: 1.3699 - rightLayer1_loss: 1.2893 - leftLayer2_loss: 0.0952 - midLayer2_loss: 1.5856 - rightLayer2_loss: 1.0673\n",
      "Epoch 00003: val_loss improved from 5.80320 to 5.54350, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.5167 - leftLayer1_loss: 0.1107 - midLayer1_loss: 1.3697 - rightLayer1_loss: 1.2887 - leftLayer2_loss: 0.0952 - midLayer2_loss: 1.5855 - rightLayer2_loss: 1.0669 - val_loss: 5.5435 - val_leftLayer1_loss: 0.1091 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.2394 - val_leftLayer2_loss: 0.1020 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.2285\n",
      "Epoch 4/11\n",
      "1679/1690 [============================>.] - ETA: 0s - loss: 5.3201 - leftLayer1_loss: 0.1058 - midLayer1_loss: 1.3683 - rightLayer1_loss: 1.1661 - leftLayer2_loss: 0.0877 - midLayer2_loss: 1.5957 - rightLayer2_loss: 0.9965\n",
      "Epoch 00004: val_loss improved from 5.54350 to 5.38403, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.3192 - leftLayer1_loss: 0.1058 - midLayer1_loss: 1.3680 - rightLayer1_loss: 1.1657 - leftLayer2_loss: 0.0877 - midLayer2_loss: 1.5957 - rightLayer2_loss: 0.9963 - val_loss: 5.3840 - val_leftLayer1_loss: 0.1044 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.1478 - val_leftLayer2_loss: 0.0973 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.1700\n",
      "Epoch 5/11\n",
      "1678/1690 [============================>.] - ETA: 0s - loss: 5.1993 - leftLayer1_loss: 0.1012 - midLayer1_loss: 1.3696 - rightLayer1_loss: 1.0889 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5964 - rightLayer2_loss: 0.9614\n",
      "Epoch 00005: val_loss improved from 5.38403 to 5.28010, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1987 - leftLayer1_loss: 0.1012 - midLayer1_loss: 1.3695 - rightLayer1_loss: 1.0886 - leftLayer2_loss: 0.0818 - midLayer2_loss: 1.5964 - rightLayer2_loss: 0.9612 - val_loss: 5.2801 - val_leftLayer1_loss: 0.1001 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.0901 - val_leftLayer2_loss: 0.0932 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.1322\n",
      "Epoch 6/11\n",
      "1678/1690 [============================>.] - ETA: 0s - loss: 5.1099 - leftLayer1_loss: 0.0969 - midLayer1_loss: 1.3687 - rightLayer1_loss: 1.0389 - leftLayer2_loss: 0.0765 - midLayer2_loss: 1.5877 - rightLayer2_loss: 0.9412\n",
      "Epoch 00006: val_loss improved from 5.28010 to 5.20789, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1098 - leftLayer1_loss: 0.0969 - midLayer1_loss: 1.3686 - rightLayer1_loss: 1.0386 - leftLayer2_loss: 0.0765 - midLayer2_loss: 1.5883 - rightLayer2_loss: 0.9409 - val_loss: 5.2079 - val_leftLayer1_loss: 0.0962 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.0521 - val_leftLayer2_loss: 0.0895 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.1057\n",
      "Epoch 7/11\n",
      "1686/1690 [============================>.] - ETA: 0s - loss: 5.0555 - leftLayer1_loss: 0.0931 - midLayer1_loss: 1.3692 - rightLayer1_loss: 1.0054 - leftLayer2_loss: 0.0722 - midLayer2_loss: 1.5883 - rightLayer2_loss: 0.9274\n",
      "Epoch 00007: val_loss improved from 5.20789 to 5.15514, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0557 - leftLayer1_loss: 0.0931 - midLayer1_loss: 1.3693 - rightLayer1_loss: 1.0054 - leftLayer2_loss: 0.0722 - midLayer2_loss: 1.5884 - rightLayer2_loss: 0.9274 - val_loss: 5.1551 - val_leftLayer1_loss: 0.0925 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.0259 - val_leftLayer2_loss: 0.0863 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.0860\n",
      "Epoch 8/11\n",
      "1684/1690 [============================>.] - ETA: 0s - loss: 5.0181 - leftLayer1_loss: 0.0895 - midLayer1_loss: 1.3686 - rightLayer1_loss: 0.9825 - leftLayer2_loss: 0.0683 - midLayer2_loss: 1.5888 - rightLayer2_loss: 0.9205\n",
      "Epoch 00008: val_loss improved from 5.15514 to 5.11489, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0178 - leftLayer1_loss: 0.0894 - midLayer1_loss: 1.3687 - rightLayer1_loss: 0.9824 - leftLayer2_loss: 0.0683 - midLayer2_loss: 1.5885 - rightLayer2_loss: 0.9205 - val_loss: 5.1149 - val_leftLayer1_loss: 0.0891 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 1.0071 - val_leftLayer2_loss: 0.0834 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.0708\n",
      "Epoch 9/11\n",
      "1671/1690 [============================>.] - ETA: 0s - loss: 4.9861 - leftLayer1_loss: 0.0862 - midLayer1_loss: 1.3694 - rightLayer1_loss: 0.9640 - leftLayer2_loss: 0.0648 - midLayer2_loss: 1.5900 - rightLayer2_loss: 0.9117\n",
      "Epoch 00009: val_loss improved from 5.11489 to 5.08310, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9876 - leftLayer1_loss: 0.0862 - midLayer1_loss: 1.3694 - rightLayer1_loss: 0.9644 - leftLayer2_loss: 0.0648 - midLayer2_loss: 1.5900 - rightLayer2_loss: 0.9127 - val_loss: 5.0831 - val_leftLayer1_loss: 0.0860 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 0.9932 - val_leftLayer2_loss: 0.0808 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.0587\n",
      "Epoch 10/11\n",
      "1684/1690 [============================>.] - ETA: 0s - loss: 4.9620 - leftLayer1_loss: 0.0830 - midLayer1_loss: 1.3688 - rightLayer1_loss: 0.9510 - leftLayer2_loss: 0.0619 - midLayer2_loss: 1.5904 - rightLayer2_loss: 0.9069\n",
      "Epoch 00010: val_loss improved from 5.08310 to 5.05736, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9621 - leftLayer1_loss: 0.0830 - midLayer1_loss: 1.3689 - rightLayer1_loss: 0.9510 - leftLayer2_loss: 0.0619 - midLayer2_loss: 1.5904 - rightLayer2_loss: 0.9068 - val_loss: 5.0574 - val_leftLayer1_loss: 0.0831 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 0.9826 - val_leftLayer2_loss: 0.0785 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.0487\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687/1690 [============================>.] - ETA: 0s - loss: 4.9454 - leftLayer1_loss: 0.0801 - midLayer1_loss: 1.3696 - rightLayer1_loss: 0.9399 - leftLayer2_loss: 0.0595 - midLayer2_loss: 1.5918 - rightLayer2_loss: 0.9045\n",
      "Epoch 00011: val_loss improved from 5.05736 to 5.03605, saving model to ./experiments/0.011999999999999997_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9453 - leftLayer1_loss: 0.0801 - midLayer1_loss: 1.3696 - rightLayer1_loss: 0.9399 - leftLayer2_loss: 0.0595 - midLayer2_loss: 1.5917 - rightLayer2_loss: 0.9045 - val_loss: 5.0360 - val_leftLayer1_loss: 0.0805 - val_midLayer1_loss: 1.3986 - val_rightLayer1_loss: 0.9744 - val_leftLayer2_loss: 0.0764 - val_midLayer2_loss: 1.4658 - val_rightLayer2_loss: 1.0403\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.011999999999999997_test.log **\n",
      "auroc 0Edema: 0.7232938139001964\n",
      "\n",
      "auprc 0Edema: 0.03687890591598152\n",
      "\n",
      "auroc 1Edema: 0.3461155168204999\n",
      "\n",
      "auprc 1Edema: 0.012741516791752045\n",
      "\n",
      "auroc 2Edema: 0.8162035173834925\n",
      "\n",
      "auprc 2Edema: 0.10757848228863637\n",
      "\n",
      "auroc 3Edema: 0.47040314440097375\n",
      "\n",
      "auprc 3Edema: 0.01693847476697128\n",
      "\n",
      "auroc 4Edema: 0.4262724509745708\n",
      "\n",
      "auprc 4Edema: 0.014726153021222176\n",
      "\n",
      "auroc 5Edema: 0.5944937246131077\n",
      "\n",
      "auprc 5Edema: 0.028437489672840627\n",
      "\n",
      "mean auroc: 0.5627970280154735\n",
      "\n",
      "mean auprc: 0.036216837076234\n",
      "\n",
      "max auroc: 0.8162035173834925\n",
      "\n",
      "max auprc: 0.10757848228863637\n",
      "\n",
      "76.67758965492249\n",
      "** set output weights path to: ./experiments/0.012999999999999996_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1682/1690 [============================>.] - ETA: 0s - loss: 6.5100 - leftLayer1_loss: 0.1164 - midLayer1_loss: 1.4945 - rightLayer1_loss: 1.7274 - leftLayer2_loss: 0.1294 - midLayer2_loss: 1.4702 - rightLayer2_loss: 1.5722\n",
      "Epoch 00001: val_loss improved from inf to 6.14481, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.5080 - leftLayer1_loss: 0.1164 - midLayer1_loss: 1.4945 - rightLayer1_loss: 1.7267 - leftLayer2_loss: 0.1294 - midLayer2_loss: 1.4700 - rightLayer2_loss: 1.5710 - val_loss: 6.1448 - val_leftLayer1_loss: 0.1142 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.5949 - val_leftLayer2_loss: 0.1226 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.4698\n",
      "Epoch 2/11\n",
      "1688/1690 [============================>.] - ETA: 0s - loss: 5.8418 - leftLayer1_loss: 0.1115 - midLayer1_loss: 1.4937 - rightLayer1_loss: 1.4710 - leftLayer2_loss: 0.1164 - midLayer2_loss: 1.4682 - rightLayer2_loss: 1.1810\n",
      "Epoch 00002: val_loss improved from 6.14481 to 5.72847, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.8416 - leftLayer1_loss: 0.1115 - midLayer1_loss: 1.4938 - rightLayer1_loss: 1.4709 - leftLayer2_loss: 0.1164 - midLayer2_loss: 1.4681 - rightLayer2_loss: 1.1809 - val_loss: 5.7285 - val_leftLayer1_loss: 0.1095 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.3849 - val_leftLayer2_loss: 0.1145 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.2762\n",
      "Epoch 3/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 5.5069 - leftLayer1_loss: 0.1070 - midLayer1_loss: 1.4937 - rightLayer1_loss: 1.2921 - leftLayer2_loss: 0.1053 - midLayer2_loss: 1.4669 - rightLayer2_loss: 1.0418\n",
      "Epoch 00003: val_loss improved from 5.72847 to 5.48434, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.5069 - leftLayer1_loss: 0.1070 - midLayer1_loss: 1.4938 - rightLayer1_loss: 1.2919 - leftLayer2_loss: 0.1053 - midLayer2_loss: 1.4671 - rightLayer2_loss: 1.0418 - val_loss: 5.4843 - val_leftLayer1_loss: 0.1052 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.2462 - val_leftLayer2_loss: 0.1075 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.1820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1676/1690 [============================>.] - ETA: 0s - loss: 5.3070 - leftLayer1_loss: 0.1026 - midLayer1_loss: 1.4926 - rightLayer1_loss: 1.1750 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.4642 - rightLayer2_loss: 0.9764\n",
      "Epoch 00004: val_loss improved from 5.48434 to 5.33217, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.3068 - leftLayer1_loss: 0.1026 - midLayer1_loss: 1.4928 - rightLayer1_loss: 1.1746 - leftLayer2_loss: 0.0963 - midLayer2_loss: 1.4644 - rightLayer2_loss: 0.9761 - val_loss: 5.3322 - val_leftLayer1_loss: 0.1012 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.1572 - val_leftLayer2_loss: 0.1014 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.1291\n",
      "Epoch 5/11\n",
      "1673/1690 [============================>.] - ETA: 0s - loss: 5.1889 - leftLayer1_loss: 0.0987 - midLayer1_loss: 1.4922 - rightLayer1_loss: 1.0995 - leftLayer2_loss: 0.0880 - midLayer2_loss: 1.4627 - rightLayer2_loss: 0.9479\n",
      "Epoch 00005: val_loss improved from 5.33217 to 5.23120, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1896 - leftLayer1_loss: 0.0987 - midLayer1_loss: 1.4923 - rightLayer1_loss: 1.0993 - leftLayer2_loss: 0.0879 - midLayer2_loss: 1.4633 - rightLayer2_loss: 0.9482 - val_loss: 5.2312 - val_leftLayer1_loss: 0.0974 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.0992 - val_leftLayer2_loss: 0.0960 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0952\n",
      "Epoch 6/11\n",
      "1670/1690 [============================>.] - ETA: 0s - loss: 5.1119 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.4921 - rightLayer1_loss: 1.0488 - leftLayer2_loss: 0.0813 - midLayer2_loss: 1.4648 - rightLayer2_loss: 0.9299\n",
      "Epoch 00006: val_loss improved from 5.23120 to 5.16054, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1128 - leftLayer1_loss: 0.0950 - midLayer1_loss: 1.4923 - rightLayer1_loss: 1.0489 - leftLayer2_loss: 0.0813 - midLayer2_loss: 1.4649 - rightLayer2_loss: 0.9305 - val_loss: 5.1605 - val_leftLayer1_loss: 0.0939 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.0600 - val_leftLayer2_loss: 0.0914 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0719\n",
      "Epoch 7/11\n",
      "1676/1690 [============================>.] - ETA: 0s - loss: 5.0562 - leftLayer1_loss: 0.0915 - midLayer1_loss: 1.4924 - rightLayer1_loss: 1.0139 - leftLayer2_loss: 0.0761 - midLayer2_loss: 1.4608 - rightLayer2_loss: 0.9214\n",
      "Epoch 00007: val_loss improved from 5.16054 to 5.10859, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0570 - leftLayer1_loss: 0.0915 - midLayer1_loss: 1.4926 - rightLayer1_loss: 1.0138 - leftLayer2_loss: 0.0761 - midLayer2_loss: 1.4616 - rightLayer2_loss: 0.9215 - val_loss: 5.1086 - val_leftLayer1_loss: 0.0906 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.0326 - val_leftLayer2_loss: 0.0873 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0547\n",
      "Epoch 8/11\n",
      "1670/1690 [============================>.] - ETA: 0s - loss: 5.0111 - leftLayer1_loss: 0.0883 - midLayer1_loss: 1.4929 - rightLayer1_loss: 0.9886 - leftLayer2_loss: 0.0710 - midLayer2_loss: 1.4585 - rightLayer2_loss: 0.9117\n",
      "Epoch 00008: val_loss improved from 5.10859 to 5.06878, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0135 - leftLayer1_loss: 0.0883 - midLayer1_loss: 1.4933 - rightLayer1_loss: 0.9889 - leftLayer2_loss: 0.0710 - midLayer2_loss: 1.4596 - rightLayer2_loss: 0.9125 - val_loss: 5.0688 - val_leftLayer1_loss: 0.0876 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 1.0126 - val_leftLayer2_loss: 0.0838 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0414\n",
      "Epoch 9/11\n",
      "1682/1690 [============================>.] - ETA: 0s - loss: 4.9799 - leftLayer1_loss: 0.0853 - midLayer1_loss: 1.4926 - rightLayer1_loss: 0.9704 - leftLayer2_loss: 0.0670 - midLayer2_loss: 1.4569 - rightLayer2_loss: 0.9077\n",
      "Epoch 00009: val_loss improved from 5.06878 to 5.03761, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9793 - leftLayer1_loss: 0.0852 - midLayer1_loss: 1.4926 - rightLayer1_loss: 0.9700 - leftLayer2_loss: 0.0670 - midLayer2_loss: 1.4571 - rightLayer2_loss: 0.9074 - val_loss: 5.0376 - val_leftLayer1_loss: 0.0848 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 0.9978 - val_leftLayer2_loss: 0.0807 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0310\n",
      "Epoch 10/11\n",
      "1678/1690 [============================>.] - ETA: 0s - loss: 4.9656 - leftLayer1_loss: 0.0824 - midLayer1_loss: 1.4937 - rightLayer1_loss: 0.9553 - leftLayer2_loss: 0.0635 - midLayer2_loss: 1.4683 - rightLayer2_loss: 0.9023\n",
      "Epoch 00010: val_loss improved from 5.03761 to 5.01234, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9649 - leftLayer1_loss: 0.0824 - midLayer1_loss: 1.4939 - rightLayer1_loss: 0.9551 - leftLayer2_loss: 0.0635 - midLayer2_loss: 1.4679 - rightLayer2_loss: 0.9022 - val_loss: 5.0123 - val_leftLayer1_loss: 0.0822 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 0.9864 - val_leftLayer2_loss: 0.0779 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0225\n",
      "Epoch 11/11\n",
      "1680/1690 [============================>.] - ETA: 0s - loss: 4.9461 - leftLayer1_loss: 0.0799 - midLayer1_loss: 1.4922 - rightLayer1_loss: 0.9447 - leftLayer2_loss: 0.0610 - midLayer2_loss: 1.4698 - rightLayer2_loss: 0.8986\n",
      "Epoch 00011: val_loss improved from 5.01234 to 4.99109, saving model to ./experiments/0.012999999999999996_weights.h5\n",
      "1690/1690 [==============================] - 6s 4ms/step - loss: 4.9440 - leftLayer1_loss: 0.0798 - midLayer1_loss: 1.4921 - rightLayer1_loss: 0.9440 - leftLayer2_loss: 0.0609 - midLayer2_loss: 1.4692 - rightLayer2_loss: 0.8979 - val_loss: 4.9911 - val_leftLayer1_loss: 0.0798 - val_midLayer1_loss: 1.4886 - val_rightLayer1_loss: 0.9774 - val_leftLayer2_loss: 0.0755 - val_midLayer2_loss: 1.3547 - val_rightLayer2_loss: 1.0151\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.012999999999999996_test.log **\n",
      "auroc 0Edema: 0.6024440691161238\n",
      "\n",
      "auprc 0Edema: 0.021425690064663425\n",
      "\n",
      "auroc 1Edema: 0.5924221431980172\n",
      "\n",
      "auprc 1Edema: 0.021442175196632\n",
      "\n",
      "auroc 2Edema: 0.7823463371401302\n",
      "\n",
      "auprc 2Edema: 0.07796942804767161\n",
      "\n",
      "auroc 3Edema: 0.6663237030830436\n",
      "\n",
      "auprc 3Edema: 0.03754951793796845\n",
      "\n",
      "auroc 4Edema: 0.5131062890218665\n",
      "\n",
      "auprc 4Edema: 0.021492908497908945\n",
      "\n",
      "auroc 5Edema: 0.6787207535302486\n",
      "\n",
      "auprc 5Edema: 0.04109053280343648\n",
      "\n",
      "mean auroc: 0.6392272158482383\n",
      "\n",
      "mean auprc: 0.03682837542471348\n",
      "\n",
      "max auroc: 0.7823463371401302\n",
      "\n",
      "max auprc: 0.07796942804767161\n",
      "\n",
      "78.01281332969666\n",
      "** set output weights path to: ./experiments/0.013999999999999995_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1670/1690 [============================>.] - ETA: 0s - loss: 6.5012 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4162 - rightLayer1_loss: 1.7406 - leftLayer2_loss: 0.1256 - midLayer2_loss: 1.5484 - rightLayer2_loss: 1.5475\n",
      "Epoch 00001: val_loss improved from inf to 6.20180, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.4974 - leftLayer1_loss: 0.1228 - midLayer1_loss: 1.4167 - rightLayer1_loss: 1.7389 - leftLayer2_loss: 0.1255 - midLayer2_loss: 1.5485 - rightLayer2_loss: 1.5448 - val_loss: 6.2018 - val_leftLayer1_loss: 0.1207 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.6092 - val_leftLayer2_loss: 0.1198 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.4831\n",
      "Epoch 2/11\n",
      "1675/1690 [============================>.] - ETA: 0s - loss: 5.8867 - leftLayer1_loss: 0.1179 - midLayer1_loss: 1.4163 - rightLayer1_loss: 1.4979 - leftLayer2_loss: 0.1140 - midLayer2_loss: 1.5464 - rightLayer2_loss: 1.1942\n",
      "Epoch 00002: val_loss improved from 6.20180 to 5.81107, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.8849 - leftLayer1_loss: 0.1179 - midLayer1_loss: 1.4165 - rightLayer1_loss: 1.4970 - leftLayer2_loss: 0.1140 - midLayer2_loss: 1.5462 - rightLayer2_loss: 1.1934 - val_loss: 5.8111 - val_leftLayer1_loss: 0.1160 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.4076 - val_leftLayer2_loss: 0.1130 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.3055\n",
      "Epoch 3/11\n",
      "1689/1690 [============================>.] - ETA: 0s - loss: 5.5709 - leftLayer1_loss: 0.1132 - midLayer1_loss: 1.4165 - rightLayer1_loss: 1.3217 - leftLayer2_loss: 0.1040 - midLayer2_loss: 1.5627 - rightLayer2_loss: 1.0529\n",
      "Epoch 00003: val_loss improved from 5.81107 to 5.57091, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.5707 - leftLayer1_loss: 0.1132 - midLayer1_loss: 1.4165 - rightLayer1_loss: 1.3216 - leftLayer2_loss: 0.1040 - midLayer2_loss: 1.5625 - rightLayer2_loss: 1.0529 - val_loss: 5.5709 - val_leftLayer1_loss: 0.1116 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.2703 - val_leftLayer2_loss: 0.1070 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.2131\n",
      "Epoch 4/11\n",
      "1674/1690 [============================>.] - ETA: 0s - loss: 5.3665 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.4158 - rightLayer1_loss: 1.2033 - leftLayer2_loss: 0.0955 - midLayer2_loss: 1.5528 - rightLayer2_loss: 0.9903\n",
      "Epoch 00004: val_loss improved from 5.57091 to 5.41667, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.3658 - leftLayer1_loss: 0.1088 - midLayer1_loss: 1.4159 - rightLayer1_loss: 1.2029 - leftLayer2_loss: 0.0955 - midLayer2_loss: 1.5524 - rightLayer2_loss: 0.9903 - val_loss: 5.4167 - val_leftLayer1_loss: 0.1074 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.1797 - val_leftLayer2_loss: 0.1017 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.1590\n",
      "Epoch 5/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 5.2528 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4164 - rightLayer1_loss: 1.1235 - leftLayer2_loss: 0.0885 - midLayer2_loss: 1.5603 - rightLayer2_loss: 0.9595\n",
      "Epoch 00005: val_loss improved from 5.41667 to 5.31231, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.2532 - leftLayer1_loss: 0.1047 - midLayer1_loss: 1.4166 - rightLayer1_loss: 1.1235 - leftLayer2_loss: 0.0884 - midLayer2_loss: 1.5604 - rightLayer2_loss: 0.9596 - val_loss: 5.3123 - val_leftLayer1_loss: 0.1035 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.1194 - val_leftLayer2_loss: 0.0970 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.1235\n",
      "Epoch 6/11\n",
      "1682/1690 [============================>.] - ETA: 0s - loss: 5.1632 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.4175 - rightLayer1_loss: 1.0705 - leftLayer2_loss: 0.0821 - midLayer2_loss: 1.5537 - rightLayer2_loss: 0.9386\n",
      "Epoch 00006: val_loss improved from 5.31231 to 5.23797, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1620 - leftLayer1_loss: 0.1008 - midLayer1_loss: 1.4174 - rightLayer1_loss: 1.0702 - leftLayer2_loss: 0.0821 - midLayer2_loss: 1.5535 - rightLayer2_loss: 0.9380 - val_loss: 5.2380 - val_leftLayer1_loss: 0.0998 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.0780 - val_leftLayer2_loss: 0.0928 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.0984\n",
      "Epoch 7/11\n",
      "1689/1690 [============================>.] - ETA: 0s - loss: 5.0985 - leftLayer1_loss: 0.0972 - midLayer1_loss: 1.4168 - rightLayer1_loss: 1.0324 - leftLayer2_loss: 0.0769 - midLayer2_loss: 1.5495 - rightLayer2_loss: 0.9256\n",
      "Epoch 00007: val_loss improved from 5.23797 to 5.18291, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0987 - leftLayer1_loss: 0.0972 - midLayer1_loss: 1.4167 - rightLayer1_loss: 1.0325 - leftLayer2_loss: 0.0769 - midLayer2_loss: 1.5497 - rightLayer2_loss: 0.9257 - val_loss: 5.1829 - val_leftLayer1_loss: 0.0964 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.0487 - val_leftLayer2_loss: 0.0891 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.0797\n",
      "Epoch 8/11\n",
      "1683/1690 [============================>.] - ETA: 0s - loss: 5.0599 - leftLayer1_loss: 0.0938 - midLayer1_loss: 1.4174 - rightLayer1_loss: 1.0048 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.5520 - rightLayer2_loss: 0.9198\n",
      "Epoch 00008: val_loss improved from 5.18291 to 5.14033, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0600 - leftLayer1_loss: 0.0938 - midLayer1_loss: 1.4174 - rightLayer1_loss: 1.0046 - leftLayer2_loss: 0.0721 - midLayer2_loss: 1.5525 - rightLayer2_loss: 0.9197 - val_loss: 5.1403 - val_leftLayer1_loss: 0.0932 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.0273 - val_leftLayer2_loss: 0.0859 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.0650\n",
      "Epoch 9/11\n",
      "1672/1690 [============================>.] - ETA: 0s - loss: 5.0201 - leftLayer1_loss: 0.0908 - midLayer1_loss: 1.4157 - rightLayer1_loss: 0.9841 - leftLayer2_loss: 0.0683 - midLayer2_loss: 1.5520 - rightLayer2_loss: 0.9092\n",
      "Epoch 00009: val_loss improved from 5.14033 to 5.10697, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0225 - leftLayer1_loss: 0.0908 - midLayer1_loss: 1.4162 - rightLayer1_loss: 0.9846 - leftLayer2_loss: 0.0683 - midLayer2_loss: 1.5525 - rightLayer2_loss: 0.9101 - val_loss: 5.1070 - val_leftLayer1_loss: 0.0902 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 1.0112 - val_leftLayer2_loss: 0.0830 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.0536\n",
      "Epoch 10/11\n",
      "1677/1690 [============================>.] - ETA: 0s - loss: 4.9955 - leftLayer1_loss: 0.0877 - midLayer1_loss: 1.4171 - rightLayer1_loss: 0.9688 - leftLayer2_loss: 0.0646 - midLayer2_loss: 1.5502 - rightLayer2_loss: 0.9070\n",
      "Epoch 00010: val_loss improved from 5.10697 to 5.07967, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9958 - leftLayer1_loss: 0.0877 - midLayer1_loss: 1.4170 - rightLayer1_loss: 0.9687 - leftLayer2_loss: 0.0646 - midLayer2_loss: 1.5507 - rightLayer2_loss: 0.9071 - val_loss: 5.0797 - val_leftLayer1_loss: 0.0874 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 0.9988 - val_leftLayer2_loss: 0.0804 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.0440\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1674/1690 [============================>.] - ETA: 0s - loss: 4.9750 - leftLayer1_loss: 0.0850 - midLayer1_loss: 1.4162 - rightLayer1_loss: 0.9569 - leftLayer2_loss: 0.0619 - midLayer2_loss: 1.5502 - rightLayer2_loss: 0.9048\n",
      "Epoch 00011: val_loss improved from 5.07967 to 5.05698, saving model to ./experiments/0.013999999999999995_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9759 - leftLayer1_loss: 0.0850 - midLayer1_loss: 1.4165 - rightLayer1_loss: 0.9569 - leftLayer2_loss: 0.0619 - midLayer2_loss: 1.5505 - rightLayer2_loss: 0.9050 - val_loss: 5.0570 - val_leftLayer1_loss: 0.0848 - val_midLayer1_loss: 1.4312 - val_rightLayer1_loss: 0.9890 - val_leftLayer2_loss: 0.0781 - val_midLayer2_loss: 1.4378 - val_rightLayer2_loss: 1.0360\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.013999999999999995_test.log **\n",
      "auroc 0Edema: 0.6980659229008188\n",
      "\n",
      "auprc 0Edema: 0.06496844865004439\n",
      "\n",
      "auroc 1Edema: 0.37464642532762427\n",
      "\n",
      "auprc 1Edema: 0.013378423688262477\n",
      "\n",
      "auroc 2Edema: 0.7472869150431152\n",
      "\n",
      "auprc 2Edema: 0.06404868915775894\n",
      "\n",
      "auroc 3Edema: 0.38733118472531025\n",
      "\n",
      "auprc 3Edema: 0.013494781055211175\n",
      "\n",
      "auroc 4Edema: 0.7735919690002265\n",
      "\n",
      "auprc 4Edema: 0.06820152801346979\n",
      "\n",
      "auroc 5Edema: 0.5361231699995381\n",
      "\n",
      "auprc 5Edema: 0.018550855901443116\n",
      "\n",
      "mean auroc: 0.5861742644994389\n",
      "\n",
      "mean auprc: 0.04044045441103165\n",
      "\n",
      "max auroc: 0.7735919690002265\n",
      "\n",
      "max auprc: 0.06820152801346979\n",
      "\n",
      "76.20044350624084\n",
      "** set output weights path to: ./experiments/0.014999999999999994_weights.h5 **\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1536)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat2 (Flatten)                 (None, 1536)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1536)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 417)          640929      flat2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 292)          448804      flat1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 417)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 292)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 417)          0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 292)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 417)          0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer1 (Dense)              (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer1 (Dense)               (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer1 (Dense)             (None, 14)           4102        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leftLayer2 (Dense)              (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "midLayer2 (Dense)               (None, 14)           5852        dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rightLayer2 (Dense)             (None, 14)           5852        dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,119,595\n",
      "Trainable params: 19,908\n",
      "Non-trainable params: 1,099,687\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  {'leftLayer1': '...', 'midLayer1': '...', 'rightLayer1': '...', 'leftLayer2': '...', 'midLayer2': '...', 'rightLayer2': '...'}\n",
      "    to  \n",
      "  ['...', '...', '...', '...', '...', '...']\n",
      "Train for 1690 steps, validate for 200 steps\n",
      "Epoch 1/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 6.4086 - leftLayer1_loss: 0.1251 - midLayer1_loss: 1.4146 - rightLayer1_loss: 1.7904 - leftLayer2_loss: 0.1278 - midLayer2_loss: 1.3705 - rightLayer2_loss: 1.5801\n",
      "Epoch 00001: val_loss improved from inf to 6.19698, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 6.4075 - leftLayer1_loss: 0.1251 - midLayer1_loss: 1.4145 - rightLayer1_loss: 1.7901 - leftLayer2_loss: 0.1278 - midLayer2_loss: 1.3704 - rightLayer2_loss: 1.5795 - val_loss: 6.1970 - val_leftLayer1_loss: 0.1231 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.6750 - val_leftLayer2_loss: 0.1196 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.5046\n",
      "Epoch 2/11\n",
      "1685/1690 [============================>.] - ETA: 0s - loss: 5.8022 - leftLayer1_loss: 0.1206 - midLayer1_loss: 1.4147 - rightLayer1_loss: 1.5673 - leftLayer2_loss: 0.1165 - midLayer2_loss: 1.3703 - rightLayer2_loss: 1.2127\n",
      "Epoch 00002: val_loss improved from 6.19698 to 5.81118, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.8019 - leftLayer1_loss: 0.1206 - midLayer1_loss: 1.4148 - rightLayer1_loss: 1.5670 - leftLayer2_loss: 0.1165 - midLayer2_loss: 1.3705 - rightLayer2_loss: 1.2124 - val_loss: 5.8112 - val_leftLayer1_loss: 0.1189 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.4809 - val_leftLayer2_loss: 0.1130 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.3237\n",
      "Epoch 3/11\n",
      "1689/1690 [============================>.] - ETA: 0s - loss: 5.4661 - leftLayer1_loss: 0.1164 - midLayer1_loss: 1.4146 - rightLayer1_loss: 1.3922 - leftLayer2_loss: 0.1066 - midLayer2_loss: 1.3742 - rightLayer2_loss: 1.0620\n",
      "Epoch 00003: val_loss improved from 5.81118 to 5.56187, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.4660 - leftLayer1_loss: 0.1164 - midLayer1_loss: 1.4145 - rightLayer1_loss: 1.3922 - leftLayer2_loss: 0.1066 - midLayer2_loss: 1.3742 - rightLayer2_loss: 1.0620 - val_loss: 5.5619 - val_leftLayer1_loss: 0.1149 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.3369 - val_leftLayer2_loss: 0.1072 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.2282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "1684/1690 [============================>.] - ETA: 0s - loss: 5.2536 - leftLayer1_loss: 0.1125 - midLayer1_loss: 1.4147 - rightLayer1_loss: 1.2659 - leftLayer2_loss: 0.0981 - midLayer2_loss: 1.3668 - rightLayer2_loss: 0.9957\n",
      "Epoch 00004: val_loss improved from 5.56187 to 5.39487, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.2532 - leftLayer1_loss: 0.1124 - midLayer1_loss: 1.4146 - rightLayer1_loss: 1.2657 - leftLayer2_loss: 0.0980 - midLayer2_loss: 1.3669 - rightLayer2_loss: 0.9955 - val_loss: 5.3949 - val_leftLayer1_loss: 0.1111 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.2354 - val_leftLayer2_loss: 0.1019 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.1717\n",
      "Epoch 5/11\n",
      "1688/1690 [============================>.] - ETA: 0s - loss: 5.1225 - leftLayer1_loss: 0.1087 - midLayer1_loss: 1.4153 - rightLayer1_loss: 1.1756 - leftLayer2_loss: 0.0906 - midLayer2_loss: 1.3720 - rightLayer2_loss: 0.9603\n",
      "Epoch 00005: val_loss improved from 5.39487 to 5.27865, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.1226 - leftLayer1_loss: 0.1087 - midLayer1_loss: 1.4153 - rightLayer1_loss: 1.1756 - leftLayer2_loss: 0.0906 - midLayer2_loss: 1.3721 - rightLayer2_loss: 0.9604 - val_loss: 5.2786 - val_leftLayer1_loss: 0.1075 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.1644 - val_leftLayer2_loss: 0.0973 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.1347\n",
      "Epoch 6/11\n",
      "1682/1690 [============================>.] - ETA: 0s - loss: 5.0268 - leftLayer1_loss: 0.1051 - midLayer1_loss: 1.4145 - rightLayer1_loss: 1.1124 - leftLayer2_loss: 0.0842 - midLayer2_loss: 1.3698 - rightLayer2_loss: 0.9407\n",
      "Epoch 00006: val_loss improved from 5.27865 to 5.19465, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 5.0258 - leftLayer1_loss: 0.1051 - midLayer1_loss: 1.4143 - rightLayer1_loss: 1.1121 - leftLayer2_loss: 0.0841 - midLayer2_loss: 1.3699 - rightLayer2_loss: 0.9402 - val_loss: 5.1946 - val_leftLayer1_loss: 0.1041 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.1142 - val_leftLayer2_loss: 0.0932 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.1084\n",
      "Epoch 7/11\n",
      "1682/1690 [============================>.] - ETA: 0s - loss: 4.9598 - leftLayer1_loss: 0.1017 - midLayer1_loss: 1.4151 - rightLayer1_loss: 1.0676 - leftLayer2_loss: 0.0786 - midLayer2_loss: 1.3706 - rightLayer2_loss: 0.9262\n",
      "Epoch 00007: val_loss improved from 5.19465 to 5.13214, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9586 - leftLayer1_loss: 0.1017 - midLayer1_loss: 1.4150 - rightLayer1_loss: 1.0673 - leftLayer2_loss: 0.0785 - midLayer2_loss: 1.3703 - rightLayer2_loss: 0.9258 - val_loss: 5.1321 - val_leftLayer1_loss: 0.1009 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.0780 - val_leftLayer2_loss: 0.0896 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.0890\n",
      "Epoch 8/11\n",
      "1674/1690 [============================>.] - ETA: 0s - loss: 4.9154 - leftLayer1_loss: 0.0986 - midLayer1_loss: 1.4150 - rightLayer1_loss: 1.0337 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3754 - rightLayer2_loss: 0.9189\n",
      "Epoch 00008: val_loss improved from 5.13214 to 5.08381, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.9154 - leftLayer1_loss: 0.0985 - midLayer1_loss: 1.4152 - rightLayer1_loss: 1.0336 - leftLayer2_loss: 0.0739 - midLayer2_loss: 1.3752 - rightLayer2_loss: 0.9190 - val_loss: 5.0838 - val_leftLayer1_loss: 0.0979 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.0511 - val_leftLayer2_loss: 0.0864 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.0737\n",
      "Epoch 9/11\n",
      "1672/1690 [============================>.] - ETA: 0s - loss: 4.8665 - leftLayer1_loss: 0.0955 - midLayer1_loss: 1.4150 - rightLayer1_loss: 1.0078 - leftLayer2_loss: 0.0701 - midLayer2_loss: 1.3701 - rightLayer2_loss: 0.9081\n",
      "Epoch 00009: val_loss improved from 5.08381 to 5.04575, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.8681 - leftLayer1_loss: 0.0954 - midLayer1_loss: 1.4153 - rightLayer1_loss: 1.0083 - leftLayer2_loss: 0.0701 - midLayer2_loss: 1.3702 - rightLayer2_loss: 0.9088 - val_loss: 5.0458 - val_leftLayer1_loss: 0.0950 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.0308 - val_leftLayer2_loss: 0.0835 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.0617\n",
      "Epoch 10/11\n",
      "1671/1690 [============================>.] - ETA: 0s - loss: 4.8367 - leftLayer1_loss: 0.0926 - midLayer1_loss: 1.4135 - rightLayer1_loss: 0.9885 - leftLayer2_loss: 0.0665 - midLayer2_loss: 1.3709 - rightLayer2_loss: 0.9047\n",
      "Epoch 00010: val_loss improved from 5.04575 to 5.01475, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.8390 - leftLayer1_loss: 0.0926 - midLayer1_loss: 1.4139 - rightLayer1_loss: 0.9889 - leftLayer2_loss: 0.0665 - midLayer2_loss: 1.3717 - rightLayer2_loss: 0.9055 - val_loss: 5.0148 - val_leftLayer1_loss: 0.0923 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.0150 - val_leftLayer2_loss: 0.0810 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.0518\n",
      "Epoch 11/11\n",
      "1686/1690 [============================>.] - ETA: 0s - loss: 4.8083 - leftLayer1_loss: 0.0899 - midLayer1_loss: 1.4141 - rightLayer1_loss: 0.9744 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.3658 - rightLayer2_loss: 0.9007\n",
      "Epoch 00011: val_loss improved from 5.01475 to 4.98925, saving model to ./experiments/0.014999999999999994_weights.h5\n",
      "1690/1690 [==============================] - 4s 3ms/step - loss: 4.8081 - leftLayer1_loss: 0.0899 - midLayer1_loss: 1.4140 - rightLayer1_loss: 0.9744 - leftLayer2_loss: 0.0634 - midLayer2_loss: 1.3656 - rightLayer2_loss: 0.9008 - val_loss: 4.9892 - val_leftLayer1_loss: 0.0898 - val_midLayer1_loss: 1.4178 - val_rightLayer1_loss: 1.0026 - val_leftLayer2_loss: 0.0786 - val_midLayer2_loss: 1.3569 - val_rightLayer2_loss: 1.0436\n",
      "22433/22433 [==============================] - 28s 1ms/step\n",
      "** write log to ./experiments/0.014999999999999994_test.log **\n",
      "auroc 0Edema: 0.6318051716137433\n",
      "\n",
      "auprc 0Edema: 0.030833423117138353\n",
      "\n",
      "auroc 1Edema: 0.6651477415424674\n",
      "\n",
      "auprc 1Edema: 0.031020851832828458\n",
      "\n",
      "auroc 2Edema: 0.6466228698101879\n",
      "\n",
      "auprc 2Edema: 0.029934295175664795\n",
      "\n",
      "auroc 3Edema: 0.48189187465500216\n",
      "\n",
      "auprc 3Edema: 0.01630698945545924\n",
      "\n",
      "auroc 4Edema: 0.4207385207812401\n",
      "\n",
      "auprc 4Edema: 0.01424085604650825\n",
      "\n",
      "auroc 5Edema: 0.48893934195855404\n",
      "\n",
      "auprc 5Edema: 0.016960541631627326\n",
      "\n",
      "mean auroc: 0.5558575867268658\n",
      "\n",
      "mean auprc: 0.0232161595432044\n",
      "\n",
      "max auroc: 0.6651477415424674\n",
      "\n",
      "max auprc: 0.031020851832828458\n",
      "\n",
      "76.71883201599121\n"
     ]
    }
   ],
   "source": [
    "step = np.arange(0.009, 0.0151, 0.001)\n",
    "maxi = []\n",
    "for k in np.nditer(step):\n",
    "    opn, daTime = optimize_network(k)\n",
    "    print(daTime)\n",
    "    maxi.append(opn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8162035173834925\n"
     ]
    }
   ],
   "source": [
    "print(np.max(maxi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
